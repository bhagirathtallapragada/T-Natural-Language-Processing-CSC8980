{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlpexam2fin.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVOxZXn4dBi2kRHQdGPfT5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhagirathtallapragada/T-Natural-Language-Processing-CSC8980/blob/main/exam2/nlpexam2fin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVRYqutWmN8"
      },
      "source": [
        "Bhagirath Tallapragada panther id: 002575358"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plc37yg5dmnr"
      },
      "source": [
        "Question 1) (20 points) Write a function that takes a List of five words: [‘apple’, ‘house’, ‘pear’,\n",
        "‘dog’, ‘doctor’] and returns a list of lists with each element being a word and a list of the top five\n",
        "most similar words. For this task you have to use the most suitable method of the ones we have\n",
        "seen in class to determine the most similar words to the original input list. You can use a\n",
        "pre-trained resource if you think is appropriate. After calling your function, print the most similar\n",
        "words to the screen. Are these ‘similar’ words actually similar? If not, why not? What do you\n",
        "think can be improved and how - talk about it, do not necessarily implement it?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWoYbp6NYgVl"
      },
      "source": [
        "Using Google's Word2Vec pre-computed embeddings from https://code.google.com/archive/p/word2vec/ for this question:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0upjHy5_drT8",
        "outputId": "305e0f3b-1c58-4ae3-d48e-2939a6e6a57d"
      },
      "source": [
        "!gdown --id 0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:09, 167MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLoUPAo7fBfg"
      },
      "source": [
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alU9Hgy3P1_y"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "filename = '/content/GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW0nrkWsQBLS"
      },
      "source": [
        "keywords=['apple', 'house', 'pear', 'dog', 'doctor']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10EjDQveUA0O"
      },
      "source": [
        "def most_similar(l):\n",
        "  res=[]\n",
        "  for i in l:\n",
        "    # dat=[]\n",
        "    dat=[tup[0] for tup in model.most_similar(i)]\n",
        "    dat=dat[:5]\n",
        "    res.append(dat)\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MsOoQYHP9IE",
        "outputId": "ef6c829f-a22c-49a4-9f89-c47c39e867a4"
      },
      "source": [
        "res=most_similar(keywords)\n",
        "print(\"keywords:\\n {}\".format(keywords))\n",
        "print(\"similar words list\\n {}\".format(res))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keywords:\n",
            " ['apple', 'house', 'pear', 'dog', 'doctor']\n",
            "similar words list\n",
            " [['apples', 'pear', 'fruit', 'berry', 'pears'], ['houses', 'bungalow', 'apartment', 'bedroom', 'townhouse'], ['pears', 'apricot', 'apricots', 'nectarine', 'Fuji_apple'], ['dogs', 'puppy', 'pit_bull', 'pooch', 'cat'], ['physician', 'doctors', 'gynecologist', 'surgeon', 'dentist']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0ToMH0kUdn7"
      },
      "source": [
        "Observation: As can be observed the similar words fetched by the function for most of the keywords is a mixed bag of great and poor similarity. For instance the words like  'fruit, 'berry' are accurately similar to the keyword 'apple' (meaning a fruit). However, the model does misfire in terms of differentiating between different forms of the same word such as plurality. This results in capture of the *same word* being branded as a *similar* word.\n",
        "In terms of improving this, a threshold could be introduced to filter out words that are too similar to each other. For instance, the word vector of 'house' will be nearly similar to 'houses', where as other similar words such as 'bungalow' or 'apartment' will still be relatively different.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Debu9O8SYlDV"
      },
      "source": [
        "Question 2) (30 points) Using the Homework 2 dataset, also attached in the Exam 2 files,\n",
        "shakespeares-works_TXT_FolgerShakespeare.zip. Find the document to document similarity\n",
        "using:\n",
        "a) Cosine similarity. And create a 42 x 42 heatmap of these similarities.\n",
        "b) Use Doc2Vec to create document embeddings and find the similarities between the\n",
        "documents. To visualize this, also create a 42 x 42 heatmap for this.\n",
        "c) What are the differences you find between the two methods? Is there anything radically\n",
        "different? Please describe your answer in terms of the heatmap of part a and part b."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvNkdA20abdJ",
        "outputId": "9b831f2a-b484-4d46-a6b1-74fd98ce8dbc"
      },
      "source": [
        "import os\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gensim\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMBgxM8FWh_x",
        "outputId": "431fe637-0ab1-44c9-d9ad-d24dbbc21552"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9V-pOMTY4pU"
      },
      "source": [
        "# !unzip /content/drive/MyDrive/shakespeares-works_TXT_FolgerShakespeare.zip -d /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBz8UzejYjr3"
      },
      "source": [
        "directory='/content/drive/MyDrive/shakespeares-works_TXT_FolgerShakespeare'\n",
        "collection=[]\n",
        "doc_name=[]\n",
        "for filename in os.listdir(directory):\n",
        "  if (filename.endswith('.txt')):\n",
        "    string1=(open(os.path.join(directory, filename)))\n",
        "    collection.append(string1.read())\n",
        "\n",
        "    doc_name.append(filename.rstrip('.txt'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD_BY4cYeMOh"
      },
      "source": [
        "a. Using Cosine Similarity:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKnZaNRFarui"
      },
      "source": [
        "def cosine_sim_creator(collection):\n",
        "  tfIdfVectorizer1=TfidfVectorizer()\n",
        "  tfIdf = tfIdfVectorizer1.fit_transform(collection)\n",
        "  # tfIdf=tfIdf.astype(np.float32)\n",
        "  csmat=cosine_similarity(tfIdf)\n",
        "\n",
        "  return csmat"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTE2bOJVdpbd",
        "outputId": "5fc52037-fe1a-414e-a76b-2e6cc577c7e6"
      },
      "source": [
        "cs=cosine_sim_creator(collection)\n",
        "cs"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.63130422, 0.56777768, ..., 0.62809744, 0.58210527,\n",
              "        0.70198325],\n",
              "       [0.63130422, 1.        , 0.53550819, ..., 0.59404353, 0.53697935,\n",
              "        0.70306567],\n",
              "       [0.56777768, 0.53550819, 1.        , ..., 0.52581905, 0.47821321,\n",
              "        0.60407163],\n",
              "       ...,\n",
              "       [0.62809744, 0.59404353, 0.52581905, ..., 1.        , 0.52841954,\n",
              "        0.67101444],\n",
              "       [0.58210527, 0.53697935, 0.47821321, ..., 0.52841954, 1.        ,\n",
              "        0.58303526],\n",
              "       [0.70198325, 0.70306567, 0.60407163, ..., 0.67101444, 0.58303526,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiNnCzm0d0kO",
        "outputId": "d7750e81-a4c9-4829-8222-0372160a5634"
      },
      "source": [
        "cs.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "RJp2VUk3d2cx",
        "outputId": "da68262f-3383-43b8-c014-3180dc038cd6"
      },
      "source": [
        "plt.imshow(cs, cmap='hot', interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75giLSXfeUaE"
      },
      "source": [
        "b. Using Doc2Vec:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j0F6PuyeWjY"
      },
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(collection)]\n",
        "model = Doc2Vec(documents)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etBzit2fkSrX"
      },
      "source": [
        "X = []\n",
        "for i in range(len(collection)):\n",
        "  X.append(model.infer_vector(collection[i]))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWPv9sb4lZvc",
        "outputId": "eca6c355-47e6-446f-8837-2e34c0ae374a"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjVklhMXrZhW",
        "outputId": "aa1ca5a4-3164-4f69-e870-9b40e0d4577d"
      },
      "source": [
        "cs2=cosine_similarity(X)\n",
        "cs2"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.0000001 ,  0.23162475, -0.12114841, ..., -0.18891105,\n",
              "         0.27973443,  0.35160038],\n",
              "       [ 0.23162475,  1.0000001 , -0.1021529 , ..., -0.13561012,\n",
              "         0.22396421,  0.15577094],\n",
              "       [-0.12114841, -0.1021529 ,  1.        , ...,  0.30140823,\n",
              "         0.23245032,  0.15710765],\n",
              "       ...,\n",
              "       [-0.18891105, -0.13561012,  0.30140823, ...,  1.0000001 ,\n",
              "        -0.42639315,  0.37269056],\n",
              "       [ 0.27973443,  0.22396421,  0.23245032, ..., -0.42639315,\n",
              "         1.        ,  0.11739547],\n",
              "       [ 0.35160038,  0.15577094,  0.15710765, ...,  0.37269056,\n",
              "         0.11739547,  0.9999999 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk6fq728r-Nz",
        "outputId": "5feb6d80-5539-42ca-f3a7-92815ff6d84d"
      },
      "source": [
        "cs2.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "r12J6NSqjgFM",
        "outputId": "7f74784e-b10e-4a9f-ebd2-27ca3e769859"
      },
      "source": [
        "plt.imshow(cs2, cmap='hot', interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTjBZk4AleYn"
      },
      "source": [
        "c. What are the differences you find between the two methods? Is there anything radically\n",
        "different? Please describe your answer in terms of the heatmap of part a and part b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqk304LjPlnY"
      },
      "source": [
        "In terms of the two generated heatmaps, the most visible difference is that the Doc2Vec model has lesser number of black cells than the cosine similarity method. This indicates that the doc2vec model seems to find more similarity in the documents as compared to the cosine similarity.\n",
        "Both models seem to agree about the most similar documents in the way the yellow color band is spread, however both tell a different story in terms of non similar documents. The non similar documents are sparse in in the doc2vec model where as they are clearly distinguishable and linear in cosine similarity criscrossing the heatmap. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RJYR09xllFS"
      },
      "source": [
        "Question 3) (30 points) Using the Homework 2 dataset. Use SpaCy to extract the following:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aFcmi-LnG1p"
      },
      "source": [
        "a) Write a function to generate all unique bigrams from all documents in the dataset. The\n",
        "input of this function should be the concatenated dataset and the output should be the\n",
        "list of bigrams and their frequency. Display the top 10 most common bigrams and their\n",
        "frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6k0xlyMu22r"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNWydlnPGnPM"
      },
      "source": [
        "def n_common_freq_bi(collection):\n",
        "  bi_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "  sentences= []\n",
        "  for i in collection:\n",
        "    sentences.append(nltk.word_tokenize(i.rstrip('\\n')))\n",
        "  bigram=[]\n",
        "  for i in sentences:\n",
        "    bigram.extend(list(nltk.bigrams(i)))\n",
        "    # compute frequency of bigrams\n",
        "  d={}\n",
        "  for x in bigram:\n",
        "    d[x] = d.get(x,0) + 1\n",
        "  bigram=set(bigram)\n",
        "  bi_freq={}\n",
        "  for i in bigram:\n",
        "    bi_freq[i]=d[i]\n",
        "  sorted_freq = sorted(bi_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "  return sorted_freq"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tThoNsUTGDV6",
        "outputId": "ac614291-d2c9-4bfc-c5a2-0c0260630ae3"
      },
      "source": [
        "res=n_common_freq_bi(collection)\n",
        "#printing 10 most common bigrams\n",
        "for i in res[:10]:\n",
        "  print([i[0],i[1]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(',', 'and'), 7555]\n",
            "[('.', ']'), 6766]\n",
            "[('.', '['), 4857]\n",
            "[(',', 'I'), 4460]\n",
            "[(',', 'And'), 3742]\n",
            "[('.', 'I'), 3132]\n",
            "[(',', '['), 2773]\n",
            "[(',', 'my'), 2251]\n",
            "[('[', 'Enter'), 2177]\n",
            "[('I', 'am'), 1962]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_gPSW8gGmLE"
      },
      "source": [
        "b) Write a function to generate all unique trigrams from all documents in the dataset. The\n",
        "input of this function should be the concatenated dataset and the output should be the\n",
        "list of trigrams and their frequency. Display the top 10 most common trigrams and their\n",
        "frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK3CDG86FGsZ"
      },
      "source": [
        "# defining the function to return the 10 most common bigrams with their frequencies\n",
        "\n",
        "def n_common_freq_tri(collection):\n",
        "  tri_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "  sentences= []\n",
        "  for i in collection:\n",
        "    sentences.append(nltk.word_tokenize(i.rstrip('\\n')))\n",
        "  trigram=[]\n",
        "  for i in sentences:\n",
        "    trigram.extend(list(nltk.trigrams(i)))\n",
        "    # compute frequency of trigrams\n",
        "  d={}\n",
        "  for x in trigram:\n",
        "    d[x] = d.get(x,0) + 1\n",
        "  trigram=set(trigram)\n",
        "  tri_freq={}\n",
        "  for i in trigram:\n",
        "    tri_freq[i]=d[i]\n",
        "  sorted_freq = sorted(tri_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "  return sorted_freq"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeicWgVRHXbh",
        "outputId": "50f52a2a-cf1b-428a-af41-d1657dda8f24"
      },
      "source": [
        "res=n_common_freq_tri(collection)\n",
        "#printing 10 most common trigrams\n",
        "for i in res[:10]:\n",
        "  print([i[0],i[1]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('.', '[', 'Enter'), 994]\n",
            "[(',', 'sir', ','), 991]\n",
            "[('exits', '.', ']'), 986]\n",
            "[('exit', '.', ']'), 970]\n",
            "[(',', 'my', 'lord'), 957]\n",
            "[('.', '[', 'He'), 918]\n",
            "[(',', '[', 'to'), 876]\n",
            "[(',', '[', 'as'), 717]\n",
            "[('.', '[', 'They'), 698]\n",
            "[('=======', '[', 'Enter'), 630]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auN62ZdmwRtl"
      },
      "source": [
        "c) Write a function to extract all unique NOUN and VERB tokens. The input of this function\n",
        "should be the concatenated dataset and the output should be two lists: one of the NOUN\n",
        "tokens and their frequency, the other list should be the VERB tokens and their counts.\n",
        "Display the top 10 most common NOUN and VERB tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnmgz-JaH1Vc"
      },
      "source": [
        "import collections\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRB-WBXev5qR"
      },
      "source": [
        "#concatinate the collection\n",
        "col=\" \".join(collection)\n",
        "# col1=\"HELEN O, my good lord, when I was like this maid, I found you wondrous kind. There is your ring, And, look you, here's your letter. [She takes out a paper.] This it says: When from my finger you can get this ring And are by me with child, etc. This is done. Will you be mine now you are doubly won?\""
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psVXHNt9xI7C"
      },
      "source": [
        "def ext_nv(col):\n",
        "  nouns=[]\n",
        "  verbs=[]\n",
        "  # col=col.splitlines()\n",
        "  # print(col)\n",
        "  # doc=nlp(col)\n",
        "  for text in col.splitlines():\n",
        "    doc=nlp(text)\n",
        "    for token in doc:\n",
        "      if token.pos_ ==\"NOUN\":\n",
        "        nouns.append(str(token))\n",
        "      elif token.pos_ ==\"VERB\":\n",
        "        verbs.append(str(token))\n",
        "  noun_count=Counter(nouns)\n",
        "  verb_count=Counter(verbs)\n",
        "  return list(noun_count.items()), list(verb_count.items())"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_llXanIoEYO"
      },
      "source": [
        "sorted_noun_freq, sorted_verb_freq=ext_nv(col)"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mONgpMAJVCJr",
        "outputId": "c3d343ae-a099-4078-c67c-77c724eadf74"
      },
      "source": [
        "#printing the 10 most common nouns and verbs\n",
        "\n",
        "print(sorted(sorted_noun_freq, key = lambda x: x[1], reverse=True)[:10])\n",
        "print(sorted(sorted_verb_freq, key = lambda x: x[1], reverse=True)[:10])"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('man', 1969), ('love', 1573), ('sir', 1280), ('heart', 1099), ('time', 1074), ('father', 992), ('men', 970), ('life', 933), ('hand', 925), ('death', 877)]\n",
            "[('will', 4445), ('shall', 3349), (\"'ll\", 2598), ('would', 2166), ('can', 1901), ('Enter', 1759), ('know', 1680), ('make', 1575), ('come', 1568), ('may', 1546)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taYKrepfV5kP"
      },
      "source": [
        "d) What do you think the most common bigrams and trigrams could be useful for? There is\n",
        "a particular method we have seen in this class to characterize a corpus that could benefit\n",
        "from having these bigrams/trigrams when the underlying text corpus can’t be shared.\n",
        "Please talk about this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QVxLYeV6UY"
      },
      "source": [
        "Ans.Bigrams and Trigrams can be useful for tasks such as text completion. It can be very helpful to approximate the most probable word pairs for a particular meaning. For example: 'childish view' vs 'childlike viiew' . Though similar in occurance the former can have alternate meanings. So frequent bigrams or trigrams can be analysed to obtain regular and politically correct representation of text. This ability extends to another area of study which is to analyse the change in language patterns over periodic intervals. word Pairings can be studied to see how some word expressions change over time without technically altering the intended meaning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ5FminWpWWz"
      },
      "source": [
        "Question 4) (30 points) Using the dataset: Ask0729, found in Exam files, write two functions to\n",
        "extract all dates found in this dataset. The input of these functions should take the dataset as\n",
        "input, and output a list of dates. You should use two different methods, one per function.\n",
        "a) First method: using SpaCy (this is a big enough hint)\n",
        "b) Second method: using regular expressions.\n",
        "c) Print to screen to compare the results from the two functions.\n",
        "d) Which one of the two approaches was better? Why do you think so? Would you use any\n",
        "of these approaches? Or a different one?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcCgO_rNpZ21",
        "outputId": "faad8bae-2881-4bdb-ab64-0c13e8d9687b"
      },
      "source": [
        "!unzip /content/sample_data/Ask0729.zip -d /content/sample_data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/sample_data/Ask0729.zip\n",
            "  inflating: /content/sample_data/Ask0729-fixed.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqih3fhBt_79"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkCkiI9qHJa"
      },
      "source": [
        "directory='/content/sample_data/'\n",
        "collection=[]\n",
        "for filename in os.listdir(directory):\n",
        "  if (filename=='Ask0729-fixed.txt'):\n",
        "    string1=(open(os.path.join(directory, filename)))\n",
        "    collection.append(string1.read())\n",
        "\n",
        "    # doc_name.append(filename.rstrip('.txt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEzreoe2sl58"
      },
      "source": [
        "# using regexp\n",
        "import re\n",
        "col=\" \".join(collection)\n",
        "\n",
        "def regex_dates(col):\n",
        "  dates_reg=re.findall(r\"(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec\\w*)\\s[\\d]{4} | [\\d]{1,2} [ADFJMNOS]\\w* [\\d]{4}\", col, re.I)\n",
        "  return dates_reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZeTin8iq5Fy"
      },
      "source": [
        "# using spacy\n",
        "\n",
        "def spacy_dates(collection):\n",
        "  dates_sp=[]\n",
        "  for i in collection:\n",
        "    doc=nlp(i)\n",
        "    for ent in doc.ents:\n",
        "      if ent.label_=='DATE':\n",
        "        # print(ent.text, ent.label_)\n",
        "        dates_sp.append(ent.text)\n",
        "  return dates_sp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsltPLeoB_lU"
      },
      "source": [
        "c. Print to screen to compare the results from the two functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1enUQnol62Ez",
        "outputId": "534d4d97-6195-4025-957c-1a70cc19a8b1"
      },
      "source": [
        "dates_re=regex_dates(col)\n",
        "print(dates_re)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' 30 June 2012', ' 28 August 2011', ' 1 Dec 2013', ' 29 April 2012']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRPOwueXxSIC",
        "outputId": "bc116682-dd2a-4ecc-9809-fb26e24c156b"
      },
      "source": [
        "dates_sp=spacy_dates(collection)\n",
        "print(dates_sp)\n",
        "print(len())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['up to 5 years', 'today', 'today', 'today', 'one week', 'MA 02143', 'daily', 'today', '3+ Nights & Save', 'this week', 'weekend', 'this week', '2 Weeks', 'the year', 'tomorrow', 'Wednesday', 'Saturday', 'the 6 year old', 'tomorrow', '25 years', 'year end 2000', 'under 40/over 40', 'junior-year', 'all summer', 'next week', 'yesterday', 'Monday', 'Thursday 4:00PM', 'July 31, 2014', '30 June 2012', 'April 15th', 'this year', 'this time', 'next year', 'years', 'Friday', 'Monday', 'December 7th', 'yesterday', 'yesterday', 'tomorrow', '14 day', '2 days', 'years', 'tomorrow', 'tomorrow', 'tomorrow', 'the next year', 'Sunday', 'a day', '12 MONTHS', 'July 4, 2012', 'Tomorrow', 'this week', 'Tuesday, March 20, 2001', 'annual', '21st Century', 'this week', 'tomorrow', 'next Wednesday', 'the old days', 'Next week', 'April', 'the 19th', 'August 31st', 'the year', 'only a week', 'June 23, 2000', 'today', 'Last week', 'Friday', 'the week', 'the 31st of March', '1 Year Giveaway', 'Thanksgiving', 'Today', 'Tomorrow', '2 weeks ago', 'every day', 'weekly', 'annual', 'tomorrow', 'A few weeks ago', 'this week', '1999', '2000', 'annual', '2081', 'Monday', 'March 8, 2013', 'the late 18th century', 'last week', 'today', 'next week', 'Sunday', 'the next two weeks', 'a few weeks', 'today', '1850-1940 1.1.0', 'February 28, 2014', 'the last year', 'the weeks', 'months ahead', '2 day', 'today', '30 June', 'the next 75 days', '2000', 'about a month', \"last Tuesday'Wednesday's\", 'Thursday', 'this year', '11 July', '1 year', 'April 2011', 'Day 5', 'April 5-19 15,000/day', 'Wednesday, June 27', 'the first weekend', 'April', 'Jan 26th', 'the weekend', 'the week of January 15th', 'that week', 'friday', 'yesterday', 'Thursday', 'approximately 2 years', 'the next 3-6 months', 'yesterday', 'August 2013', 'August 22, 2012', 'August 23, 2012', 'August 8, 2012', 'this Monday, September 2nd, 2013', 'a week or so ago', 'Friday', '2001', 'today', 'tomorrow', 'last week', 'tomorrow', 'yesterday', 'Monday', 'Tuesday', 'the days/weeks ahead', 'Thursday', '36 months', 'Wednesday', 'Thursday', 'Tuesday, October 24 - available 9:30 am to 1:00 pm', 'daily', 'August', \"Dec. '95\", \"Dec. '95\", 'today', 'tomorrow', 'Wednesday, July 31, 2013', 'the 16th of August', 'Monday, January 14, 2013', 'Friday', 'Friday', 'the first two days', '17 days ago', 'Nov. 8, 2000', 'today', 'the end of the month', 'five-year', 'May 16th', '7', 'quarterly', 'April 16', '2001', 'the school year', 'Weekly', 'Monday, April 23rd', 'Weekly', 'Monday, January 29', 'Thursday, June 14, 2001', 'St 65', 'Friday', 'Friday', 'Friday', 'Christmas', 'July', 'tomorrow', 'tomorrow', 'August', 'the week of April 16', 'April 16, 17', '18 or 19th', 'today', 'Thursday', 'tomorrow', 'today', 'the 13th and 14th', 'tomorrow', 'Monday', 'another month', 'weeks', 'mid-May', 'today', 'tomorrow', 'this week', 'next week', 'this week', 'the day', 'tomorrow', 'today', 'this weeks', 'Monday', 'the past few winters', 'tomorrow', 'tomorrow', 'today', 'tomorrow', 'this week', 'next week', 'next week', 'early November', 'tomorrow', 'this season', 'yesterday', 'a day', 'days', 'today', 'quarter this year', 'Monday', 'Tuesday', 'Monday', 'tomorrow', 'Thursday', 'today', 'tomorrow', 'Tuesday', 'today', 'next week', 'several business days', 'today', 'today', 'half days', 'next week', 'tomorrow', 'Wed of next week', 'this summer', 'Nov. 29', 'a couple of weeks', 'today', 'yesterday', 'Wednesday, October 25', 'later this week', 'next week', 'the day', 'tomorrow - deal 169576', 'tomorrow', 'last year', 'Friday', 'July', 'no quarter', 'the next 60-90 days', 'one month', 'today', 'last week', 'today', 'this week', 'all day', 'tomorrow', 'next week', 'the week', 'tomorrow', 'about 10 days', 'this week', 'today', 'February', 'monthly', 'next week', 'every day', 'the next couple of hours', 'Friday', 'end of day', 'today', 'Monday', 'tomorrow', 'Monday', 'today', 'today', '9 years', 'the next ten days', 'January', 'December', 'daily', 'GoHealthInsurance', 'January 16, 2013 to January 18, 2013', 'today', '10010', 'the end of April', 'tomorrow', 'two year', 'this year', 'monthly', 'every month', 'this month', '2 Weeks', 'the 13th', 'the 12th', 'the weeks', 'today', 'Halloween', 'next week', 'December', 'NaNoWriMo 2013', 'the last 6 months', 'each day', 'Monday', 'Wednesday', 'this week', 'July', 'June 2011 13', 'Day 5', 'June', 'an awesome month', 'the last several months', 'Thursday', 'the weekend', 'daily', 'Half-Year', 'July 11', '380571', 'LAST DAY', 'LAST DAY', 'Last Week', 'Last year', 'every week', 'Wednesday', 'Saturday', 'the 14th of May.', 'a week', 'Aug. 3, 2000', 'March 2011 12: Period Day 1 13:', '7 28', 'Day 1', 'Wednesday, December 31st', 'Monday', 'Monday', 'Monday through Friday', 'Monday, April 16th', 'Monday, August 6th', 'Monday, June 4th', 'Monday', 'May 14th', 'this week', 'several weeks ago', 'Feb. 20, 2001', 'Tuesday', 'the first quarter', 'January', 'today', 'this week', 'Feb 26, 2013', 'Friday, October 26, 2001', 'July 3, 2012', 'May 3rd', 'November 3', 'the days', 'Saturday', '30 days', 'One Week to Christmas', 'One day', 'Friday, May 25', 'tomorrow', 'the last several years', 'a few weeks ago', 'Monday', 'Tuesday, October 2 4, 2000', '1 year', 'the week of the 11th', 'tomorrow', 'Monday', 'monthly', 'today', 'Friday', 'Tuesday, June 12, 2001', '7 days', 'every month', 'Thursday', 'next week', 'Saturday', 'HE15-19', 'Monday', 'next week', 'Friday', 'Saturday January 19, 2002', 'Saturday', 'Monday', 'Sunday', 'Friday, April the 27th', 'Monday', 'tomorrow', 'tomorrow', 'last Thursday', 'September 4, 2011', 'Wednesday', 'the fall', 'Thursday', 'Sunday 28 August 2011', 'hundreds of years ago', 'the football season', 'tomorrow', 'yesterday', 'this year', 'tomorrow', 'Tomorrow', 'August 21, 2001', 'next summer', 'today', 'tomorrow', 'today', 'Monday, December 16th, 2013', 'tomorrow', 'Friday the 15th', 'Nov. 15th', 'Dec. 1', 'Wednesday', 'Wednesday', 'this week', 'Friday', 'next week', 'this week', 'yesterday', 'tomorrow', 'tomorrow', 'tomorrow', 'Wednesday', '33462', '33464', '33491', '33492', 'Feb. 8', 'Wednesday, August 28th', 'yesterday', 'the end of next week', 'August 18th', 'Sunday, July 14th', 'Four Weeks', '4 Weeks', '1-Hour', 'a day', 'next day', 'nightly', 'tomorrow', '2001', 'April 2010', 'this week', 'Sunday', 'tomorrow', 'today', '1989', '1989', 'October 17, 2013', 'tomorrow', 'next week', 'next week', 'This Friday', 'Saturday', '251415618', 'today', 'Friday', 'July 28 - August 4, 2001', 'every single day', 'the weekend', 'summer', 'This month', 'later this quarter', 'This week', '72', 'This week', 'Halloween', 'This week', 'This weekend', '2001', '2001', 'This year', 'today', '3:45pm - 10:00pm', 'Today', 'Today', 'Today', 'Today', 'Today', 'Today', 'Tomorrow', 'Wednesday', 'Thursday', 'Friday', 'Tomorrow', 'this week', 'year 2001', 'this week', 'today', 'Two Weeks', 'the next couple of weeks', 'this summer', '6 years', 'Thursday', 'Thursday & Friday', 'Thursday, January 25, 2001 08:36 AM?ET', 'Sept. 11', 'Thursday, September 19th', 'each day', 'daily', 'Saturday', 'between the days', 'July', 'Friday', 'Thursday', 'today', 'tomorrow', 'Thursday', 'later this week', 'this month', 'daily', 'monthly', 'this week', 'next week', 'Wednesday', '01&prudent', 'the past few months', \"this current year's\", 'a couple of days', 'Thursday', '2014-07-01', 'this week', 'next week', 'Wednesday', 'Labor Day', 'Friday of this week', 'Monday', 'this weekend', 'Monday 5 November', '19.30', '1201', '7 FREE days', 'this day', 'tomorrow', 'these last few weeks', 'Wednesday, August 2nd', 'last week', 'January', 'the new day', 'summer', 'maybe weeks', 'the coming decade', 'the coming decade', 'year', 'winter', 'the coming year', 'the next 3 business days', 'four weeks', 'the winter', 'the next week', 'Tuesday', 'a couple of weeks', 'tomorrow', 'daily', '1 Dec 2013', '30 day', 'Sunday 29 April 2012', 'January 31, 2013', 'Monday', 'today', 'today', 'Thursday, 31st January', 'the 29th', 'this week', 'today', 'today', 'Tuesday', 'each day', 'this week', 'may 1', 'may 2', '978/281-0744', '2 weeks', 'next week', 'Sept. 11', 'today', 'yesterday', 'weekly', '7 days', 'tomorrow', 'Sunday', 'another 30 days', 'Friday', 'Friday', 'Thursday June 20', 'January', 'Monday, October 8, 2001', 'the month of November', 'Sept. 20', 'tomorrow', 'Thursday', 'Friday', 'today', 'Sunday, December 8th, 2013', 'Monday, November 11th', 'Wednesday, September 25th', '415)244-6094', 'tomorrow', 'this June', 'Tuesday', 'the end of September', 'September 25', 'Thursday', '14 day', 'today', 'today', 'Halloween', 'today', 'tomorrow', 'tomorrow', 'this week', 'Tuesday', 'today', 'Monday', 'the day on Monday or', 'Tuesday', 'Saturday', 'Monday', 'Friday', 'tomorrow', 'Friday', 'this school year', 'This week', 'Wednesday', 'Wednesday', 'each day', '2001', 'up to 3 years', 'Thursday', 'today', 'Monday', 'Friday', 'this week', 'Tuesday', 'this Sunday', 'today', 'the beginning of the month', 'Saturday, March 25', 'this weekend', '713/853-5984', '713/853-6440', 'weekly', 'tomorrow', 'the past several months', 'Saturday', 'December 7', 'this week', 'Monday', 'Tuesday, January 8th', 'next week', 'Thursday', 'Friday', 'tomorrow', 'this weekend', 'Thursday, March 22', 'tomorrow', 'tomorrow', 'next week', 'tomorrow', 'this week', 'tomorrow', '1130', 'the weekend', 'today', 'Friday', 'daily', 'October 11th', 'this week', 'the 18th', 'Friday', 'Monday', 'November', 'this week', 'Tuesday', 'Tuesday', 'Wednesday', 'Monday', 'tomorrow', '2 day', 'Friday', 'Monday', 'last weekend', 'Monday', 'Jan 2000', 'yesterday', 'next week', 'that day', 'Tuesday, February 20, 2001', 'Tuesday', 'the weekend', '87-7449', 'today', 'Friday', '2001', 'tomorrow', 'July', 'Sunday', 'tomorrow', 'a year anniversary', 'the following week', 'today', 'early next week', 'March', 'March 28th', 'next week', 'tomorrow', 'tomorrow', 'tomorrow', 'Friday', 'next week', 'Monday, June 4th', 'all day', 'tomorrow', 'tomorrow', 'the end of the day', 'December 9', 'next Monday', 'tomorrow', 'the week', 'tomorrow', 'Thursday', 'today', 'this weekend', 'next week', 'next week', 'this weekend', 'the day and tomorrow', 'Thursday, November 29th', 'between now and Thursday', 'the week', 'next week', 'November 5th', 'today', 'this weekend', 'next week', 'this week', 'the next week', 'a couple days this week', 'next week', 'this week', 'tomorrow', 'a few weeks ago', 'Sunday', 'Monday', 'next week', 'Thursday', 'Wednesday', 'Thursday', 'this week', 'today', 'tomorrow', '3-0977', 'last Thursday', 'tomorrow', 'Thursday', 'Thursday', 'Friday', '3 nights', 'sunday', 'March', '21 years old', 'December', 'today', '251408768', 'Tuesday, August 27th, 2013', 'Friday', 'Friday', 'May 6 and May 24', 'November 11th and December 2nd, 2013', 'November 1, 2001', 'Monday, November 20th', 'a couple weeks', 'tomorrow', 'Monday, Jan. 22nd', 'Wednesday, Jan. 24th', 'today', 'the next few business days', 'the next couple of weeks', 'Sunday earlier', 'August 17', 'Thursday', 'next week', 'last week', 'XXXXXXXXX2159', 'Wednesday', 'April 12th', '2:30pm', 'March', 'Monday', '2001', 'Thursday', 'Friday', 'Monday', 'Tuesday', 'tomorrow', 'daily', 'tomorrow (Sunday', 'today', 'next week', 'every Friday', 'Wednesday', 'Tuesday', 'tomorrow', 'Friday', 'later this week', 'a few days', 'every week', 'this week', 'Sunday', 'Thursday', 'April 30', 'tomorrow', 'Friday', 'Monday', '2001', 'this next week', 'Saturday', 'Sunday', 'Tuesday', 'next week', 'next Monday', 'tomorrow', 'a later date', 'tomorrow', 'Friday', 'tomorrow', 'today', 'next week', 'last week', 'Monday', 'next Wednesday', 'Thursday', 'Saturday', '2000', 'Friday', 'two weeks', 'quarterly', 'Monday', 'late Oct.', 'today', 'tomorrow', 'tomorrow', 'Friday', 'the next few days', 'next week', 'annual', 'May 12, 2001', 'tomorrow', 'Monday', 'tomorrow', 'Monday', 'next week', 'Sunday', 'Thursday', 'Wednesday', 'Monday', 'Wednesday', 'Monday', 'today', 'Monday', 'next week', '10/31', 'Monday, December 18', 'Intra-month', 'next Monday', 'the end of the week', 'tomorrow', 'last week', 'Wednesday', 'next week', 'Wednesday, Dec. 13th', 'tomorrow', 'summer', 'April', 'May', 'summer', 'next week', 'Monday', 'Monday', 'tomorrow', 'Friday', 'Monday', '627-8172', 'next Tuesday/Wednesday', 'Thursday', 'between now and Monday', 'Friday', 'a day', 'Sunday', 'December', 'today', 'Monday', 'next week', '301/652-7877', 'tommorrow', 'today', 'tomorrow', 'Monday', 'Saturday', 'Friday', 'Friday', 'the next week', 'March 12', 'this week', 'last Sunday', 'Labor Day', 'the 17th', 'today', 'Christmas', 'tomorrow', 'season', 'season', 'today', 'tomorrow', 'Christmas', 'Friday, August 4th', '26301', 'this coming Monday', 'every other week', 'a week', 'tomorrow', 'monthly', 'last week', 'Thursday', '7-10', '1100', 'Monday', 'two days', 'Wednesday', 'Thursday', '2014', 'Tuesday, September 30th', 'January', 'these days', 'this week', 'Thursday', 'next week', 'early next week', 'Monday', '2000', 'this week', 'yesterday', 'the weekend', 'Monday', 'next week', 'the following week', 'next week', 'Tuesday', 'this week', 'the end of January', 'mid January', 'Wednesday', 'Thursday', 'early October', 'the next couple weeks', 'Friday', 'early next week', 'today', 'this weekend', 'this weekend', 'next summer', 'today', 'Week 2013', 'the next month', 'April 16', 'Monday', 'today', '15s', 'this week', 'today', 'next Monday', 'Thursday', 'all next week', 'next week', 'the next many months', 'September 5, 2000', 'tomorrow', 'weekly', 'Friday', 'weekly', 'this week', 'Dec. 17th', 'Thursday', 'this weekend', '2000', 'year', 'tomorrow', 'Thursday, November 28', 'Monday', 'Saturday', 'tomorrow', 'that day', 'this week', 'monthly', 'the 8:30 call tomorrow', 'next week', 'next year', 'this week', 'tomorrow', 'the next few weeks', 'Sunday', 'Saturday', 'April 11', 'same week', 'Saturday', 'Tuesday the 24th', 'Sunday', 'the next couple of days', 'Monday', 'next week', 'the weekend', 'this weekend', 'next Thursday', 'the last several weeks', 'Thursday', 'tomorrow', 'Sunday', 'tomorrow', 'the 25th - 28th', 'the 28th', 'tomorrow', 'Wednesday', '37323']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI8bF-H7B7Zd"
      },
      "source": [
        "d) Which one of the two approaches was better? Why do you think so? Would you use any of these approaches? Or a different one?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KzYwIiPCIVP"
      },
      "source": [
        "Based on the results above I feel using the Spacy approach does a better job at identifying every single possibility of date entity. On the other hand the regex method has its own merits in terms of identifying precise formats of date. It offers superior control over handling noise unlike the Spacy method which returns just about anything resembling a datetime entity. This advantage of regex comes with a pinch of salt too as it requires manual analysis of the dataset first to identify different formats or styles in which a date string can exist. This makes it prone to missing some edge cases that may escape the eye. I find it open to interpretation as to which approach is better as it depends on how specific the format of the extracted dates should be. \n",
        "In terms of applicability a wiser method in my opinion is to combine usage of both where first we let the spacy identify the date entity in the dataset and return a list. Then we can extract specific patterns from this list based on requirement using regular expressions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xio6XIkm030x"
      },
      "source": [
        "5. Train an LSTM model to classify the Cornell Movie Review data\n",
        "using the polarity_dataset V2.0. You can use the code for class 19, but take a note that\n",
        "you will have to adapt some of the parameters like: Review size = 450, epochs=5. You will use\n",
        "85% of the dataset for training, and 15% for testing. Once you build the model, please display\n",
        "the sklearn classification report. What are you noticing here? Anything unexpected? How does\n",
        "this model compare to the one built with the IMDB dataset in class? Any ideas on how to\n",
        "improve it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a4Ev_p60tb0",
        "outputId": "0d5f2351-603a-4f14-d966-b765fe1d5bb5"
      },
      "source": [
        "# All the imports!\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import os\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Supress deprecation warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIabXeet1GtP",
        "outputId": "abcfcad6-8321-43dc-b1fb-b7e14a4f5539"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK8qNiK92LzB"
      },
      "source": [
        "# tar –xvzf /content/drive/MyDrive/review_polarity.tar\n",
        "# %%bash\n",
        "# !tar –xvf /content/drive/MyDrive/review_polarity.tar.gz #–C '/home/user/destination'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY1OVCMu7tSA",
        "outputId": "ef71c2bd-ed09-4288-ec18-ba4838cec050"
      },
      "source": [
        "directory='/content/drive/MyDrive/review_polarity/txt_sentoken'\n",
        "collection=[]\n",
        "doc_name=[]\n",
        "label=[]\n",
        "for dir in os.listdir(directory):\n",
        "  print(dir)\n",
        "  if (dir == \"neg\"):\n",
        "    dir1=directory+'/neg/'\n",
        "    print(dir1)\n",
        "    for filename in os.listdir(dir1):\n",
        "      if (filename.endswith('.txt')):\n",
        "        string1=(open(os.path.join(dir1, filename)))\n",
        "        collection.append(string1.read())\n",
        "        doc_name.append(filename.rstrip('.txt'))\n",
        "        label.append(0)\n",
        "  elif (dir == \"pos\"):\n",
        "    dir1=directory+'/pos/'\n",
        "    print(dir1)\n",
        "    for filename in os.listdir(dir1):\n",
        "      if (filename.endswith('.txt')):\n",
        "        string1=(open(os.path.join(dir1, filename)))\n",
        "        collection.append(string1.read())\n",
        "        doc_name.append(filename.rstrip('.txt'))\n",
        "        label.append(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neg\n",
            "/content/drive/MyDrive/review_polarity/txt_sentoken/neg/\n",
            "pos\n",
            "/content/drive/MyDrive/review_polarity/txt_sentoken/pos/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiC50f5P91xu"
      },
      "source": [
        "data_set=pd.DataFrame(list(zip(doc_name, collection, label)), columns =['doc_name', 'text', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "QNrYNZHd966j",
        "outputId": "41f5cf0b-171b-4547-fd05-f00044fd2c0d"
      },
      "source": [
        "data_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_name</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cv000_29416</td>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cv001_19502</td>\n",
              "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cv002_17424</td>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cv003_12683</td>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cv004_12641</td>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      doc_name                                               text  label\n",
              "0  cv000_29416  plot : two teen couples go to a church party ,...      0\n",
              "1  cv001_19502  the happy bastard's quick movie review \\ndamn ...      0\n",
              "2  cv002_17424  it is movies like these that make a jaded movi...      0\n",
              "3  cv003_12683   \" quest for camelot \" is warner bros . ' firs...      0\n",
              "4  cv004_12641  synopsis : a mentally unstable man undergoing ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVFX195RB1Co"
      },
      "source": [
        "train_a, test_a = train_test_split(data_set, test_size=0.15, random_state=12345)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzobON2uAdcH"
      },
      "source": [
        "X=list(train_a['text'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-yoEcoqA8X6"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "enc=[]\n",
        "tokenizer=Tokenizer(filters='')\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "enc=tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SlbbxzYA9Be",
        "outputId": "c718663c-c3fb-4491-f3bf-268f19c7cecc"
      },
      "source": [
        "print(enc[60])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[142, 197, 1, 1369, 3057, 1, 708, 45, 861, 52, 4938, 142, 969, 52, 222, 2856, 1, 4683, 17266, 1, 5, 4, 848, 6, 1833, 142, 519, 27, 567, 17267, 5, 436, 27, 1690, 29004, 142, 17268, 52, 2610, 29005, 13, 222, 2856, 12, 680, 18, 129, 337, 19, 17269, 92, 493, 5486, 9, 1156, 1033, 272, 2, 6720, 6, 2, 6708, 7260, 2338, 3, 116, 1855, 7, 6363, 22, 2, 2376, 443, 27, 2793, 28, 955, 17, 2, 379, 3, 345, 94, 72, 6, 2, 695, 140, 2, 837, 6, 602, 1833, 5, 118, 111, 8796, 85, 3, 21338, 5, 644, 522, 52, 29, 101, 1281, 7614, 3, 21, 5565, 6, 197, 5, 1036, 17270, 1580, 3, 2156, 133, 1560, 20, 19, 397, 1, 5, 1652, 1, 9, 366, 426, 2, 1422, 6, 424, 251, 17, 4, 622, 3, 21, 2533, 6, 2, 19, 91, 5837, 45, 1054, 28, 805, 71, 3, 21, 335, 6, 41, 2, 8208, 23, 212, 22, 2, 937, 1, 597, 222, 2856, 16, 2, 7683, 1052, 3, 321, 29, 76, 875, 1254, 20, 19, 7, 370, 341, 17, 4, 764, 8209, 1, 286, 245, 95, 7, 948, 4, 356, 6, 605, 3, 29006, 1, 48, 3302, 522, 52, 29007, 6, 29008, 21, 2517, 328, 29, 1281, 20, 19, 34, 1, 11, 141, 125, 4, 197, 1, 2, 19, 91, 104, 28, 805, 71, 7, 427, 3, 3228, 133, 1560, 1396, 17271, 7, 2, 2, 3224, 11, 4, 197, 441, 63, 102, 40, 622, 3, 376, 261, 2, 30, 1, 622, 4, 224, 1, 685, 2, 1998, 5, 184, 213, 15, 40, 3, 29009, 8, 32, 47, 11, 3, 82, 352, 2, 289, 916, 45, 57, 29, 76, 86, 3316, 15, 2, 6708, 7260, 2338, 3, 82, 368, 780, 2038, 57, 76, 631, 7, 2, 87, 6, 2, 19, 3, 89, 72, 2562, 1, 29, 368, 780, 3070, 45, 57, 76, 631, 7, 2, 87, 3, 21, 197, 6, 2, 19, 3931, 172, 2856, 1, 18, 79, 1, 5, 2, 19, 25, 680, 7, 1156, 1033, 3, 82, 406, 11, 2856, 8, 33, 6, 2, 2241, 1607, 231, 9, 2, 759, 1396, 3, 116, 8, 1242, 6828, 193, 3802, 5, 14615, 3, 82, 846, 25, 38, 237, 3286, 28, 710, 2288, 17, 18, 155, 9, 12882, 14670, 3, 21, 83, 87, 23, 428, 374, 9, 4, 120, 15, 58, 765, 7, 18, 4718, 798, 1, 309, 1, 141, 2, 235, 1, 2856, 8, 200, 32, 38, 2, 1907, 6, 2, 19, 3, 21, 30, 8, 101, 2, 71, 6, 2, 602, 1833, 1, 4220, 31, 44, 23, 5, 57, 44, 275, 1, 381, 4, 1066, 112, 38, 107, 1190, 14, 117, 41, 151, 3, 82, 408, 2, 451, 2532, 134, 1242, 1047, 3, 240, 1439, 7, 2900, 14, 46, 1, 44, 1439, 7, 955, 36, 2, 3584, 6, 53, 162, 3, 505, 14, 1465, 17272, 154, 9, 1, 597, 15, 2, 1133, 1, 5, 2, 4306, 6, 2, 65, 3, 339, 2, 197, 7684, 22, 2856, 1, 5, 2, 528, 22, 2, 3257, 1, 81, 34, 4, 139, 694, 6, 29010, 3, 4939, 1889, 6, 2, 6120, 23, 1120, 9, 4, 1502, 764, 3, 308, 487, 8, 4, 120, 112, 114, 23, 1300, 243, 83, 17, 2, 2, 195, 14671, 5, 17273, 6, 1309, 9, 4, 6829, 1204, 3, 219, 40, 187, 45, 14, 2, 2794, 6, 1964, 10391, 150, 1199, 7, 26, 2, 3538, 17, 4, 197, 1, 24, 14, 384, 158, 3, 1044, 328, 29, 47, 20, 19, 8, 11, 29, 47, 21339, 638, 610, 137, 3, 308, 6, 131, 941, 105, 7, 149, 261, 8, 918, 2966, 36, 4361, 544, 3, 42, 13, 718, 29, 217, 32, 203, 14, 34, 33, 6, 131, 941, 137, 1, 24, 33, 6, 131, 941, 7, 94, 3, 12, 339, 17269, 92, 3890, 320, 152, 1, 133, 105, 47, 14, 134, 1, 5, 17269, 92, 21340, 635, 16, 4038, 2727, 7, 2, 17274, 25, 1631, 3, 321, 239, 29, 76, 47, 7, 1254, 7614, 7, 3460, 341, 17, 4, 64, 1, 1502, 71, 3, 97, 175, 4, 2374, 19, 47, 133, 83, 1560, 24, 28, 805, 1, 21341, 46, 1, 19, 45, 180, 114, 15, 180, 513, 667, 9, 28, 428, 774, 95, 3, 21342, 92, 42]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW8Js_zvCnJv"
      },
      "source": [
        "#setting the max_review_len to 450\n",
        "max_review_len=450\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9arPrqOkBEK1"
      },
      "source": [
        "X= sequence.pad_sequences(enc, maxlen=max_review_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLTDf2KRBJwR",
        "outputId": "3f48d57a-7c36-4693-965e-f87a01fcded6"
      },
      "source": [
        "X[60].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(450,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkghRwrSBQO_"
      },
      "source": [
        "train_a.insert(3,\"encoded_list\", X.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlbrxgfrBQwv",
        "outputId": "2883a821-72d5-4b5a-9f6d-7909cec6fd99"
      },
      "source": [
        "# designing the LSTM model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = vocab_size, # The size of our vocabulary \n",
        "        output_dim = 32, # Dimensions to which each words shall be mapped\n",
        "        input_length = max_review_len # Length of input sequences\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.LSTM(\n",
        "        units=32 # 32 LSTM units in this layer\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1, # Single unit\n",
        "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
        "    )\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 450, 32)           1660480   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 450, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,668,833\n",
            "Trainable params: 1,668,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "St_yD6lHBXU2",
        "outputId": "022d07a9-a87a-4f58-be82-cc3db253c11a"
      },
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAJzCAYAAACh2LArAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzda1hUV5Y//m9BFdSF4uINaBDFQiEqJhrNT4g2nTYhURsEL5EYE00eCTEaRA2NgCgKGBUHGQxMJpFgj6ZFVB6woyRpddAmEse0GpFMK+IFxAvgjVshBaz/C/9VY1mAFBRVoOvzPLzIPrv2WXUOWR722WcdARERGGOM9aS9ZqaOgDHGngecbBljzAg42TLGmBFwsmWMMSMQdneAwsJCJCUlGSIWxhjrlfbu3dvtMbp9ZVteXo59+/Z1OxDW837++Wf8/PPPpg6jT7l+/Tr/fj/HDHn+u31lq2aIzM961pw5cwDwudJHVlYW5s6dy8fsOaU+/4bAc7aMMWYEnGwZY8wIONkyxpgRcLJljDEj4GTLGGNGwMmW6e3QoUOwsbHB3/72N1OH0it9/PHHEAgEmp/58+fr9Dl8+DAiIyOxf/9+DBs2TNP3vffe0+nr6+sLuVwOc3NzjBo1CqdPnzbG1zCYxsZGeHh4YPXq1Vrt8fHxWsdJ/TN69GidMQoKCvDqq69CKpXC0dERERERePjwoWb7gQMHsGnTJrS0tGh9LicnR2vsAQMG9MyX7AROtkxvXCju6fr164e8vDxcuHAB6enpWtvWrl2LlJQUREVFYdasWbh8+TIUCgX69++PXbt24eDBg1r9f/zxR+zduxd+fn4oLi7GuHHjjPlVui06OhoXLlzo8ueLi4vh6+uLKVOmoKqqCtnZ2fjmm2+wePFiTR9/f3+IxWJMmTIF9+/f17TPmDED169fx/HjxzFt2rRufY/u4mTL9DZ9+nQ8ePAAfn5+pg4FSqUS3t7epg5Dh0QiwVtvvYURI0bA0tJS075x40ZkZmYiKysLcrlc6zMpKSkwMzNDSEgIHjx4YOyQe8SJEydw/vz5drfv3LkTRKT182T/uLg4ODg4YN26dZDJZPDy8kJERAR27NiBf/3rX5p+y5Ytw4svvohp06ahubkZACAQCODk5ITJkydj+PDhPfMlO4mTLevT0tPTUVlZaeowOuXSpUuIiYnBunXrIBaLdbZ7e3sjLCwMFRUV+Oyzz0wQoWEplUqEh4cjOTm5y2M0Nzfj4MGD8PHxgUAg0LRPnToVRITc3Fyt/rGxsTh79my39tlTONkyvRQUFMDFxQUCgQBffPEFACAtLQ0ymQxSqRS5ubmYOnUqrK2t4ezsjN27d2s+m5KSArFYjEGDBuHjjz+Go6MjxGIxvL29cfLkSU2/0NBQWFhYwMHBQdO2ZMkSyGQyCAQCVFdXAwDCwsKwcuVKlJaWQiAQwM3NDQDw/fffw9raGgkJCcY4JJ2WkpICIoK/v3+7feLj4zFixAhs374dhw8f7nA8IkJSUhJeeOEFWFpaws7ODgEBAVpXe509NwDQ0tKCNWvWwMXFBRKJBGPGjMGePXu6/H2jo6OxZMkSDBw4sMtjXL58GXV1dXBxcdFqVygUAIBz585ptdvZ2cHHxwfJycm9brqLky3Ty6RJk3DixAmttk8++QTLly+HUqmEXC7Hnj17UFpaimHDhiE4OBgqlQrAoyS6cOFCNDQ0YNmyZbh69SpOnz6N5uZmvPHGGygvLwfwKCm9/fbbWvtITU3FunXrtNqSk5Ph5+cHhUIBIsKlS5cAQHOTpLW1tUeOQVcdPHgQ7u7ukEql7faRSCTYsWMHzMzMEBwcjPr6+nb7xsbGIjIyEtHR0aisrMTx48dRXl6OyZMn4/bt2wA6f24AYNWqVdi8eTO2bt2Kmzdvws/PD/PmzcMvv/yi93f96aefUFpainnz5nXYLzIyEnZ2drCwsICrqysCAgJw6tQpzfZbt24BgM6Ui1gshkQi0XzPx40dOxYVFRX49ddf9Y67J3GyZQbl7e0Na2trDBw4EEFBQaivr0dZWZlWH6FQqLkaGzlyJNLS0lBbW4uMjAyDxDB9+nTU1NQgJibGIOMZQn19Pa5cuaK5IuuIl5cXli9fjqtXr2LVqlVt9lEqlUhKSsLMmTMxf/582NjYwNPTE19++SWqq6vx1Vdf6Xymo3PT2NiItLQ0BAYGYtasWbC1tcXq1ashEon0Pi9KpRJhYWFIS0vrsN+CBQtw4MABlJeXo66uDrt370ZZWRl8fHxQXFwMAJoVB+bm5jqfF4lEUCqVOu3qudmioiK94u5pnGxZj7GwsAAArauntowfPx5SqVTrz99nTWVlJYiow6vax8XHx8Pd3R2pqakoKCjQ2V5cXIy6ujqMHz9eq33ChAmwsLDQmpZpy5Pn5sKFC2hoaNBadiWRSODg4KD3eYmKisJHH30EJyenDvsNHjwYY8eOhZWVFSwsLDBx4kRkZGRAqVQiNTUVADRz2+obXo9ramqCRCLRaVcf47auek2Jky3rFSwtLVFVVWXqMHpMY2MjAGitTOiIWCxGRkYGBAIBPvzwQ50rOPXyJisrK53P2traora2Vq/41NMVq1ev1lqXeu3aNTQ0NHR6nIKCAhQVFWHRokV67V/N09MT5ubmuHjxIgBo5u1ramq0+jU0NKCxsRGOjo46Y6gTsPqY9xacbJnJqVQq3L9/H87OzqYOpceoE8CTi+474uXlhRUrVqCkpARxcXFa22xtbQGgzaTalWOpvom1detWnaVYhYWFnR4nPT0dR44cgZmZmSZhq8dOSEiAQCDocA64tbUVra2tmn+UXF1dIZfLce3aNa1+6vn5MWPG6IzR1NQEAG1e9ZoSJ1tmcvn5+SAiTJw4UdMmFAqfOv3QlwwaNAgCgUDv9bNxcXHw8PDAmTNntNpHjx4NKysrncR18uRJNDU14eWXX9ZrP4MHD4ZYLMbZs2f1+tyTMjIydJK1+i+W6OhoEJFm6uPNN9/U+fypU6dARPDy8gLw6Pdg2rRpOH78uNYNz7y8PAgEgjZXdqiPsb29fbe+i6FxsmVG19rainv37qG5uRnnzp1DWFgYXFxcsHDhQk0fNzc33L17Fzk5OVCpVKiqqtK5ugEePal148YNXL16FbW1tVCpVMjLy+t1S7+kUimGDRuG69ev6/U59XTCkzeIxGIxVq5ciezsbOzatQs1NTUoKirC4sWL4ejoiJCQEL3388EHH2D37t1IS0tDTU0NWlpacP36ddy8eRMAEBQUBHt7e4M9LlxRUYHMzEzcv38fKpUKhYWFWLRoEVxcXLSeDouJicHt27exdu1a1NfXo7CwEImJiVi4cCHc3d11xlUfY09PT4PEaTDUTXv27CEDDMOMYPbs2TR79uxujbFt2zZycHAgACSVSsnf359SU1NJKpUSABo+fDiVlpbSV199RdbW1gSAhgwZQhcvXiQiopCQEBKJROTk5ERCoZCsra0pICCASktLtfZz584deu2110gsFpOrqyt9+umnFB4eTgDIzc2NysrKiIjo9OnTNGTIEJJIJDRp0iS6desWHTp0iORyOcXHx3fruxJ17fc7JCSEnJycdNpDQ0NJJBJRQ0ODpi07O5sUCgUBoAEDBtDSpUvbHDM8PJxmzJih1dba2kqJiYk0fPhwEolEZGdnR4GBgXThwgVNH33OzcOHDykiIoJcXFxIKBTSwIEDadasWVRcXExERIGBgQSA1qxZo9fxqKqqIgAUHR2t1b5y5UpSKBQkk8lIKBSSs7MzBQcH040bN3TGOHbsGL3yyitkaWlJjo6OFB4eTo2NjW3ub/r06eTk5EStra1a7cuWLaP+/fvrFbsB81sWJ9vniCGSbXeFhIRQv379TBqDPgyZbEtKSkgoFNLOnTsNFZ5RtbS00OTJkyk9Pd3UobSrurqaxGIxbdmyRWebqZMtTyMwo9PnJlFfpVQq8cMPP6CkpERzw8bNzQ3r16/H+vXrUVdXZ+II9dPS0oKcnBzU1tYiKCjI1OG0KzY2Fi+99BJCQ0MBPHrK7saNGygoKNDcVDMVTraM9YC7d+9qCtF8+OGHmvbIyEjMmTMHQUFBfarYTH5+Pvbv34+8vLxOrxU2tqSkJJw9exaHDh2CSCQCAOTm5moK0TxZTc3YjJ5sf/75Z7zwwguapSH29vaIj483dhgderLGqIODQ5s1SZl+oqKikJGRgQcPHsDV1fWZfUX4l19+qXU3fteuXVrbExISEBoais8//9xEEepvypQp+Pbbb7XqVfQmubm5ePjwIfLz82FnZ6dpDwgI0DoX6roapiAg6l61BvWrfvUd5q233sIPP/yAe/fuadYM9jZubm6orq7Wqo/Zl/GrzPXX1d9v9mww4Pnfy9MI6L01URljzw5OtuhbNVEZY31Tr0m2va0mqr7+8Y9/YOTIkbCxsYFYLIanpyd++OEHAMCiRYs0878KhULzNNAHH3wAqVQKGxsbHDhwAEDHNUU3b94MqVQKuVyOyspKrFy5Ek5OTt165QhjzEi6u3isq+vQ3nzzTQJA9+7d07RFR0cTADpy5Ag9ePCAKisrafLkySSTyaipqUnTLyQkhGQyGf3222/U2NhIxcXFNGHCBJLL5ZrF7kRE7777Ltnb22vtNzExkQBQVVWVpm3WrFmkUCh0YlQoFGRjY9Op77N3716KjY2lu3fv0p07d2jixIlaa/pmzZpF5ubmVFFRofW5efPm0YEDBzT//dlnn5GlpSXt27eP7t27R1FRUWRmZkanTp3SOkbLli2jbdu20cyZM+l///d/OxVjb1hn29fwOvLn2zO/zrY31ETV1+zZs7F27VrY2dmhX79+8Pf3x507dzTPhS9evBgtLS1a8dXU1ODUqVOaF9HpU1N048aNWLp0Kfbv3w8PDw/jfVHGWJcITR3A0/TVmqjqdX7qBfx//OMfMWLECHzzzTeIioqCQCBAZmYmgoKCNM+9G7KmaHv27dun9S4n1jl8zFh39fpkqw9T1kQ9ePAgEhMTUVxcjJqaGp1/HAQCAT7++GOsWLECR44cweuvv47/+q//wrfffqvp83hN0dWrV2t9vq26nV0xceJELF++3CBjPQ8KCwuRnJzcrXdxsb5Lff4N4ZlJtsauiXr8+HH885//xPLly1FWVobAwEDMnDkT33zzDX73u99h27Zt+POf/6z1mYULFyIqKgrbt2/H4MGDYW1tjSFDhmi2P15TNCwsrEfidnZ21nm/F+tYcnIyH7PnGCfbJxi7Juo///lPyGQyAI/edaRSqfDJJ59g2LBhANr+s9POzg5z585FZmYm5HI5goODtbYbqqYoY6z36ZU3yDqjp2uitkelUuH27dvIz8/XJFv1a5YPHz6MxsZGlJSUtPsOqMWLF+Phw4f47rvv4Ofnp7WtMzVFGWN9VHfXM+i7NOLnn3+mUaNGkZmZGQEgBwcHSkhI6FU1Uf/jP/5DU2O0o5/s7GzNviIiIqhfv35ka2tLc+bMoS+++IIAkEKh0FqORkQ0duxYioyMbPP4dFRTdNOmTSSRSAgADR48WO9Sfbz0S3+89Ov59tzXs+1rNVGfNG3aNLp8+bLR98vJVn+cbJ9vz/w6287oSzVRH5+WOHfuHMRiMVxdXU0YEWPM2Ppssu1LIiIiUFJSgosXL+KDDz7QeVMqe7Z8/PHHWq8Db6s85+HDhxEZGalTzvO9997T6evr6wu5XA5zc3OMGjXKYO8AM5bGxkZ4eHjoLGeMj4/XOk7qn8fXmasVFBTg1VdfhVQqhaOjIyIiIvDw4UPN9gMHDmDTpk06F2E5OTlaYw8YMKBnvmQn9Llk2xdrokqlUnh4eOD1119HbGwsRo4caeqQWA/r168f8vLycOHCBaSnp2ttW7t2LVJSUhAVFYVZs2bh8uXLUCgU6N+/P3bt2qVT5PrHH3/E3r174efnh+LiYowbN86YX6XboqOju1W/o7i4GL6+vpgyZQqqqqqQnZ2Nb775RuulkP7+/hCLxZgyZYpWSdQZM2bg+vXrOH78uOZJTVPpc8l2w4YNePjwIYgIV65cwezZs00d0lPFx8ejpaUFZWVlOisQnjfGKGfZG0pmSiQSzZsaLC0tNe0bN25EZmYmsrKyIJfLtT6TkpICMzMzhISE9Km3OHTkxIkTOH/+fLvbd+7cqfPq8yf7x8XFwcHBAevWrYNMJoOXlxciIiKwY8cOrScrly1bhhdffBHTpk1Dc3MzgEdLMNVvahg+fHjPfMlO6nPJlvVtxihn2VtLZl66dAkxMTFYt24dxGKxznZvb2+EhYWhoqICn332mQkiNCylUonw8PBuPRTQ3NyMgwcPwsfHR2vt+tSpU0FEyM3N1eofGxuLs2fPGuxBBEPiZMs6RERISkrSFP2xs7NDQECA1hVFd8pZGqtk5vfffw9ra2skJCT06PHqSEpKCogI/v7+7faJj4/HiBEjsH37dhw+fLjD8TpzbjpbuhTouLxnV0RHR2PJkiWaJyO74vLly6irq9OsZVdTKBQAHt1wfpydnR18fHyQnJzc696uwcmWdSg2NhaRkZGIjo5GZWUljh8/jvLyckyePBm3b98G8CiJPPk4a2pqKtatW6fVlpycDD8/PygUChARLl26hNDQUCxcuBANDQ1YtmwZrl69itOnT6O5uRlvvPEGysvLu70P4P9Wr7S2thru4Ojp4MGDcHd37/CFiRKJBDt27ICZmRmCg4M19TLa0plz88knn2D58uVQKpWQy+XYs2cPSktLMWzYMAQHB2utlFm1ahU2b96MrVu34ubNm/Dz88O8efPwyy+/6P1df/rpJ5SWlmLevHkd9ouMjISdnR0sLCzg6uqKgIAAnDp1SrP91q1bAKAz5SIWiyGRSDTf83Fjx45FRUUFfv31V73j7kmcbFm7lEolkpKSMHPmTMyfPx82Njbw9PTEl19+ierqanz11VcG21dPl8ycPn06ampqEBMTY5Dx9FVfX48rV65orsg64uXlheXLl+Pq1atYtWpVm326cm46Kl2qT3nPp1EqlQgLC0NaWlqH/RYsWIADBw6gvLwcdXV12L17N8rKyuDj44Pi4mIA0Kw4UFfGe5xIJIJSqdRpV8/NFhUV6RV3T+Nky9pVXFyMuro6jB8/Xqt9woQJsLCwaPeRZEPobSUzu6uyshJE1OnXgMfHx8Pd3R2pqakoKCjQ2d7dc/Nk6VJDlveMiorCRx99BCcnpw77DR48GGPHjoWVlRUsLCwwceJEZGRkQKlUIjU1FQA0c9vqG16Pa2pqgkQi0WlXH+O2rnpNiZMta5d6CY2VlZXONltbW9TW1vbo/k1ZMtPQGhsbAUBrZUJHxGIxMjIyIBAI8OGHH+pcwRn63Dxe3vPxdanXrl1DQ0NDp8cpKChAUVERFi1apNf+1Tw9PWFubo6LFy8CgGaOvqamRqtfQ0MDGhsb2yw9qk7A6mPeW3CyZe1Sv2K+rf9xe7qcpbFLZvY0dQLQ58lHLy8vrFixAiUlJToPwhj63Dxe3vPJpViFhYWdHic9PR1HjhyBmZmZJmGrx05ISIBAIOhwDri1tRWtra2af5RcXV0hl8t1Ckip5+LHjBmjM0ZTUxMAtHnVa0qcbFm7Ro8eDSsrK53/OU6ePImmpia8/PLLmjZDl7M0dsnMnjZo0CAIBAK918/GxcXBw8ND85JQNX3OTWcYqrxnRkaGTrJW/3USHR0NItJMfbz55ps6nz916hSICF5eXgAenfNp06bh+PHjWjc38/LyIBAI2lzZoT7G9vb23fouhsbJlrVLLBZj5cqVyM7Oxq5du1BTU4OioiIsXrwYjo6OCAkJ0fTtbjnLni6ZmZeXZ9KlX1KpFMOGDcP169f1+px6OuHJG0T6nJvO7udp5T2DgoJgb29vsMeFKyoqkJmZifv370OlUqGwsBCLFi2Ci4uL1tNhMTExuH37NtauXYv6+noUFhYiMTERCxcuhLu7u8646mPs6elpkDgNprulbLgqUt/Rlapfra2tlJiYSMOHDyeRSER2dnYUGBhIFy5c0OrX1XKWt27d6vGSmbdu3aJDhw6RXC6n+Ph4vb5/V36/Q0JCyMnJSac9NDSURCIRNTQ0aNqys7M15TwHDBhAS5cubXPM8PBwmjFjhlZbZ86NPqVLOyrvSUQUGBhIAGjNmjV6HY+qqioCQNHR0VrtK1euJIVCQTKZjIRCITk7O1NwcDDduHFDZ4xjx47RK6+8QpaWluTo6Ejh4eHU2NjY5v6mT59OTk5O1NraqtW+bNkyrTded8ZzX2KRdU1vLbHYm0tmGjLZlpSUkFAo1LsOcW/R0tJCkydPpvT0dFOH0q7q6moSi8W0ZcsWnW2mTrY8jcB6hb5UMrMzlEolfvjhB5SUlGhu2Li5uWH9+vVYv3496urqTByhflpaWpCTk4Pa2loEBQWZOpx2xcbG4qWXXkJoaCiAR0/Z3bhxAwUFBZqbaqbCyZaxHnD37l1NIZoPP/xQ0x4ZGYk5c+YgKCioTxWbyc/Px/79+5GXl9fptcLGlpSUhLNnz+LQoUMQiUQAgNzcXE0hmierqRkbJ1tmUn2xZObTfPnll1p343ft2qW1PSEhAaGhofj8889NFKH+pkyZgm+//VarNkVvkpubi4cPHyI/Px92dnaa9oCAAK1zoa6hYQrPzNt1Wd+0YcMGbNiwwdRhGJ2vry98fX1NHcYzY8aMGZgxY4apw+gQX9kyxpgRcLJljDEj4GTLGGNGwMmWMcaMwGA3yLKysgw1FOsh6scY+Vx1nroICx+z55M+RXieRkDUvXdHZGVlYe7cuYaKhzHGep1upkkA2NvtZMuYMan/cedfW9bH7OU5W8YYMwJOtowxZgScbBljzAg42TLGmBFwsmWMMSPgZMsYY0bAyZYxxoyAky1jjBkBJ1vGGDMCTraMMWYEnGwZY8wIONkyxpgRcLJljDEj4GTLGGNGwMmWMcaMgJMtY4wZASdbxhgzAk62jDFmBJxsGWPMCDjZMsaYEXCyZYwxI+BkyxhjRsDJljHGjICTLWOMGQEnW8YYMwJOtowxZgScbBljzAg42TLGmBFwsmWMMSPgZMsYY0bAyZYxxoyAky1jjBkBJ1vGGDMCoakDYKw9169fx4IFC9DS0qJpu3fvHuRyOf7whz9o9XV3d8d//ud/GjlCxjqPky3rtZydnXHt2jWUlpbqbDt27JjWf//+9783VliMdQlPI7Be7f3334dIJHpqv6CgICNEw1jXcbJlvdq7776L5ubmDvuMGjUKI0eONFJEjHUNJ1vWqykUCowZMwYCgaDN7SKRCAsWLDByVIzpj5Mt6/Xef/99mJubt7mtubkZc+bMMXJEjOmPky3r9d555x20trbqtJuZmWHixIkYOnSo8YNiTE+cbFmv5+joiFdffRVmZtq/rmZmZnj//fdNFBVj+uFky/qE9957T6eNiDBz5kwTRMOY/jjZsj5h9uzZWvO25ubmeP311zFo0CATRsVY53GyZX2CnZ0d3njjDU3CJSLMnz/fxFEx1nmcbFmfMX/+fM2NMpFIhICAABNHxFjncbJlfYa/vz8sLS0BAH5+frCysjJxRIx1Hidb1mfIZDLN1SxPIbC+RkBE9HhDVlYW5s6da6p4GGOsz3sirQLA3narfu3Zs6dno2E9orCwEMnJyc/s+WtpacGePXswb948g447d+5chIWFwcvLy6DjsueL+v+/trSbbN9+++0eC4j1rOTk5Gf6/AUGBkIsFht0zLlz58LLy+uZPm7MONpLtjxny/ocQydaxoyBky1jjBkBJ1vGGDMCTraMMWYEnGwZY8wIONmyNh06dAg2Njb429/+ZupQnnmHDx9GZGQk9u/fj2HDhkEgEEAgELRZ6czX1xdyuRzm5uYYNWoUTp8+bYKIu66xsREeHh5YvXq1Vnt8fLzmez/+M3r0aJ0xCgoK8Oqrr0IqlcLR0RERERF4+PChZvuBAwewadMmrbcy9wacbFmb2liUzXrA2rVrkZKSgqioKMyaNQuXL1+GQqFA//79sWvXLhw8eFCr/48//oi9e/fCz88PxcXFGDdunIki75ro6GhcuHChy58vLi6Gr68vpkyZgqqqKmRnZ+Obb77B4sWLNX38/f0hFosxZcoU3L9/3xBhGwQnW9am6dOn48GDB/Dz8zN1KFAqlfD29jZ1GAa3ceNGZGZmIisrC3K5XGtbSkoKzMzMEBISggcPHpgoQsM6ceIEzp8/3+72nTt3goi0fp7sHxcXBwcHB6xbtw4ymQxeXl6IiIjAjh078K9//UvTb9myZXjxxRcxbdq0p74w1Fg42bJeLz09HZWVlaYOw6AuXbqEmJgYrFu3rs11w97e3ggLC0NFRQU+++wzE0RoWEqlEuHh4e0u+O+M5uZmHDx4ED4+PlovAJ06dSqICLm5uVr9Y2Njcfbs2W7t05A42TIdBQUFcHFxgUAgwBdffAEASEtLg0wmg1QqRW5uLqZOnQpra2s4Oztj9+7dms+mpKRALBZj0KBB+Pjjj+Ho6AixWAxvb2+cPHlS0y80NBQWFhZwcHDQtC1ZsgQymQwCgQDV1dUAgLCwMKxcuRKlpaUQCARwc3MDAHz//fewtrZGQkKCMQ6JwaWkpICI4O/v326f+Ph4jBgxAtu3b8fhw4c7HI+IkJSUhBdeeAGWlpaws7NDQECA1tVeZ88h8Oix6DVr1sDFxQUSiQRjxozp1iPg0dHRWLJkCQYOHNjlMS5fvoy6ujq4uLhotSsUCgDAuXPntNrt7Ozg4+OD5OTkXjEtxsmW6Zg0aRJOnDih1fbJJ59g+fLlUCqVkMvl2LNnD0pLSzFs2DAEBwdDpVIBeJREFy5ciIaGBixbtgxXr17F6dOn0dzcjDfeeAPl5eUAHiWbJx+NTU1Nxbp167TakpOT4efnB4VCASLCpUuXAEBz86OtF0H2BQcPHoS7uzukUmm7fSQSCXbs2AEzMzMEBwejvr6+3b6xsbGIjIxEdHQ0Kisrcfz4cZSXl2Py5Mm4ffs2gM6fQwBYtWoVNm/ejK1bt+LmzZvw8/PDvHnz8Msvv+j9XX/66SeUlpY+tZ5FZGQk7OzsYGFhAVdXVwQEBNzzvc8AACAASURBVODUqVOa7bdu3QIAnSkXsVgMiUSi+Z6PGzt2LCoqKvDrr7/qHbehcbJlevP29oa1tTUGDhyIoKAg1NfXo6ysTKuPUCjUXGWNHDkSaWlpqK2tRUZGhkFimD59OmpqahATE2OQ8Yypvr4eV65c0VyRdcTLywvLly/H1atXsWrVqjb7KJVKJCUlYebMmZg/fz5sbGzg6emJL7/8EtXV1fjqq690PtPROWxsbERaWhoCAwMxa9Ys2NraYvXq1RCJRHqfP6VSibCwMKSlpXXYb8GCBThw4ADKy8tRV1eH3bt3o6ysDD4+PiguLgYAzYqDtl5rLxKJoFQqddqHDx8OACgqKtIr7p7AyZZ1i4WFBQBoXRW1Zfz48ZBKpVp/1j6vKisrQUQdXtU+Lj4+Hu7u7khNTUVBQYHO9uLiYtTV1WH8+PFa7RMmTICFhYXW9E1bnjyHFy5cQENDg9ayK4lEAgcHB73PX1RUFD766CM4OTl12G/w4MEYO3YsrKysYGFhgYkTJyIjIwNKpRKpqakA/q8mRls3vJqamiCRSHTa1ce4rateY+Nky4zG0tISVVVVpg7D5BobGwFA89aJpxGLxcjIyIBAIMCHH36ocwWnXt7U1psrbG1tUVtbq1d86umK1atXa615vXbtGhoaGjo9TkFBAYqKirBo0SK99q/m6ekJc3NzXLx4EQA08/s1NTVa/RoaGtDY2AhHR0edMdQJWH3MTYmTLTMKlUqF+/fvw9nZ2dShmJw6Aeiz6N7LywsrVqxASUkJ4uLitLbZ2toCQJtJtSvHXH0Ta+vWrTpLsQoLCzs9Tnp6Oo4cOQIzMzNNwlaPnZCQAIFA0OEccGtrK1pbWzX/KLm6ukIul+PatWta/dTz+GPGjNEZo6mpCQDavOo1Nk62zCjy8/NBRJg4caKmTSgUPnX64Vk0aNAgCAQCvdfPxsXFwcPDA2fOnNFqHz16NKysrHQS18mTJ9HU1ISXX35Zr/0MHjwYYrEYZ8+e1etzT8rIyNBJ1uq/bKKjo0FEmqmPN998U+fzp06dAhFpCroLhUJMmzYNx48f17oxmpeXB4FA0ObKDvUxtre379Z3MQROtqxHtLa24t69e2hubsa5c+cQFhYGFxcXLFy4UNPHzc0Nd+/eRU5ODlQqFaqqqnSuWgCgX79+uHHjBq5evYra2lqoVCrk5eX12aVfUqkUw4YNw/Xr1/X6nHo64ckbRGKxGCtXrkR2djZ27dqFmpoaFBUVYfHixXB0dERISIje+/nggw+we/dupKWloaamBi0tLbh+/Tpu3rwJAAgKCoK9vb3BHheuqKhAZmYm7t+/D5VKhcLCQixatAguLi5aT4fFxMTg9u3bWLt2Lerr61FYWIjExEQsXLgQ7u7uOuOqj7Gnp6dB4uwWesKePXuojWbWRxji/G3bto0cHBwIAEmlUvL396fU1FSSSqUEgIYPH06lpaX01VdfkbW1NQGgIUOG0MWLF4mIKCQkhEQiETk5OZFQKCRra2sKCAig0tJSrf3cuXOHXnvtNRKLxeTq6kqffvophYeHEwByc3OjsrIyIiI6ffo0DRkyhCQSCU2aNIlu3bpFhw4dIrlcTvHx8d36rmoAaM+ePQYZqzNCQ0NJJBJRQ0ODpi07O5sUCgUBoAEDBtDSpUvb/Gx4eDjNmDFDq621tZUSExNp+PDhJBKJyM7OjgIDA+nChQuaPvqcw4cPH1JERAS5uLiQUCikgQMH0qxZs6i4uJiIiAIDAwkArVmzRq/vXVVVRQAoOjpaq33lypWkUChIJpORUCgkZ2dnCg4Ophs3buiMcezYMXrllVfI0tKSHB0dKTw8nBobG9vc3/Tp08nJyYlaW1v1irOrOvj/L4uT7TOmN5y/kJAQ6tevn0lj0Jexk21JSQkJhULauXOn0fZpSC0tLTR58mRKT083dSjtqq6uJrFYTFu2bDHaPjtKtjyNwHpEb6u41Nu4ublh/fr1WL9+Perq6kwdjl5aWlqQk5OD2tpaBAUFmTqcdsXGxuKll15CaGioqUMBYIA52yfLwrX1M3ToUAOE+mjdoLm5OV566SWDjPe4RYsWQS6XQyAQdHhjoL1+XJKQ6SsyMhJz5sxBUFBQnyo2k5+fj/379yMvL6/Ta4WNLSkpCWfPnsWhQ4cgEolMHQ4AAyTbx8vC2djYaO46Njc3o6GhAbdv3zbYCTl16hRee+01g4z1pO3bt+Prr7/ucj/qBc9e9wZRUVHIyMjAgwcP4Orqin379pk6pF4tISEBoaGh+Pzzz00dSqdNmTIF3377rVZdi94kNzcXDx8+RH5+Puzs7Ewdjka7rzLvLnNzc0gkEkgkEowYMcKgYz9e8ae3UJckfN5t2LABGzZsMHUYfYqvry98fX1NHcYzY8aMGZgxY4apw9BhlDnbnJwcg47XU38WdDaJGyPZExH27t3b5nPtjLG+x+g3yJKTkyGTyWBmZoaXX34Z9vb2EIlEkMlkGDduHCZPnqxZVG1ra4s///nPOmNcunQJHh4ekMlkkEgkmDx5ss4z408rEUdESExMhLu7OywtLWFjY4Pw8HCdfXWmX3dKEqpj3bBhA9zd3SGRSDBgwAC4urpiw4YNOpWxGGN9lB5LFzqkUCjIxsZGq23ZsmVUVFSk03ft2rUEgE6ePEn19fVUXV1Nb731FgGggwcPUlVVFdXX11NoaCgBoLNnz2o+O2XKFBo2bBhduXKFVCoVnT9/nv7f//t/JBaLNWsEiYg+++wzsrS0pH379tG9e/coKiqKzMzM6NSpU0REFB0dTQKBgP7t3/6N7t27Rw0NDZSamkoA6MyZM5pxOtuvvLycANC2bdu0PguAjhw5Qg8ePKDKykqaPHkyyWQyampq0vRLSEggc3Nzys3NpYaGBvrnP/9J9vb29Ic//EHv89Abln71RTDy0i/2bDLa0q8HDx5orUL493//9w77jxw5ElKpFP3798c777wDAHBxccGAAQMglUoxf/58ANCpNCSXyzF06FAIhUKMGjUKX3/9NRobGzV/cj+tRJxSqcTWrVvx+uuvY8WKFbC1tYVEIkG/fv209tPZfk/ztJKEOTk5ePnll+Hv7w+JRIJx48ZhxowZOH78uObZbsZY32bQG2Q2NjZaL1gLCwvr9GfVZd4eL5+mnpt92vPznp6esLGx0VRqf1qJuEuXLqGhoQFTpkzpcNzO9tNHWyUJGxsbdV6N0tLSApFI1Gbtzs7IysrqepDPKX2KrDDWlo5+h3psNQIAo777RyQSaRLY4yXinnxlsqOjo+Z56ae9oqOz/bpr2rRpSExMRG5uLnx9fVFcXIycnBz86U9/6nKynTt3roGjfPYlJyf3mvdVsWfPM/EEWXNzM+7evat5N9HTSsSpryIff9d8Wzrbr7tiY2Pxxz/+EQsXLoS1tTVmzpyJt99+u1Prftvz5Pfmn45/AGDPnj0mj4N/+vZPR+9pM0qyvXnzJj744IMeG/+///u/0drainHjxgF4eom40aNHw8zMDMeOHetw3M72667i4mKUlpaiqqoKKpUKZWVlSEtL61ULshlj3dOjyZaIoFQqsX//flhbWxts3KamJjx48ADNzc04ffo0QkNDMWTIEE35vqeViBs4cCBmzZqFffv2IT09HTU1NTh37pzOmtbO9uuupUuXwsXFpc89I88Y0wM9Qd+lQ4+XhevoZ/Xq1URElJycrCnzNnToUPrHP/5BGzduJBsbGwJA9vb29O2331JmZibZ29sTALKzs6Pdu3cTEVFGRga99tprNGjQIBIKhdS/f39655136Nq1a1pxPa1EXG1tLS1atIj69+9PVlZWNGnSJFqzZg0BIGdnZ/r111873a+7JQmPHj1K/fv31zpeIpGIXnjhBdq/f3+nz0VXzh97BLz0ixkAl1js5VJTUyksLEyr7eHDh7R8+XKytLTUqnn6NHz+uoaTLTOEjpJtj65GYE9369YthIaG6swvW1hYwMXFBSqVCiqVqle8Q4kx1nXPxGqEvkwikUAkEiE9PR23b9+GSqXCjRs3sH37dqxZswZBQUEGne9mjJkGJ1sTs7GxwY8//ojz589jxIgRkEgkGDlyJDIyMrBx40b85S9/MXWI7CkOHz6MyMhIndrO7733nk5fX19fyOVymJubY9SoUQZ7h5exNDY2wsPDQ2f9enx8fJu1rB9/sEitoKAAr776KqRSKRwdHREREdHl5ZWbNm2Ch4cHJBIJZDIZPDw8EBMTo/O68/Xr12PkyJGwtraGpaUl3Nzc8Oc//1nrpvSBAwewadOmnit8r8ecA+sD+Px1Dbo4Z7tmzRry8/OjmpoaTZtCodDc8Pzuu+90PpOXl6fzDrG+YsWKFW2+QywuLq7NG+OjRo3S6nf+/HmSSCQUExNDdXV1dOLECRowYAB98MEHXYpn+vTptGXLFqqsrKTa2lrKysoikUhEb7zxhlY/Hx8fSk1NpTt37lBNTQ3t2bOHRCIRvfXWW1r9kpOTycfHh+7du9elePi1OMyolEolvL29+/w+nmbjxo3IzMxEVlYW5HK51raUlBSYmZkhJCTkmalzfOLECZw/f77d7Tt37tRZ5P9k/7i4ODg4OGDdunWQyWTw8vJCREQEduzYoVMDpTMsLCywZMkSDBw4EFZWVpgzZw4CAgLw97//XfMmYACwsrJCSEgI+vXrB7lcjrfffhuBgYH4/vvvUV5erum3bNkyvPjii5g2bZpW6QBD4GTLDC49PR2VlZV9fh8duXTpEmJiYrBu3TqduhbAo+JDYWFhqKiowGeffWaCCA1LqVQiPDy8W48zNzc34+DBg/Dx8dGqCT116lQQEXJzc/UeMzs7W+f4Ozk5AYDWFMF3332n8+j7gAEDAAANDQ1a7bGxsTh79qzBH93mZMtAREhKSsILL7wAS0tL2NnZISAgQOtKIzQ0FBYWFlqvQlmyZAlkMhkEAgGqq6sBPCo+tHLlSpSWlkIgEMDNzQ0pKSkQi8UYNGgQPv74Yzg6OkIsFsPb2xsnT540yD4A4Pvvv4e1tTUSEhJ69HgBj65ciQj+/v7t9omPj8eIESOwfft2HD58uMPxOnMO9K2R3FE9Z31FR0drriC76vLly6irq9M8Vq+mUCgAQFNIqrtKSkpga2uLIUOGdNivoqICEokErq6uWu12dnbw8fFBcnIyiAz4uis95hxYH9CV87dmzRqysLCgnTt30v379+ncuXM0btw4GjBgAN26dUvT79133yV7e3utzyYmJhIAqqqq0rTNmjWLFAqFVr+QkBCSyWT022+/UWNjIxUXF9OECRNILpdTWVmZQfbx3XffkVwup/Xr1+v1/Yn0n7MdNmwYjRw5ss1tCoWCrly5QkREJ06cIDMzMxo6dCjV1dURUdtztp09B52tkfy0es76KCgoIH9/fyIiqqqqanfO1tnZmWxtbUkkEtHQoUNpxowZ9D//8z+aPseOHSMAlJiYqLMPiURCU6ZM0Ts2taamJrp+/Tpt27aNLC0tn/qK+Pr6epLL5RQaGtrm9sjISJ2a1Z3Bc7asXUqlEklJSZg5cybmz58PGxsbeHp64ssvv0R1dbVBH00WCoWaK7eRI0ciLS0NtbW1yMjIMMj406dPR01NDWJiYgwyXnvq6+tx5coVzRVZR7y8vLB8+XJcvXoVq1atarNPV85BRzWSn1bPWR9KpRJhYWFIS0vrsN+CBQtw4MABlJeXo66uDrt370ZZWRl8fHxQXFwM4P8KOrVVyU4kEkGpVOoV2+MGDx4MZ2dnxMbGYvPmzU+terdhwwY4OjoiPj6+ze3Dhw8HABQVFXU5pidxsn3OFRcXo66uDuPHj9dqnzBhAiwsLLT+zDe08ePHQyqVdunGiClVVlaCiDr91uj4+Hi4u7sjNTVV5/VNQPfPwZM1kp9Wz1kfUVFR+OijjzTzoO0ZPHgwxo4dCysrK1hYWGDixImaQv2pqakA/q+KXls3npqamrr14E55eTkqKyvx17/+FX/5y18wduzYduf0s7OzkZWVhR9++EHnxqaa+tzevn27yzE9iZPtc05d7N3Kykpnm62tLWpra3t0/5aWlqiqqurRfRhaY2MjgEexd4ZYLEZGRgYEAgE+/PBDnSs4Q5+Dx+s5P77m9dq1azo3gzpSUFCAoqIiLFq0SK/9q3l6esLc3BwXL14EAM1c/JNrYBsaGtDY2AhHR8cu7Qd4dGU8cOBA+Pr6IjMzE8XFxW2+5TkzMxMbN25Efn4+hg4d2u546sSvPteGwMn2OWdrawsAbf4Pff/+fTg7O/fYvlUqVY/voyeo/0fUZ/G7l5cXVqxYgZKSEsTFxWltM/Q5eFo9585KT0/HkSNHYGZmpknY6rETEhIgEAjwyy+/tPv51tZWtLa2av5RcnV1hVwux7Vr17T6Xbp0CQAwZswYvb5ne9zc3GBubq6ZvlDbtm0bdu3ahaNHj+J3v/tdh2OoX0dlyMfkOdk+50aPHg0rKyud/2lOnjyJpqYmvPzyy5o2oVD41FcU6SM/Px9EhIkTJ/bYPnrCoEGDIBAI9F4/GxcXBw8PD5w5c0arXZ9z0BlPq+fcWRkZGTrJWv1XSHR0NIhIM/Xx5ptv6nz+1KlTICJ4eXkBeHRup02bhuPHj6O1tVXTLy8vDwKBoMOVHW25c+cO5s2bp9NeUlKClpYWDB48GMCjlR4REREoKipCTk5Om39BPEl9bu3t7fWKqSOcbJ9zYrEYK1euRHZ2Nnbt2oWamhoUFRVh8eLFcHR0REhIiKavm5sb7t69i5ycHKhUKlRVVelcpQBAv379cOPGDVy9ehW1tbWa5Nna2op79+6hubkZ586dQ1hYGFxcXDR1iLu7j7y8PKMs/ZJKpRg2bJjmtUmdpZ5OePIGkT7noLP76aieMwAEBQXB3t7eYI8LV1RUIDMzE/fv34dKpUJhYSEWLVoEFxcXLF68WNMvJiYGt2/fxtq1a1FfX4/CwkIkJiZi4cKFcHd31/TrTHwymQw//vgjjh49ipqaGqhUKpw5cwYLFiyATCbDihUrAAC//fYbNm/ejK+//hoikUjnkeItW7bojK0+t56engY5PgB46dezpivnr7W1lRITE2n48OEkEonIzs6OAgMD6cKFC1r97ty5Q6+99hqJxWJydXWlTz/9lMLDwwkAubm5aZZwnT59moYMGUISiYQmTZpEt27dopCQEBKJROTk5ERCoZCsra0pICCASktLDbaPQ4cOkVwup/j4eL2PG/Rc+hUaGkoikUir/OXjtZ0HDBhAS5cubfOz4eHhOku/OnMO9KmR/LR6zoGBgQSA1qxZ0+nvTNT+0q+VK1eSQqEgmUxGQqGQnJ2dKTg4mG7cuKEzxrFjx+iVV14hS0tLcnR0pPDwcGpsbNTq09n4/P39ydXVlaysrMjS0pIUCgUFBQVRUVGRpk9RUVGHtbbbWoo2ffp0cnJyotbWVn0OD9ezfZ701vMXEhJC/fr1M3UY7dI32ZaUlJBQKHzqes7eqqWlhSZPnkzp6emmDqVNpoyvurqaxGIxbdmyRe/P8jpb1iv0WDUlE3Bzc8P69euxfv36Pvc6o5aWFuTk5KC2thZBQUGmDkeHqeOLjY3FSy+9hNDQUIOOy8mWsS6KjIzEnDlzEBQU1KeKzeTn52P//v3Iy8vr9FphYzJlfElJSTh79iwOHToEkUhk0LE52bIeFxUVhYyMDDx48ACurq7Yt2+fqUMymISEBISGhuLzzz83dSidNmXKFHz77bdaNSh6E1PFl5ubi4cPHyI/P79H3mzNr8VhPW7Dhg1tLjB/Vvj6+sLX19fUYbBumjFjBmbMmNFj4/OVLWOMGQEnW8YYMwJOtowxZgScbBljzAjavUE2Z84cY8bBDET9mCGfP/1t3boVe/fuNXUYrA/r6BFuAZH2ex8KCwuRlJTU40Ex1hW3bt3CmTNnMHXqVFOHwli72vhHe69OsmWsN8vKysLcuXMN+24oxnreXp6zZYwxI+BkyxhjRsDJljHGjICTLWOMGQEnW8YYMwJOtowxZgScbBljzAg42TLGmBFwsmWMMSPgZMsYY0bAyZYxxoyAky1jjBkBJ1vGGDMCTraMMWYEnGwZY8wIONkyxpgRcLJljDEj4GTLGGNGwMmWMcaMgJMtY4wZASdbxhgzAk62jDFmBJxsGWPMCDjZMsaYEXCyZYwxI+BkyxhjRsDJljHGjICTLWOMGQEnW8YYMwJOtowxZgScbBljzAg42TLGmBEITR0AY+1RqVSoq6vTaquvrwcA3Lt3T6tdIBDA1tbWaLExpi9OtqzXunv3LpycnNDS0qKzrV+/flr//dprr+Ho0aPGCo0xvfE0Auu17O3t8fvf/x5mZh3/mgoEArzzzjtGioqxruFky3q1995776l9zM3NMXPmTCNEw1jXcbJlvdqsWbMgFLY/22Vubo633noL/fv3N2JUjOmPky3r1aytrTF16tR2Ey4RYf78+UaOijH9cbJlvd78+fPbvEkGABYWFvjTn/5k5IgY0x8nW9br/elPf4JUKtVpF4lECAwMhEwmM0FUjOmHky3r9cRiMWbOnAmRSKTVrlKp8O6775ooKsb0w8mW9Qnz5s2DSqXSarO2tsYbb7xhoogY0w8nW9YnvP7661oPMohEIrzzzjuwsLAwYVSMdR4nW9YnCIVCvPPOO5qpBJVKhXnz5pk4KsY6j5Mt6zPeeecdzVSCvb09Jk2aZOKIGOs8Trasz/D29oaTkxMA4P3333/qY7yM9SYGKURTWFiI8vJyQwzFWIcmTJiAiooK9O/fH1lZWaYOhz0HvL294ezs3P2ByABmz55NAPiHf/iHf565nz179hgiTWYZrMTi7NmzsXfvXkMNx/5/AoEAe/bswdtvv23qUHqNffv2Yfbs2e1unzNnDgDw7yPrNoFAYLCxeNKL9TkdJVrGeitOtowxZgScbBljzAg42TLGmBFwsmWMMSPgZMsYY0bAyfY5cejQIdjY2OBvf/ubqUPp9Q4fPozIyEjs378fw4YNg0AggEAgaPN9aL6+vpDL5TA3N8eoUaNw+vRpE0TcdY2NjfDw8MDq1au12uPj4zXf+/Gf0aNH64xRUFCAV199FVKpFI6OjoiIiMDDhw+7FM+mTZvg4eEBiUQCmUwGDw8PxMTEoKamRqvf+vXrMXLkSFhbW8PS0hJubm7485//jLq6Ok2fAwcOYNOmTe0Wnjc2TrbPCSIydQh9wtq1a5GSkoKoqCjMmjULly9fhkKhQP/+/bFr1y4cPHhQq/+PP/6IvXv3ws/PD8XFxRg3bpyJIu+a6OhoXLhwocufLy4uhq+vL6ZMmYKqqipkZ2fjm2++weLFi7s03j/+8Q8EBwejrKwMt2/fRlxcHDZt2qSz3O/o0aNYunQprl69iurqamzYsAHJycmaNdYA4O/vD7FYjClTpuD+/ftd/o6Gwsn2OTF9+nQ8ePAAfn5+pg4FSqUS3t7epg5Dx8aNG5GZmYmsrCzI5XKtbSkpKTAzM0NISAgePHhgoggN68SJEzh//ny723fu3Aki0vp5sn9cXBwcHBywbt06yGQyeHl5ISIiAjt27MC//vUvvWOysLDAkiVLMHDgQFhZWWHOnDkICAjA3//+d9y8eVPTz8rKCiEhIejXrx/kcjnefvttBAYG4vvvv9cqHbBs2TK8+OKLmDZtGpqbm/WOx5A42TKjS09PR2VlpanD0HLp0iXExMRg3bp1EIvFOtu9vb0RFhaGiooKfPbZZyaI0LCUSiXCw8ORnJzc5TGam5tx8OBB+Pj4aD1pNXXqVBARcnNz9R4zOztb5/iriw89PkXw3XffwdzcXKvfgAEDAAANDQ1a7bGxsTh79my3vqshcLJ9DhQUFMDFxQUCgQBffPEFACAtLQ0ymQxSqRS5ubmYOnUqrK2t4ezsjN27d2s+m5KSArFYjEGDBuHjjz+Go6MjxGIxvL29cfLkSU2/0NBQWFhYwMHBQdO2ZMkSyGQyCAQCVFdXAwDCwsKwcuVKlJaWQiAQwM3NDQDw/fffw9raGgkJCcY4JDpSUlJARPD392+3T3x8PEaMGIHt27fj8OHDHY5HREhKSsILL7wAS0tL2NnZISAgQOtqr7PnAABaWlqwZs0auLi4QCKRYMyYMdizZ0+Xv290dLTmCrKrLl++jLq6Ori4uGi1KxQKAMC5c+e6PPbjSkpKYGtriyFDhnTYr6KiAhKJBK6urlrtdnZ28PHxQXJyskmn0zjZPgcmTZqEEydOaLV98sknWL58OZRKJeRyOfbs2YPS0lIMGzYMwcHBmrqxoaGhWLhwIRoaGrBs2TJcvXoVp0+fRnNzM9544w3Nn2wpKSk69RtSU1Oxbt06rbbk5GT4+flBoVCAiHDp0iUA0NzEaG1t7ZFj8DQHDx6Eu7t7my+WVJNIJNixYwfMzMwQHByM+vr6dvvGxsYiMjIS0dHRqKysxPHjx1FeXo7Jkyfj9u3bADp/DgBg1apV2Lx5M7Zu3YqbN2/Cz88P8+bNwy+//KL3d/3pp59QWlr61OLrkZGRsLOzg4WFBVxdXREQEIBTp05ptt+6dQsAdKZcxGIxJBKJ5nt2hUqlQkVFBb744gscPnwY27Zt6/CtHA0NDTh69CiCg4Pb7Dd27FhUVFTg119/7XJM3cXJlsHb2xvW1tYYOHAggoKCUF9fj7KyMq0+QqFQc5U2cuRIpKWloba2FhkZGQaJYfr06aipqUFMTIxBxtNHfX09rly5orki64iXlxeWL1+Oq1evYtWqVW32USqVSEpKwsyZMzF//nzY2NjA09MTX375Jaqrq/HVV1/pfKajc9DY2Ii0tDQEBgZi1qxZsLW1xerVqyESifQ+/kqlEmFhYUhLS+uw34IFC3DgwAGUl5ejrq4Ou3fvRllZGXx8fFBcXAwAmhUHT/45Dzx6bZFSqdQrtscNHjwYzs7OiI2NxebNmzIXzAAAIABJREFUmzF37twO+2/YsAGOjo6Ij49vc/vw4cMBAEVFRV2Oqbs42TIt6quCJ1+u+KTx48dDKpV26SZIb1NZWQki6vCq9nHx8fFwd3dHamoqCgoKdLYXFxejrq4O48eP12qfMGECLCwstKZf2vLkObhw4QIaGhq0ll1JJBI4ODjoffyjoqLw0UcfaeZB2zN48GCMHTsWVlZWsLCwwMSJE5GRkQGlUonU1FQA0MyttnXjqampCRKJRK/YHldeXo7Kykr89a9/xV/+8heMHTu23Xn+7OxsZGVl4YcfftC5ylZTn9vuXG13Fydb1mWWlpaoqqoydRjd1tjYCODR9+kMsViMjIwMCAQCfPjhhzpXcOplRlZWVjqftbW1RW1trV7xqacrVq9erbXm9dq1azo3gzpSUFCAoqIiLFq0SK/9q3l6esLc3BwXL14EAM38/JNrYBsaGtDY2AhHR8cu7Qd4dGU8cOBA+Pr6IjMzE8XFxdiwYYNOv8zMTGzcuBH5+fkYOnRou+OpE7/6XJsCJ1vWJSqVCvfv3zdMBXsTU/+PqM/idy8vL6xYsQIlJSWIi4vT2mZrawsAbSbVrhwz9U2srVu36izFKiws7PQ46enpOHLkCMzMzDQJWz12QkICBAJBh3PAra2taG1t1fyj5OrqCrlcjmvXrmn1U8/DjxkzRq/v2R43NzeYm5trpi/Utm3bhl27duHo0aP43e9+1+EYTU1NANCtq+3u4mTLuiQ/Px9EhIkTJ2rahELhU6cfeqNBgwZBIBDovX42Li4OHh4eOHPmjFb76NGjYWVlpZO4Tp48iaamJrz88st67Wfw4MEQi8U4e/asXp97UkZGhk6yVv9lEh0dDSLSTH28+eabOp8/deoUiAheXl4AHp3vadOm4fjx41o3NvPy8iAQCDpc2dGWO3futHnTrqSkBC0tLRg8eDCARys9IiIiUFRUhJycnDb/gniS+tza29vrFZMhcbJlndLa2op79+6hubkZ586dQ1hYGFxcXLBw4UJNHzc3N9y9exc5OTlQqVSoqqrSueoBgH79+uHGjRu4evUqamtroVKpkJeXZ7KlX1KpFMOGDcP169f1+px6OuHJG0RisRgrV65EdnY2du3ahZqaGhQVFWHx4sVwdHRESEiI3vv54IMPsHv3bqSlpaGmpgYtLS24fv26ZqF/UFAQ7O3tDfa4cEVFBTIzM3H//n2oVCoUFhZi0aJFcHFx0Xo6LCYmBrdv38batWtRX1+PwsJCJCYmYuHChXB3d9f060x8MpkMP/74I44ePYqamhqoVCqcOXMGCxYsgEwmw4oVKwAAv/32GzZv3oyvv/4aIpFI55HiLVu26IytPreenp4GOT5dYoiX68yePZtmz55tiKHYE2CAdyBt27aNHBwcCABJpVLy9/en1NRUkkqlBICGDx9OpaWl9NVXX5G1tTUBoCFDhtDFixeJiCgkJIREIhE5OTmRUCgka2trCggIoNLSUq393Llzh1577TUSi8Xk6upKn376KYWHhxMAcnNzo7KyMiIiOn36NA0ZMoQkEglNmjSJbt26RYcOHSK5XE7x8fHd+q5EXft9DA0NJZFIRA0NDZq27OxsUigUBIAGDBhAS5cubfOz4eHhNGPGDK221tZWSkxMpOHDh5NIJCI7OzsKDAykCxcuaProcw4ePnxIERER5OLiQkKhkAYOHEizZs2i4uJiIiIKDAwkALRmzRq9vndVVRUBoOjoaK32lStXkkKhIJlMRkKhkJydnSk4OJhu3LihM8axY8folVdeIUtLS3J0dKTw8HBqbGzU6tPZ+Pz9/cnV1ZWsrKzI0tKSFAoFBQUFUVFRkaZPUVFRh+8MS0xM1Bl3+vTp5OTkRK2trfocHoO+g4yTbS9nwJPdZSEhIdSvXz+TxqCPrvw+lpSUkFAopJ07d/ZQVD2rpaWFJk+eTOnp6aYOpU2mjK+6uprEYjFt2bJF788aMtnyNALrlN5SOamnuLm5Yf369Vi/fr3WY6F9QUtLC3JyclBbW4ugoCBTh6PD1PHFxsbipZdeQmhoqNH3/TiTJNsnS9epfywsLDBo0CD84Q9/QGJiIu7du2eK8NhzKjIyEnPmzEFQUFCfKjaTn5+P/fv3Iy8vr9NrhY3JlPElJSXh7NmzOPT/sXfvcVGW6f/APwMMzIEZwUAgTuJgkqapm61QrrVu7JorSoDiKc1XLpWGZwkVQ0AS9at8cWH7Wi710pKTLJqJmbFUrtbPNlhZ3DUkT1AKmHI+c/3+cJltGA4zMDwzg9f79Zo/ep77eZ7rOXg13HM/133yJMRisaDH7sooyfbnpeuGDRsGIkJHRwcqKiqQkZEBLy8vREREYNy4cf16HZEZzubNm5Gamorq6mp4eXkhKyvL2CENqh07diA8PBxvvfWWsUPR2YwZM/DBBx9o1KUwJcaK79ixY2hubkZ+fj7s7e0FPXZ3TKYbQSQSwc7ODs888wxSU1ORkZGB27dvq0sDmjtTLSvYl/j4eDQ3N4OIcPXq1QdiGnF/f3/s3LnT2GGwAZozZw4iIyO7fZ3YGEwm2XYVHByMZcuWoaKiAm+//baxwxkwUywryBgTjskmWwDqMZy5ubkAgF27dkEmk0GhUKCiogLr16+Hq6srLl++rFNJO13LBQK6lcgbaFlBxtiDw6ST7cSJEwHcr5sJAJs2bcK6detQV1eH+Ph4eHl5YerUqSAinUra6VouENCtRN5Aywoyxh4cJp1sFQoFRCJRt++Y79y5E6tWrcLRo0fh6empV0m7vsoF9qdEHmOM9cbK2AH0pr6+HkQEpVLZa7uBlrTrWi5woPsztH379iEzM1PQY5qzr776CgA0Jv9jzNhM+pttZyk3Hx+fXtsZoqTdz8sFGrpEHmOMmfQ321OnTgG4P4FcbwZa0q5ruUBDl8gbqLVr12r1DbOedX6j5b8G2ED9fCLLgTLZb7a3bt3Cvn374ObmhuXLl/fadqAl7bqWC9Rnf+ZaVpAxJiyjJ1siQl1dHTo6OtT1NdPT0/HUU0/B0tISOTk5ffbZ6lvSrq9ygfrsbyBlBRljDxBDlLPRt8rS8ePHacKECSSTycja2posLCwIAIlEIrKzs6Mnn3ySYmJi6M6dOxrbJSQkkFQqJQDk7u6uUaFJl5J2RLqXC9R1fwMpK6gLmEDVL3PDVeiYoRjw31+G6D87HBBz6iN75ZVXkJmZiTt37hg7FJ2IRCKkp6dzn60ezOl5ZKbNgP/+Mo3ejWAMQ71cIGPM9DyQyZax3pw5cwaRkZFapUCXLFmi1dbf3x8KhQKWlpYYN26cwaalEUpTUxN8fHywdetWjeVxcXFaJVBFIpHGdOqdzp49i6eeegoymQwuLi6IiIhAc3Nzv+JJSEiAj48PpFIp5HI5fHx8EBUVpTWDb0xMDMaOHQulUgkbGxt4e3tj06ZNGrWIjx8/joSEBJP5cvVAJdsHrVwg09+bb76JpKQkbN68WaMU6EMPPYTDhw/j448/1mh/+vRpZGZmYvbs2SguLsbkyZONFHn/bNmyBZcvX+739sXFxfD398eMGTNQWVmJ7Oxs/PnPf9aYp0wfX375JVasWIEbN27g9u3biI2NRUJCgla1uby8PKxatQrXrl1DVVUV4uPjkZiYqPEiS0BAACQSCWbMmKEeO29MD1SyfRDLBQ6UEKUhTaX85M6dO5GWloaMjAwoFAqNdUlJSbCwsEBYWNiQKPkJAOfOncM///nPHtcfOnRIazberu1jY2Ph7OyM7du3Qy6Xw9fXFxEREXjvvfc0ijbpytraGitXroSjoyNsbW0REhKCuXPn4tNPP1VPbgncf+EoLCwMw4cPh0KhwLx58xAYGIhTp05p1DhZvXo1Hn/8cTz//PNoa2vTOx5DeqCSLdOfEKUhTaH85JUrVxAVFYXt27dDIpForffz88OaNWtQXl6ODRs2GCFCw2psbMTGjRuRmJjY7320tbXh448/xvTp0zUG/8+cORNEhGPHjum9z+zsbK3r7+rqCgAaXQQnTpzQqlPr4OAAAGhoaNBYHh0djcLCwgGdqyFwsh1iaJBLQ+papnKg5SdPnTol6NTmSUlJICIEBAT02CYuLg6PPPII3n33XZw5c6bX/elyH1JSUiCXyyGTyXDs2DHMnDkTSqUSbm5uOHLkiMb+2tvbsW3bNnh4eEAqlWLChAlIT0/v9/lu2bJF/Q2yv77//nvU1dXBw8NDY7lKpQIAXLx4sd/7/rmSkhLY2dnB09Oz13bl5eWQSqXw8vLSWG5vb4/p06cjMTERBhh81X+GGEDG4xoHD/Qc57dt2zaytramQ4cO0b179+jixYs0efJkcnBw0Bjbu2jRInJyctLYdvfu3QSAKisr1cuCgoJIpVJptAsLCyO5XE6XLl2ipqYmKi4upilTppBCoVCPKx7oMU6cOEEKhYJiYmJ0PvdO/XkeR40aRWPHju12nUqloqtXrxIR0blz58jCwoJGjhxJdXV1RESUm5urNZW5rvdhy5YtBIA+++wzqq6upoqKCpo2bRrJ5XJqaWlRt9uwYQPZ2NhQVlYW3b17lzZv3kwWFhZ04cIFvc6TiOjs2bMUEBBARD1PZR4bG0tubm5kZ2dHYrGYRo4cSXPmzKH/9//+n7rN559/3uPU4VKplGbMmKF3bJ1aWlqorKyM9u/fTzY2Nn3OelxfX08KhYLCw8O7XR8ZGUkAqKCgQK849P331wueXXcoEbI0ZF9lKgdq1qxZqKmpQVRUlEH215v6+npcvXpV/Y2sN76+vli7di2uXbuGN954o9s2/bkPfn5+UCqVcHR0RGhoKOrr63Hjxg0A90cMpKSkIDAwEEFBQbCzs8PWrVshFov1vt6NjY1Ys2YNUlJSem23dOlSHD9+HDdv3kRdXR2OHDmCGzduYPr06SguLgYA9YiD7qadEYvFaGxs1Cu2n3N3d4ebmxuio6Oxa9cuzJ8/v9f28fHxcHFxQVxcXLfrR48eDQAoKirqd0wDxcl2CDFmaciuZSrNSUVFBYhI55lf4+LiMGbMGCQnJ+Ps2bNa6wd6H6ytrQFA/Ur35cuX0dDQoDHsSiqVwtnZWe/rvXnzZvzhD39Q94P2xN3dHZMmTYKtrS2sra0xdepUpKamorGxEcnJyQCg7lvt7oenlpYWSKVSvWL7uZs3b6KiogIffvgh3n//fUyaNKnHfv3s7GxkZGTgk08+0fphs1Pnve0s/G8MnGyHEGOXhvx5mUpz0tTUBOB+/LqQSCRITU2FSCTC8uXLtb7BGfo+1NfXAwC2bt2qMeb1+vXrWj8G9ebs2bMoKirCyy+/rNfxO40fPx6Wlpbq0qed/fFdx8A2NDSgqakJLi4u/ToOcP+bsaOjI/z9/ZGWlobi4mLEx8drtUtLS8POnTuRn5+PkSNH9ri/zsTfea+NgZPtEGLM0pBdy1Sak85/iPoMfvf19cW6detQUlKC2NhYjXWGvg+dP2Lt27dPayjW+fPndd7PwYMH8dlnn8HCwkKdsDv3vWPHDohEIq1Kdz/X0dGBjo4O9f+UvLy8oFAotAovdU77NGHCBL3Osyfe3t6wtLRUd1902r9/Pw4fPoy8vDw8/PDDve6jpaUFAAb0bXugONkOIcYsDdm1TOVgHGOwjBgxAiKRSO/xs7GxsfDx8UFBQYHG8oGW/OzK3d0dEokEhYWFem3XVWpqqlay7vxLZMuWLSAiddfHb3/7W63tL1y4ACKCr68vgPv39/nnn8cXX3yBjo4Odbvc3FyIRKJeR3Z0586dO1i4cKHW8pKSErS3t8Pd3R3A/ZEeERERKCoqQk5OTrd/QXTVeW+dnJz0ismQONkOIUKWhuyrTOVAj5GbmyvY0C+ZTIZRo0ahrKxMr+06uxO6/kCkb8lPXY7z0ksv4ciRI0hJSUFNTQ3a29tRVlamHugfGhoKJycng70uXF5ejrS0NNy7dw+tra04f/48Xn75ZXh4eGi8HRYVFYXbt2/jzTffRH19Pc6fP4/du3dj2bJlGDNmjLqdLvHJ5XKcPn0aeXl5qKmpQWtrKwoKCrB06VLI5XKsW7cOAHDp0iXs2rUL77zzDsRisdYrxXv27NHad+e9HT9+vEGuT78YYkwDD/0aPNBz6IkQpSF1LVM5kGOcPHmSFAoFxcXF6X3N+vM8hoeHk1gspoaGBvWy7OxsUqlUBIAcHBxo1apV3W67ceNGraFfutyH5ORkkslkBIBGjx5NpaWldODAAVIqlQSAPD096bvvviMioubmZoqIiCAPDw+ysrIiR0dHCgoKouLiYiIiCgwMJAC0bds2vc67p6Ff69evJ5VKRXK5nKysrMjNzY1WrFhBP/zwg9Y+Pv/8c3ryySfJxsaGXFxcaOPGjdTU1KTRRtf4AgICyMvLi2xtbcnGxoZUKhWFhoZSUVGRuk1RUREB6PHT3VC0WbNmkaurK3V0dOhzeQw69IuTrYkz4M02mLCwMBo+fLixw+hRf57HkpISsrKy6nM8p6lqb2+nadOm0cGDB40dSreMGV9VVRVJJBLas2eP3tsaMtlyNwLrF1OppGQo3t7eiImJQUxMjMZroeagvb0dOTk5qK2tRWhoqLHD0WLs+KKjozFx4kSEh4cLfuyf42TL2H9ERkYiJCQEoaGhZlVsJj8/H0ePHkVubq7OY4WFZMz49u7di8LCQpw8eRJisVjQY3fFyZbpZaiXqdyxYwfCw8Px1ltvGTsUnc2YMQMffPCBRh0KU2Ks+I4dO4bm5mbk5+fD3t5e0GN3x6SnMmemJz4+vtvB5UOJv78//P39jR0GG6A5c+Zgzpw5xg5Djb/ZMsaYADjZMsaYADjZMsaYADjZMsaYADjZMsaYAAw2GiErK0tjHiJmOPPnz++zeDLTxs8jMyWi/7ySNiDnz5/XmNGSscFy/vx5JCYmDmj+Lcb04efnZ4jSoZkGSbaMCSUjIwPz58837sR9jOkvk/tsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAJxsGWNMAFbGDoCxnlRWVuIvf/mLxrJvvvkGAHDgwAGN5QqFAgsWLBAsNsb0JSIiMnYQjHWnubkZI0aMQF1dHSwtLQEAnY+rSCRSt2ttbcXSpUvx3nvvGSNMxnSRyd0IzGTZ2NggODgYVlZWaG1tRWtrK9ra2tDW1qb+79bWVgDAwoULjRwtY73jZMtM2sKFC9HS0tJrGzs7O/z6178WKCLG+oeTLTNpzz77LBwdHXtcLxaLsXjxYlhZ8c8PzLRxsmUmzcLCAosWLYJYLO52fWtrK/8wxswCJ1tm8hYsWKDum+3q4Ycfhq+vr8ARMaY/TrbM5D355JPw9PTUWm5tbY2lS5dqjExgzFRxsmVmYcmSJVpdCS0tLdyFwMwGJ1tmFhYtWqTVleDt7Y3x48cbKSLG9MPJlpkFHx8fjB07Vt1lIBaL8dJLLxk5KsZ0x8mWmY0XX3xR/SZZW1sbdyEws8LJlpmNBQsWoL29HQAwefJkeHl5GTkixnTHyZaZDQ8PD/zyl78EACxdutTI0TCmn0F97Wbv3r04f/78YB6CPWCam5shEolw+vRpfPHFF8YOhw0h69atG9Qx24P6zfb8+fP46quvBvMQQ0ZWVhbKysqMHYbJc3Nzg5OTEyQSCb766it+vphBZGVl4ebNm4N6jEF/oXzq1KnIzMwc7MOYPZFIhLVr12LevHnGDsXkXblyBd7e3ggJCQEAfr7YgAnxYgz32TKz4+3tbewQGNMbJ1vGGBMAJ1vGGBMAJ1vGGBMAJ1vGGBMAJ9sh5uTJkxg2bBg++ugjY4di8s6cOYPIyEgcPXoUo0aNgkgkgkgkwpIlS7Ta+vv7Q6FQwNLSEuPGjcO3335rhIj7r6mpCT4+Pti6davG8ri4OPV5//zz2GOPae3j7NmzeOqppyCTyeDi4oKIiAg0Nzf3K56EhAT4+PhAKpVCLpfDx8cHUVFRqKmp0WgXExODsWPHQqlUwsbGBt7e3ti0aRPq6urUbY4fP46EhAT124WmipPtEMOTJevmzTffRFJSEjZv3oygoCB8//33UKlUeOihh3D48GF8/PHHGu1Pnz6NzMxMzJ49G8XFxZg8ebKRIu+fLVu24PLly/3evri4GP7+/pgxYwYqKyuRnZ2NP//5z3j11Vf7tb8vv/wSK1aswI0bN3D79m3ExsYiISEBwcHBGu3y8vKwatUqXLt2DVVVVYiPj0diYqJ62B8ABAQEQCKRYMaMGbh3716/z3GwcbIdYmbNmoXq6mrMnj3b2KGgsbERfn5+xg5Dy86dO5GWloaMjAwoFAqNdUlJSbCwsEBYWBiqq6uNFKFhnTt3Dv/85z97XH/o0CEQkcana/vY2Fg4Oztj+/btkMvl8PX1RUREBN577z38+9//1jsma2trrFy5Eo6OjrC1tUVISAjmzp2LTz/9FD/++KO6na2tLcLCwjB8+HAoFArMmzcPgYGBOHXqlMZLCKtXr8bjjz+O559/Hm1tbXrHIwROtmzQHDx4EBUVFcYOQ8OVK1cQFRWF7du3QyKRaK338/PDmjVrUF5ejg0bNhghQsNqbGzExo0bkZiY2O99tLW14eOPP8b06dM1Bv/PnDkTRIRjx47pvc/s7Gyt6+/q6goAGl0EJ06cUFd66+Tg4AAAaGho0FgeHR2NwsLCAZ3rYOJkO4ScPXsWHh4eEIlE+OMf/wgASElJgVwuh0wmw7FjxzBz5kwolUq4ubnhyJEj6m2TkpIgkUgwYsQIvPLKK3BxcYFEIoGfnx++/vprdbvw8HBYW1vD2dlZvWzlypWQy+UQiUSoqqoCAKxZswbr169HaWkpRCKR+kWEU6dOQalUYseOHUJcEi1JSUkgIgQEBPTYJi4uDo888gjeffddnDlzptf9ERH27t2LRx99FDY2NrC3t8fcuXM1vu3peg8AoL29Hdu2bYOHhwekUikmTJiA9PT0fp/vli1b1N8g++v7779HXV0dPDw8NJarVCoAwMWLF/u9758rKSmBnZ1dt1Mg/Vx5eTmkUqlW1Td7e3tMnz4diYmJJtmdxsl2CHn66adx7tw5jWWvvfYa1q5di8bGRigUCqSnp6O0tBSjRo3CihUr1LMfhIeHY9myZWhoaMDq1atx7do1fPvtt2hra8Nzzz2n/pMtKSlJ65Xi5ORkbN++XWNZYmIiZs+eDZVKBSLClStXAED9I0ZHR8egXIO+fPzxxxgzZgxkMlmPbaRSKd577z1YWFhgxYoVqK+v77FtdHQ0IiMjsWXLFlRUVOCLL77AzZs3MW3aNNy+fRuA7vcAAN544w3s2rUL+/btw48//ojZs2dj4cKF+Oabb/Q+17/97W8oLS3FwoULe20XGRkJe3t7WFtbw8vLC3PnzsWFCxfU62/dugUAWl0uEokEUqlUfZ790draivLycvzxj3/EmTNnsH//flhbW/fYvqGhAXl5eVixYkW37SZNmoTy8nL84x//6HdMg4WT7QPEz88PSqUSjo6OCA0NRX19PW7cuKHRxsrKSv0tbezYsUhJSUFtbS1SU1MNEsOsWbNQU1ODqKgog+xPH/X19bh69ar6G1lvfH19sXbtWly7dg1vvPFGt20aGxuxd+9evPDCC1i8eDGGDRuG8ePH4+2330ZVVRUOHDigtU1v96CpqQkpKSkIDAxEUFAQ7OzssHXrVojFYr2vf2NjI9asWYOUlJRe2y1duhTHjx/HzZs3UVdXhyNHjuDGjRuYPn06iouLAUA94qDrn/PA/RkzGhsb9Yrt59zd3eHm5obo6Gjs2rUL8+fP77V9fHw8XFxcEBcX1+360aNHAwCKior6HdNg4WT7gOr8VtDTFOGdnnjiCchksn79CGJqKioqQES9fqv9ubi4OIwZMwbJyck4e/as1vri4mLU1dXhiSee0Fg+ZcoUWFtba3S/dKfrPbh8+TIaGho0hl1JpVI4Ozvrff03b96MP/zhD+p+0J64u7tj0qRJsLW1hbW1NaZOnYrU1FQ0NjYiOTkZANR9q9398NTS0gKpVKpXbD938+ZNVFRU4MMPP8T777+PSZMm9djPn52djYyMDHzyySda37I7dd7bgXzbHiycbFmfbGxsUFlZaewwBqypqQnA/fPRhUQiQWpqKkQiEZYvX671Da5zmJGtra3WtnZ2dqitrdUrvs7uiq1bt2qMeb1+/brWj0G9OXv2LIqKivDyyy/rdfxO48ePh6WlJb777jsAUPfPdx0D29DQgKamJri4uPTrOMD9b8aOjo7w9/dHWloaiouLER8fr9UuLS0NO3fuRH5+PkaOHNnj/joTf+e9NiWcbFmvWltbce/ePbi5uRk7lAHr/Ieoz+B3X19frFu3DiUlJYiNjdVYZ2dnBwDdJtX+XLPOH7H27dunNRRLnyL8Bw8exGeffQYLCwt1wu7c944dOyASiXrtA+7o6EBHR4f6f0peXl5QKBS4fv26RrvOfvgJEybodZ498fb2hqWlpbr7otP+/ftx+PBh5OXl4eGHH+51Hy0tLQAwoG/bg4WTLetVfn4+iAhTp05VL7Oysuqz+8EUjRgxAiKRSO/xs7GxsfDx8UFBQYHG8sceewy2trZaievrr79GS0sLfvGLX+h1HHd3d0gkEhQWFuq1XVepqalaybrzL5MtW7aAiNRdH7/97W+1tr9w4QKISD1rgZWVFZ5//nl88cUXGj9s5ubmQiQS9Tqyozt37tzp9ke7kpIStLe3w93dHcD9kR4REREoKipCTk4qRlbZAAAgAElEQVROt39BdNV5b52cnPSKSQicbJmGjo4O3L17F21tbbh48SLWrFkDDw8PLFu2TN3G29sbP/30E3JyctDa2orKykqtbz0AMHz4cPzwww+4du0aamtr0draitzcXKMN/ZLJZBg1apTeM2J0did0/YFIIpFg/fr1yM7OxuHDh1FTU4OioiK8+uqrcHFxQVhYmN7Heemll3DkyBGkpKSgpqYG7e3tKCsrUw/0Dw0NhZOTk8FeFy4vL0daWhru3buH1tZWnD9/Hi+//DI8PDw03g6LiorC7du38eabb6K+vh7nz5/H7t27sWzZMowZM0bdTpf45HI5Tp8+jby8PNTU1KC1tRUFBQVYunQp5HI51q1bBwC4dOkSdu3ahXfeeQdisVjrleI9e/Zo7bvz3o4fP94g18egaBAFBwdTcHDwYB5iyABA6enpA9rH/v37ydnZmQCQTCajgIAASk5OJplMRgBo9OjRVFpaSgcOHCClUkkAyNPTk7777jsiIgoLCyOxWEyurq5kZWVFSqWS5s6dS6WlpRrHuXPnDj377LMkkUjIy8uLXn/9ddq4cSMBIG9vb7px4wYREX377bfk6elJUqmUnn76abp16xadPHmSFAoFxcXFDehcifr3fIWHh5NYLKaGhgb1suzsbFKpVASAHBwcaNWqVd1uu3HjRpozZ47Gso6ODtq9ezeNHj2axGIx2dvbU2BgIF2+fFndRp970NzcTBEREeTh4UFWVlbk6OhIQUFBVFxcTEREgYGBBIC2bdum13lXVlYSANqyZYvG8vXr15NKpSK5XE5WVlbk5uZGK1asoB9++EFrH59//jk9+eSTZGNjQy4uLrRx40ZqamrSaKNrfAEBAeTl5UW2trZkY2NDKpWKQkNDqaioSN2mqKiIAPT42b17t9Z+Z82aRa6urtTR0aHP5THIv78+ZHCyNREC3Ow+hYWF0fDhw40agz7683yVlJSQlZUVHTp0aJCiGlzt7e00bdo0OnjwoLFD6ZYx46uqqiKJREJ79uzRe1shki13IzANpl45aaC8vb0RExODmJgYjddCzUF7eztycnJQW1uL0NBQY4ejxdjxRUdHY+LEiQgPDxf82LrgZMseOJGRkQgJCUFoaKhZFZvJz8/H0aNHkZubq/NYYSEZM769e/eisLAQJ0+ehFgsFvTYujKpZNu1rqizszMWL17c53b/+Mc/EBoaCi8vL9jY2MDBwQGPP/64xlsmoaGh3dbt7O5z4sQJrVj6euNp7969EIlEsLCwgI+PD7744osBXw8hbd68GampqaiuroaXlxeysrKMHdKg2rFjB8LDw/HWW28ZOxSdzZgxAx988IFGXQpTYqz4jh07hubmZuTn58Pe3l7QY+tlMDsp+ttnq1KpaNiwYTq1vXjxIslkMlq9ejVdvXqVGhsb6fLly7Rp0yaaMWOGut38+fPp9OnTdO/ePWptbaUff/yRAFBAQAC1tLRQfX09VVRU0IoVK+ijjz7SiAUAOTs7U0tLS7cxtLW1kaenJwHQOKY+YAJ9tuaGfxNghiLAvz/z77Pds2cP7OzskJiYiJEjR0IikeCRRx5BbGysxsBmkUiEp556CsOGDYOVlZXGcrFYDJlMBkdHx27HRv7iF7/ArVu3kJOT020MR48e7fO1SMbYg83sk+2dO3dQXV2Nn376SWO5tbW1xtQwR44c0akfKSwsDL///e81lr322msAgD/96U/dbrN3716sX79e39AZYw8Qs0+2U6ZMQX19PX7961/jb3/726Ac49e//jUeffRR/PWvf9WaWuRvf/sbGhoa4O/vPyjHZowNDWafbDdt2oQnnngC//jHP/D0009j3Lhx2LVrl9Y33YF65ZVXAABvv/22xvL/+Z//Ub/xwhhjPTH7ZCuVSnHu3Dn87//+L3x8fHDp0iVERETg0Ucfxeeff26w43S+Svj++++rqz99//33uHDhQp/FmRljzOyTLXC/TFt4eDj+9a9/4auvvsLcuXNRUVGBkJAQ3L171yDHGDZsGBYuXIi7d+8iLS0NwP3qTK+99lqvleX1MX/+fJ2Hp/FHhKysLGRlZRk9Dv6Y/0cIVn03MS+//OUv8Ze//AWvvfYa/vSnP+Gvf/0rXnjhBYPs+7XXXsM777yDt99+G4GBgcjMzMS//vUvg+wbuD9vV2elJda3ffv2AQDWrl1r5EiYuetrhghDMLtk+8UXX+Dvf/+7+h9YUFAQ0tPTNYZzAcCSJUvwpz/9Sa+iy32ZOHEipk6diq+++gphYWEICQkx6CBqX19frfm9WM8yMzMBgK8ZGzAhkq3ZdSP8/e9/h1wuV/93c3MzLl26pNWuc9SAoQobd+ocBpaVlcXfqBhjOjObZNva2orbt28jPz9fI9kCQGBgIDIyMnDv3j1UV1fj2LFjeOONNzBnzhyDJ9t58+bBwcEBgYGBGDVqlEH3zRgbukwq2f7lL3+Bt7c3SktLUV1drdGBbW1tDWdnZxw/flzj5YTVq1djypQp2Lx5M5ydnTFixAhERETg1VdfRXp6utYxamtrMX36dIwbNw4A8NFHH2H06NFa8x79PJYpU6bg9ddfB3B//qrly5drvMQQFRWlntXzr3/9K8aNG9ftBIGMsQeX6D/vBQ+KkJAQAP/tW2M9E4lESE9P5/5HPfDzxQxFgH9/mSb1zZYxxoYqTraMGciZM2cQGRmpVZ5zyZIlWm39/f2hUChgaWmJcePGGWxOscGSkJAAHx8fSKVSyOVy+Pj4ICoqSmt685iYGIwdOxZKpRI2Njbw9vbGpk2bNAq1Hz9+HAkJCUO+UH1XnGwZM4A333wTSUlJ2Lx5M4KCgvD9999DpVLhoYcewuHDh/Hxxx9rtD99+jQyMzMxe/ZsFBcXY/LkyUaKXDdffvklVqxYgRs3buD27duIjY1FQkICgoODNdrl5eVh1apVuHbtGqqqqhAfH4/ExER1lw8ABAQEQCKRYMaMGbh3757Qp2I0nGwZAKCxsRF+fn5mfwxj2LlzJ9LS0pCRkQGFQqGxLikpCRYWFggLCzOrWSG6sra2xsqVK+Ho6AhbW1uEhIRg7ty5+PTTT9Uz/wKAra0twsLCMHz4cCgUCsybNw+BgYE4deoUbt68qW63evVqPP7443j++efR1tZmjFMSHCdbBgA4ePAgKioqzP4YQrty5QqioqKwfft2SCQSrfV+fn5Ys2YNysvLsWHDBiNEaBjZ2dla59dZw/nnXQQnTpzQmvLdwcEBALReMIqOjkZhYSESExMHI2STw8nWTBER9u7di0cffRQ2Njawt7fH3Llz8e9//1vdJjw8XD1krtPKlSshl8shEolQVVUF4P5rwuvXr0dpaSlEIhG8vb2RlJQEiUSCESNG4JVXXoGLiwskEgn8/Pzw9ddfG+QYAHDq1CkolUrs2LFjUK/XYElKSgIRISAgoMc2cXFxeOSRR/Duu+/izJkzve5Pl/uakpICuVwOmUyGY8eOYebMmVAqlXBzc8ORI0c09tfe3o5t27bBw8MDUqkUEyZM6HZIZH+UlJTAzs4Onp6evbYrLy+HVCqFl5eXxnJ7e3tMnz4diYmJGMRBUaZjMOeB4GlLdAc9p+XYtm0bWVtb06FDh+jevXt08eJFmjx5Mjk4ONCtW7fU7RYtWkROTk4a2+7evZsAUGVlpXpZUFAQqVQqjXZhYWEkl8vp0qVL1NTURMXFxTRlyhRSKBR048YNgxzjxIkTpFAoKCYmRudz72QKz9eoUaNo7Nix3a5TqVR09epVIiI6d+4cWVhY0MiRI6muro6IiHJzc2nOnDka2+h6X7ds2UIA6LPPPqPq6mqqqKigadOmkVwu15i+acOGDWRjY0NZWVl09+5d2rx5M1lYWNCFCxf6db4tLS1UVlZG+/fvJxsbmz6nhK+vryeFQkHh4eHdro+MjCQAVFBQ0K94DEXff3/9YP7T4jyIGhsbsXfvXrzwwgtYvHgxhg0bhvHjx+Ptt99GVVUVDhw4YLBjWVlZqb9ljR07FikpKaitrUVqaqpB9j9r1izU1NT0OaGmKaqvr8fVq1ehUqn6bOvr64u1a9fi2rVreOONN7pt05/76ufnB6VSCUdHR4SGhqK+vh43btwAADQ1NSElJQWBgYEICgqCnZ0dtm7dCrFY3O/75+7uDjc3N0RHR2PXrl191hSIj4+Hi4uLxuSrP9f5MlBRUVG/4jEnnGzNUHFxMerq6vDEE09oLJ8yZQqsra01/sw3tCeeeAIymUzjz9oHVUVFBYhI52m74+LiMGbMGCQnJ3f7huFA72tnqc/W1lYA9+uDNDQ04LHHHlO3kUqlcHZ27vf9u3nzJioqKvDhhx/i/fffx6RJk3rsh8/OzkZGRgY++eQTrR8OO3Veu9u3b/crHnPCydYMdQ6XsbW11VpnZ2eH2traQT2+jY0NKisrB/UY5qCpqQnA/euhC4lEgtTUVIhEIixfvlxdhL6Toe9rfX09AGDr1q0ar75fv36939XwxGIxHB0d4e/vj7S0NBQXF2u96g4AaWlp2LlzJ/Lz8zFy5Mge99c5KWvntRzKONmaITs7OwDo9h/fvXv34ObmNmjHbm1tHfRjmIvORKHP4HxfX1+sW7cOJSUliI2N1Vhn6Pvq6OgI4H7dXyLS+Jw/f16vfXXH29sblpaWKC4u1li+f/9+HD58GHl5eXj44Yd73UdLSwsAaMyEPVRxsjVDjz32GGxtbfHNN99oLP/666/R0tKiMR27lZWV+s9KQ8jPzwcRYerUqYN2DHMxYsQIiEQivcfPxsbGwsfHBwUFBRrL9bmvunB3d4dEIkFhYaFe23V1586dbqd+KikpQXt7O9zd3QHcH0kRERGBoqIi5OTkdPsNvavOa+fk5DSgGM0BJ1szJJFIsH79emRnZ+Pw4cOoqalBUVERXn31Vbi4uCAsLEzd1tvbGz/99BNycnLQ2tqKyspKXL9+XWufw4cPxw8//IBr166htrZWnTw7Ojpw9+5dtLW14eLFi1izZg08PDywbNkygxwjNzfXbId+yWQyjBo1CmVlZXpt19md0HU8qj73VdfjvPTSSzhy5AhSUlJQU1OD9vZ2lJWVqV9ECA0NhZOTU6+vC8vlcpw+fRp5eXmoqalBa2srCgoK1PPydU54eunSJezatQvvvPMOxGKx1tQze/bs0dp357UbP368XudmlgZzrIMpDM0xF9Bz6ElHRwft3r2bRo8eTWKxmOzt7SkwMJAuX76s0e7OnTv07LPPkkQiIS8vL3r99ddp48aNBIC8vb3VQ7i+/fZb8vT0JKlUSk8//TTdunWLwsLCSCwWk6urK1lZWZFSqaS5c+dSaWmpwY5x8uRJUigUFBcXp/c1M4XnKzw8nMRiMTU0NKiXZWdnk0qlIgDk4OBAq1at6nbbjRs3ag390uW+Jicnk0wmIwA0evRoKi0tpQMHDpBSqSQA5OnpSd999x0RETU3N1NERAR5eHiQlZUVOTo6UlBQEBUXFxMRUWBgIAGgbdu29XqeAQEB5OXlRba2tmRjY0MqlYpCQ0OpqKhI3aaoqIgA9PjZvXu31n5nzZpFrq6u1NHR0ceVHlz6/vvrhwxOtiZCgJutt7CwMBo+fLixw+iRKTxfJSUlZGVl1ed4U1PV3t5O06ZNo4MHDwp+7KqqKpJIJLRnzx7Bj92VEMmWuxFYrx60ykz68vb2RkxMDGJiYjReWzUH7e3tyMnJQW1tLUJDQwU/fnR0NCZOnIjw8HDBj20MnGwZG6DIyEiEhIQgNDTUrIrN5Ofn4+jRo8jNzdV5rLCh7N27F4WFhTh58iTEYrGgxzYWTrasW5s3b0Zqaiqqq6vh5eWFrKwsY4dk0nbs2IHw8HC89dZbxg5FZzNmzMAHH3ygUddCCMeOHUNzczPy8/MNOju1qTO7qcyZMOLj47sdrM565u/vD39/f2OHYfLmzJmDOXPmGDsMwfE3W8YYEwAnW8YYEwAnW8YYEwAnW8YYE8Cg/0BWVlaGjIyMwT7MkGCI4iAPks5XPfn5YmZhMF+ZCA4O7vX1Pf7whz/8MZXPYL9BJiJ6ECb/YUNFRkYG5s+f/2DMWcWGkkzus2WMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFYGTsAxnpSVlaGpUuXor29Xb3s7t27UCgUeOaZZzTajhkzBv/3f/8ncISM6Y6TLTNZbm5uuH79OkpLS7XWff755xr//atf/UqosBjrF+5GYCbtxRdfhFgs7rNdaGioANEw1n+cbJlJW7RoEdra2nptM27cOIwdO1agiBjrH062zKSpVCpMmDABIpGo2/VisRhLly4VOCrG9MfJlpm8F198EZaWlt2ua2trQ0hIiMARMaY/TrbM5C1YsAAdHR1ayy0sLDB16lSMHDlS+KAY0xMnW2byXFxc8NRTT8HCQvNxtbCwwIsvvmikqBjTDydbZhaWLFmitYyI8MILLxghGsb0x8mWmYXg4GCNfltLS0v85je/wYgRI4wYFWO642TLzIK9vT2ee+45dcIlIixevNjIUTGmO062zGwsXrxY/UOZWCzG3LlzjRwRY7rjZMvMRkBAAGxsbAAAs2fPhq2trZEjYkx3nGyZ2ZDL5epvs9yFwMyNiIjI2EF0FRISgqysLGOHwRgzQ+np6Zg3b56xw+gq02Srfk2dOhVr1641dhhDzvz587FmzRr4+voaO5R+aW9vR3p6OhYuXCjYMfft2wcA/Dyagfnz5xs7hB6ZbLJ1c3Mzxf87mb358+fD19fXrK9tYGAgJBKJYMfLzMwEALO+Zg8KU0623GfLzI6QiZYxQ+FkyxhjAuBkyxhjAuBkyxhjAuBkyxhjAuBky/rl5MmTGDZsGD766CNjh2Lyzpw5g8jISBw9ehSjRo2CSCSCSCTqtpKZv78/FAoFLC0tMW7cOHz77bdGiFh3CQkJ8PHxgVQqhVwuh4+PD6KiolBTU6PRLiYmBmPHjoVSqYSNjQ28vb2xadMm1NXVqdscP34cCQkJGrMpDyWcbFm/mOC7MCbpzTffRFJSEjZv3oygoCB8//33UKlUeOihh3D48GF8/PHHGu1Pnz6NzMxMzJ49G8XFxZg8ebKRItfNl19+iRUrVuDGjRu4ffs2YmNjkZCQgODgYI12eXl5WLVqFa5du4aqqirEx8cjMTFRY5aNgIAASCQSzJgxA/fu3RP6VAYdJ1vWL7NmzUJ1dTVmz55t7FDQ2NgIPz8/Y4ehZefOnUhLS0NGRgYUCoXGuqSkJFhYWCAsLAzV1dVGinDgrK2tsXLlSjg6OsLW1hYhISGYO3cuPv30U/z444/qdra2tggLC8Pw4cOhUCgwb948BAYG4tSpU7h586a63erVq/H444/j+eef73OiT3PDyZaZvYMHD6KiosLYYWi4cuUKoqKisH379m7HBfv5+WHNmjUoLy/Hhg0bjBChYWRnZ2udn6urKwBodBGcOHFCax45BwcHAEBDQ4PG8ujoaBQWFiIxMXEwQjYaTrZMb2fPnoWHhwdEIhH++Mc/AgBSUlIgl8shk8lw7NgxzJw5E0qlEm5ubjhy5Ih626SkJEgkEowYMQKvvPIKXFxcIJFI4Ofnh6+//lrdLjw8HNbW1nB2dlYvW7lyJeRyOUQiEaqqqgAAa9aswfr161FaWgqRSARvb28AwKlTp6BUKrFjxw4hLomWpKQkEBECAgJ6bBMXF4dHHnkE7777Ls6cOdPr/ogIe/fuxaOPPgobGxvY29tj7ty5+Pe//61uo+s9AO6/9rxt2zZ4eHhAKpViwoQJSE9PH9hJ/0dJSQns7Ozg6enZa7vy8nJIpVJ4eXlpLLe3t8f06dORmJg4tLqryAQFBwdTcHCwscMYkgBQenr6gPdz8+ZNAkD79+9XL9uyZQsBoM8++4yqq6upoqKCpk2bRnK5nFpaWtTtwsLCSC6X06VLl6ipqYmKi4tpypQppFAo6MaNG+p2ixYtIicnJ43j7t69mwBQZWWlellQUBCpVCqNdidOnCCFQkExMTEDPtf+PI+jRo2isWPHdrtOpVLR1atXiYjo3LlzZGFhQSNHjqS6ujoiIsrNzaU5c+ZobLNt2zaytramQ4cO0b179+jixYs0efJkcnBwoFu3bqnb6XoPNmzYQDY2NpSVlUV3796lzZs3k4WFBV24cEGv8+zU0tJCZWVltH//frKxsaFDhw712r6+vp4UCgWFh4d3uz4yMpIAUEFBgV5xGOr5HgQZ/M2WGZyfnx+USiUcHR0RGhqK+vp63LhxQ6ONlZWV+lva2LFjkZKSgtraWqSmphokhlmzZqGmpgZRUVEG2Z8+6uvrcfXqVahUqj7b+vr6Yu3atbh27RreeOONbts0NjZi7969eOGFF7B48WIMGzYM48ePx9tvv42qqiocOHBAa5ve7kFTUxNSUlIQGBiIoKAg2NnZYevWrRCLxf2+/u7u7nBzc0N0dDR27drVZ42C+Ph4uLi4IC4urtv1o0ePBgAUFRX1Kx5TxMmWDSpra2sAQGtra6/tnnjiCchkMo0/i81VRUUFiAgymUyn9nFxcRgzZgySk5Nx9uxZrfXFxcWoq6vDE088obF8ypQpsLa21uh+6U7Xe3D58mU0NDTgscceU7eRSqVwdnbu9/W/efMmKioq8OGHH+L999/HpEmTeuxHz87ORkZGBj755BOtHw47dV6727dv9yseU8TJlpkMGxsbVFZWGjuMAWtqagIA9awSfZFIJEhNTYVIJMLy5cvR2Niosb5zGFR3M1PY2dmhtrZWr/jq6+sBAFu3blWP+RWJRLh+/brWj1W6EovFcHR0hL+/P9LS0lBcXIz4+Hitdmlpadi5cyfy8/MxcuTIHvcnlUoB/PdaDgWcbJlJaG1txb179+Dm5mbsUAasM1HoMzjf19cX69atQ0lJCWJjYzXW2dnZAUC3SbU/18zR0RHA/Tq9RKTxOX/+vF776o63tzcsLS1RXFyssXz//v04fPgw8vLy8PDDD/e6j5aWFgD/vZZDASdbZhLy8/NBRJg6dap6mZWVVZ/dD6ZoxIgREIlEeo+fjY2NhY+PDwoKCjSWP/bYY7C1tcU333yjsfzrr79GS0sLfvGLX+h1HHd3d0gkEhQWFuq1XVd37tzptoh7SUkJ2tvb4e7uDuD+SIqIiAgUFRUhJydHp7njOq+dk5PTgGI0JZxsmVF0dHTg7t27aGtrw8WLF7FmzRp4eHhg2bJl6jbe3t746aefkJOTg9bWVlRWVuL69eta+xo+fDh++OEHXLt2DbW1tWhtbUVubq7Rhn7JZDKMGjUKZWVlem3X2Z3QdTyqRCLB+vXrkZ2djcOHD6OmpgZFRUV49dVX4eLigrCwML2P89JLL+HIkSNISUlBTU0N2tvbUVZWpn4RITQ0FE5OTr2+LiyXy3H69Gnk5eWhpqYGra2tKCgowNKlSyGXy7Fu3ToAwKVLl7Br1y688847EIvFGl0XIpEIe/bs0dp357UbP368Xudm0ow4FKJHPPRr8MAAQ2P2799Pzs7OBIBkMhkFBARQcnIyyWQyAkCjR4+m0tJSOnDgACmVSgJAnp6e9N133xHR/aFfYrGYXF1dycrKipRKJc2dO5dKS0s1jnPnzh169tlnSSKRkJeXF73++uu0ceNGAkDe3t7qYWLffvsteXp6klQqpaeffppu3bpFJ0+eJIVCQXFxcQM6V6L+PY/h4eEkFoupoaFBvSw7O5tUKhUBIAcHB1q1alW3227cuFFr6FdHRwft3r2bRo8eTWKxmOzt7SkwMJAuX76sbqPPPWhubqaIiAjy8PAgKysrcnR0pKCgICouLiYiosDAQAJA27Zt6/U8AwICyMvLi2xtbcnGxoZUKhWFhoZSUVGRuk1RUREB6PGze/durf3OmjWLXF1dqaOjo48rrckQz/cgyeBk+4AxhYcxLCyMhg8fbtQY9NGf57GkpISsrKz6HG9qqtrb22natGl08OBBwY9dVVVFEomE9uzZo/e2pvB894DH2TLjGKqVnTp5e3sjJiYGMTExGq+tmoP29nbk5OSgtrYWoaGhgh8/OjoaEydORHh4uODHHkxDItl2LV3X+bG2tsaIESPwzDPPYPfu3bh7966xQ2UPkMjISISEhCA0NNSsis3k5+fj6NGjyM3N1XmssKHs3bsXhYWFOHnyJMRisaDHHmxDItn+vHTdsGHDQETo6OhARUUFMjIy4OXlhYiICIwbN07rF10mrM2bNyM1NRXV1dXw8vJCVlaWsUMaVDt27EB4eDjeeustY4eisxkzZuCDDz7QqEshhGPHjqG5uRn5+fmwt7cX9NhCGBLJtjsikQh2dnZ45plnkJqaioyMDNy+fVtdGtDcmWpZwb7Ex8ejubkZRISrV69q1T0divz9/bFz505jh2Hy5syZg8jISK3RGEPFkE22XQUHB2PZsmWoqKjA22+/bexwBswUywoyxnr2wCRbAOoxnLm5uQCAXbt2QSaTQaFQoKKiAuvXr4erqysuX76sU0k7XcsFArqVyBtoWUHGmOl6oJLtxIkTAQDff/89AGDTpk1Yt24d6urqEB8fDy8vL0ydOhVEhOjoaERGRmLLli2oqKjAF198gZs3b2LatGnq4hjh4eFYtmwZGhoasHr1aly7dg3ffvst2tra8Nxzz2lUoNdlf0lJSZg3b55GzMnJydi+fbvGssTERMyePRsqlQpEhCtXrgzaNWOMGcYDlWwVCgVEIlG374MkP3EAACAASURBVJjv3LkTq1atwtGjR+Hp6alXSbu+ygX2p0QeY2xosTJ2AEKqr68HEUGpVPbabqAl7bqWCxzo/gzNEMVGHiSdr45mZGQYORJmzh6oZPvdd98BAHx8fHptZ4iSdj8vF2joEnkDlZiYOOTmdxJCXwWxGevNA5VsT506BQCYOXNmr+0GWtKua7lAQ5fIG6j09HStvmHWs87ptjMzM40cCeuLSCQydgg9emD6bG/duoV9+/bBzc0Ny5cv77XtQEvadS0XqM/+zLWsIGOsd0Mu2RIR6urq0NHRASJCZWUl0tPT8dRTT8HS0hI5OTl99tnqW9Kur3KB+uxvIGUFGWMmzFglcHqjb5Wl48eP04QJE0gmk5G1tTVZWFgQABKJRGRnZ0dPPvkkxcTE0J07dzS2S0hIIKlUSgDI3d1do0KTLiXtiHQvF6jr/gZSVlAXMN2qSCaLq9CZDxN+vjNERKY3Mbs59ZG98soryMzMxJ07d4wdik5EIhH32erJnJ7HB50JP9+ZQ64bwRiGerlAxtjAcbJljDEBcLIdgAetXCDrnzNnziAyMlKr7vKSJUu02vr7+0OhUMDS0hLjxo3rdQ4wU5CQkAAfHx9IpVLI5XL4+PggKioKNTU1Gu1iYmIwduxYKJVK2NjYwNvbG5s2bdIorH78+HEkJCQM3b8Ujd1r3B3+QWLwwHR/QDBZA3ket23bRrNnz6aamhr1MpVKRQ899BABoBMnTmhtk5ubqzUHmamaNWsW7dmzhyoqKqi2tpYyMjJILBbTc889p9Fu+vTplJycTHfu3KGamhpKT08nsVhMv/vd7zTaJSYm0vTp0+nu3bv9iseEn2+eFocJS4g6vKZS63fnzp1IS0tDRkYGFAqFxrqkpCRYWFggLCzMrOsrW1tbY+XKlXB0dIStrS1CQkIwd+5cfPrpp+qZeoH7b0+GhYVh+PDhUCgUmDdvHgIDA3Hq1CmNgk2rV6/G448/jueffx5tbW3GOKVBw8mWCUqIOrymUOv3ypUriIqKwvbt2yGRSLTW+/n5Yc2aNSgvL8eGDRuMEKFhZGdna52fq6srAGh0EZw4cUKrKLiDgwMAoKGhQWN5dHQ0CgsLh9wr5ZxsWa9okOvw6loTeKC1fk+dOgWlUokdO3YM6vXqlJSUBCJCQEBAj23i4uLwyCOP4N1338WZM2d63Z8u9yElJQVyuRwymQzHjh3DzJkzoVQq4ebmhiNHjmjsr729Hdu2bYOHhwekUikmTJiA9PT0gZ30f5SUlMDOzg6enp69tisvL4dUKoWXl5fGcnt7e0yfPh2JiYkg0xuZ2n/G7cboHvfZDh7o2ae1bds2sra2pkOHDtG9e/fo4sWLNHnyZHJwcNB4kWLRokXk5OSkse3u3bsJAFVWVqqXBQUFkUql0mgXFhZGcrmcLl26RE1NTVRcXExTpkwhhUKhfoljoMc4ceIEKRQKiomJ0fncO/XneRw1ahSNHTu223UqlYquXr1KRETnzp0jCwsLGjlyJNXV1RFR9322ut6HLVu2EAD67LPPqLq6mioqKmjatGkkl8uppaVF3W7Dhg1kY2NDWVlZdPfuXdq8eTNZWFjQhQsX9DrPTi0tLVRWVkb79+8nGxubPqdwr6+vJ4VCQeHh4d2uj4yMJABUUFCgVxz6Pt8C4j5b1jMh6/D2VRN4oGbNmoWamhpERUUZZH+9qa+vx9WrV6FSqfps6+vri7Vr1+LatWt44403um3Tn/vg5+cHpVIJR0dHhIaGor6+Hjdu3AAANDU1ISUlBYGBgQgKCoKdnR22bt0KsVjc7+vt7u4ONzc3REdHY9euXX1WSIuPj4eLiwvi4uK6XT969GgAQFFRUb/iMUWcbFmPjFmHt2tNYHNSUVEBItJ5GvC4uDiMGTMGycnJOHv2rNb6gd4Ha2trAFDXz7h8+TIaGhrw2GOPqdtIpVI4Ozv3+3rfvHkTFRUV+PDDD/H+++9j0qRJPfabZ2dnIyMjA5988onWD4edOq9d5ywmQwEnW9YjY9fh/XlNYHPS1NQE4H78upBIJEhNTYVIJMLy5cvR2Niosd7Q96G+vh4AsHXrVvWYX5FIhOvXr2v9WKUrsVgMR0dH+Pv7Iy0tDcXFxYiPj9dql5aWhp07dyI/Px8jR47scX9SqRTAf6/lUMDJlvXImHV4u9YENiediUKfwfm+vr5Yt24dSkpKEBsbq7HO0PfB0dERALBv3z4QkcbHELN4eHt7w9LSEsXFxRrL9+/fj8OHDyMvLw8PP/xwr/toaWkB8N9rORRwsmU9MmYd3q41gQfjGINlxIgREIlEeo+fjY2NhY+PDwoKCjSWD7S+clfu7u6QSCQoLCzUa7uu7ty5g4ULF2otLykpQXt7O9zd3QHcH0kRERGBoqIi5OTkdPsNvavOa+fk5DSgGE0JJ1vWIyHr8PZVE3igx8jNzRVs6JdMJsOoUaPUc5fpqrM7oet4VH3rK+tynJdeeglHjhxBSkoKampq0N7ejrKyMvWLCKGhoXBycur1dWG5XI7Tp08jLy8PNTU1aG1tRUFBAZYuXQq5XI5169YBAC5duoRdu3bhnXfegVgs1ui6EIlE2LNnj9a+O6/d+PHj9To3k2bEoRA94qFfgwd6Do0Rog6vrjWBB3KMkydPkkKhoLi4OL2vWX+ex/DwcBKLxdTQ0KBelp2dTSqVigCQg4MDrVq1qtttN27cqDX0S5f7kJycTDKZjADQ6NGjqbS0lA4cOEBKpZIAkKenJ3333XdERNTc3EwRERHk4eFBVlZW5OjoSEFBQVRcXExERIGBgQSAtm3b1ut5BgQEkJeXF9na2pKNjQ2pVCoKDQ2loqIidZuioiIC0ONn9+7dWvudNWsWubq6UkdHRx9XWpO+z7eAMjjZPmBM8WEMCwuj4cOHGzuMHvXneSwpKSErK6s+x5uaqvb2dpo2bRodPHhQ8GNXVVWRRCKhPXv26L2tKT7f/8HjbJlpGGqVnry9vRETE4OYmBiN11bNQXt7O3JyclBbW4vQ0FDBjx8dHY2JEyciPDxc8GMPJk62jA2SyMhIhISEIDQ01KyKzeTn5+Po0aPIzc3VeaywoezduxeFhYU4efIkxGKxoMcebJxsmVEN9ZrAO3bsQHh4ON566y1jh6KzGTNm4IMPPtCoQyGEY8eOobm5Gfn5+bC3txf02EKwMnYA7MEWHx/f7eD3ocTf3x/+/v7GDsPkzZkzB3PmzDF2GIOGv9kyxpgAONkyxpgAONkyxpgAONkyxpgATPYHsq+++gohISHGDmNI2rdvHzIzM40dhtn46quvAICfRzYgJplsfX19jR3CkBUcHGzsEAbk1q1bKCgowMyZMwU75s+L4TDTFhwcrC6AY2pERENpkh821GVkZGD+/PlDa24q9iDI5D5bxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTACdbxhgTgJWxA2CsJ62trairq9NYVl9fDwC4e/euxnKRSAQ7OzvBYmNMX5xsmcn66aef4Orqivb2dq11w4cP1/jvZ599Fnl5eUKFxpjeuBuBmSwnJyf86le/goVF74+pSCTCggULBIqKsf7hZMtM2pIlS/psY2lpiRdeeEGAaBjrP062zKQFBQXByqrn3i5LS0v87ne/w0MPPSRgVIzpj5MtM2lKpRIzZ87sMeESERYvXixwVIzpj5MtM3mLFy/u9kcyALC2tsbvf/97gSNiTH+cbJnJ+/3vfw+ZTKa1XCwWIzAwEHK53AhRMaYfTrbM5EkkErzwwgsQi8Uay1tbW7Fo0SIjRcWYfjjZMrOwcOFCtLa2aixTKpV47rnnjBQRY/rhZMvMwm9+8xuNFxnEYjEWLFgAa2trI0bFmO442TKzYGVlhQULFqi7ElpbW7Fw4UIjR8WY7jjZMrOxYMECdVeCk5MTnn76aSNHxJjuONkys+Hn5wdXV1cAwIsvvtjna7yMmRKzLUSTkZFh7BCYEUyZMgXl5eV46KGH+Bl4ALm7u8PX19fYYfSLiIjI2EH0h0gkMnYIjDGBBQcHIzMz09hh9EemWf8dlp6eDiLiz38+wcHBCA4ONnocg/3JzMw02L7S09MBwOjnxJ++P8HBwUbOOANj1smWPZjM/R8dezBxsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmWMMQFwsmVaTp48iWHDhuGjjz4ydigm78yZM4iMjPz/7d19TFRX+gfw78AMc2eGGV7kRVYEYQZLQYpldVenurUxIduy8lKwktWmrkkzWu2IoqvQQikgihggWImxNWQj3QoIwdaK61pDs6Zq2ggrGVKdoviOgPIuCDLP74/+mHUcigwM8yLnk/DPvWfOee698ORy59znoLKyEoGBgeDxeODxeKOunRYZGQmpVApHR0eEhobi0qVLVoh4/HJzcxEcHAyRSASJRILg4GCkpaWhu7vboF1mZiZCQkIgk8kgFAqhUCjw97//3WAZ+q+//hq5ubm/WQR+OmDJljFCZJfvuVjcJ598gqKiIqSmpiI+Ph7Xrl2DXC7HjBkzUFpaim+//dag/enTp1FRUYEVK1ZAo9EgIiLCSpGPz3/+8x+8//77uHnzJu7fv4+srCzk5uYaTb07e/YsNm3ahObmZrS3tyMnJweFhYVYuXKlvk10dDQ4jsPy5cvR2dlp6UOxCSzZMkaioqLQ1dWFFStWWDsU9Pf3Q6lUWjsMI3v27MHRo0dRXl4OqVRqsK+oqAgODg5QqVTo6uqyUoST5+TkhI0bN8LT0xPOzs5YuXIlYmNj8e9//xv37t3Tt3N2doZKpYK7uzukUineeecdxMXF4dSpU7h165a+3ebNmxEeHo633noLT548scYhWRVLtoxNO3z4MFpbW60dhoFffvkFaWlp+PTTT8FxnNF+pVKJpKQk3LlzB9u2bbNChOZRVVVldHwjhYCefkRw4sQJODo6GrTz8PAAADx69Mhge0ZGBurr61FYWDgVIds0lmwZA+fOnYOfnx94PB4+++wzAEBxcTEkEgnEYjGOHz+ON998EzKZDL6+vvjqq6/0ny0qKgLHcfDy8sL69evh4+MDjuOgVCpx8eJFfTu1Wg0nJyfMnDlTv23jxo2QSCTg8Xhob28HACQlJSE5ORlNTU3g8XhQKBQAgFOnTkEmk2HXrl2WOCVGioqKQESIjo7+zTbZ2dmYO3cuvvjiC5w5c2bM/ogI+fn5ePnllyEUCuHm5obY2Fj8/PPP+jbjvQYAMDw8jPT0dPj5+UEkEuGVV17Rv5Y8WVqtFq6urvD39x+z3Z07dyASiRAQEGCw3c3NDa+//joKCwun3+MqslMAqKyszNph2JSEhARKSEiYdD+3bt0iALR//379to8++ogA0HfffUddXV3U2tpKS5cuJYlEQoODg/p2KpWKJBIJNTY20sDAAGk0Glq4cCFJpVK6efOmvt3q1avJ29vbYNy8vDwCQG1tbfpt8fHxJJfLDdqdOHGCpFIpZWZmTvpYy8rKyNQ/g8DAQAoJCRl1n1wup+vXrxMR0Q8//EAODg40Z84c6u3tJSKimpoaiomJMfhMeno6OTk50ZEjR6izs5MuX75MERER5OHhQS0tLfp2470G27ZtI6FQSMeOHaOOjg5KTU0lBwcH+vHHH006zhGDg4N0+/Zt2r9/PwmFQjpy5MiY7fv6+kgqlZJarR51f0pKCgGguro6k+Iw1++3lZSzO1vGJEqlEjKZDJ6enkhMTERfXx9u3rxp0IbP5+vv0kJCQlBcXIyenh6UlJSYJYaoqCh0d3cjLS3NLP2Zoq+vD9evX4dcLn9u28WLF2PLli1obm7Gzp07R23T39+P/Px8vP3221izZg1cXFwQFhaGgwcPor29HYcOHTL6zFjXYGBgAMXFxYiLi0N8fDxcXV3x8ccfQyAQTPj8z549G76+vsjIyMDevXuxatWqMdvn5OTAx8cH2dnZo+4PCgoCADQ0NEwoHnvFki0zYSPrfz27EOOzFixYALFYbPBvsb1qbW0FEY26tPposrOz8dJLL+HAgQM4d+6c0X6NRoPe3l4sWLDAYPvChQvh5ORk8PhlNM9egytXruDRo0eYN2+evo1IJMLMmTMnfP5v3bqF1tZW/POf/8Q//vEPvPrqq7/5HL2qqgrl5eX417/+ZfTF4YiRc3f//v0JxWOvWLJlLEIoFKKtrc3aYUzawMAAgF+PZzw4jkNJSQl4PB7WrVuH/v5+g/0j06CcnZ2NPuvq6oqenh6T4uvr6wMAfPzxx/o5vzweDzdu3DD6smq8BAIBPD09ERkZiaNHj0Kj0SAnJ8eo3dGjR7Fnzx7U1tZizpw5v9mfSCQC8L9zOV2wZMtMuaGhIXR2dsLX19faoUzaSKIwZXL+4sWLsXXrVmi1WmRlZRnsc3V1BYBRk+pEzpmnpycAoKCgwKge7Pnz503qazQKhQKOjo7QaDQG2/fv34/S0lKcPXsWv/vd78bsY3BwEMD/zuV0wZItM+Vqa2tBRFi0aJF+G5/Pf+7jB1vk5eUFHo9n8vzZrKwsBAcHo66uzmD7vHnz4OzsjJ9++slg+8WLFzE4OIjf//73Jo0ze/ZscByH+vp6kz73rAcPHoy6erFWq8Xw8DBmz54N4NeZFDt27EBDQwOqq6tHvUN/1si58/b2nlSM9oYlW8bsdDodOjo68OTJE1y+fBlJSUnw8/PD2rVr9W0UCgUePnyI6upqDA0Noa2tDTdu3DDqy93dHXfv3kVzczN6enowNDSEmpoaq039EovFCAwMxO3bt0363MjjhGfno3Ich+TkZFRVVaG0tBTd3d1oaGjAhg0b4OPjA5VKZfI4f/vb3/DVV1+huLgY3d3dGB4exu3bt/UvIiQmJsLb23vM14UlEglOnz6Ns2fPoru7G0NDQ6irq8N7770HiUSCrVu3AgAaGxuxd+9efP755xAIBAaPLng8Hvbt22fU98i5CwsLM+nY7J4Vp0JMCtjULyPmmBqzf/9+mjlzJgEgsVhM0dHRdODAARKLxQSAgoKCqKmpiQ4dOkQymYwAkL+/P129epWIfp36JRAIaNasWcTn80kmk1FsbCw1NTUZjPPgwQN64403iOM4CggIoA8//JC2b99OAEihUOiniV26dIn8/f1JJBLRkiVLqKWlhU6ePElSqZSys7MndaxEE5v6pVarSSAQ0KNHj/TbqqqqSC6XEwDy8PCgTZs2jfrZ7du3G0390ul0lJeXR0FBQSQQCMjNzY3i4uLoypUr+jamXIPHjx/Tjh07yM/Pj/h8Pnl6elJ8fDxpNBoiIoqLiyMAlJ6ePuZxRkdHU0BAADk7O5NQKCS5XE6JiYnU0NCgb9PQ0EAAfvMnLy/PqN+oqCiaNWsW6XS655xpQ/Y+9Ysl2xeILfwyqlQqcnd3t2oMpphIstVqtcTn858739RWDQ8P09KlS+nw4cMWH7u9vZ04jqN9+/aZ/Flb+P2eBDbPljG/F72yk0KhQGZmJjIzMw1eW7UHw8PDqK6uRk9PDxITEy0+fkZGBubPnw+1Wm3xsa1tWiTbZ8vfjfw4OTnBy8sLy5YtQ15eHjo6OqwdKmMnUlJSsHLlSiQmJtpVsZna2lpUVlaipqZm3HOFzSU/Px/19fU4efIkBAKBRce2BdMi2T5d/s7FxQVEBJ1Oh9bWVpSXlyMgIAA7duxAaGio0bfCzPilpqaipKQEXV1dCAgIwLFjx6wd0pTatWsX1Go1du/ebe1Qxm358uX48ssvDepSWMLx48fx+PFj1NbWws3NzaJj2wq+tQOwFh6PB1dXVyxbtgzLli1DVFQUVq1ahaioKFy9ehUuLi7WDtHu5OTkjDrZ/UUWGRmJyMhIa4dh82JiYhATE2PtMKxqWtzZjkdCQgLWrl2L1tZWHDx40NrhMAzzgmHJ9ikj80Bramr028YqV2dK2bvvv/8ef/jDHyAWiyGTyRAWFqZfXmQqS+IxDGMbWLJ9yvz58wEA165d02/buXMn9u7di4KCAty7dw8rVqzAX//6V/z000/44IMPsGXLFvT390MqlaKsrAxNTU0IDAzE+++/r39Dqq+vD9HR0UhISMDDhw+h1Woxd+5c/WuLY43BMMyLgSXbp0ilUvB4PP176qaUqxur7F1zczO6u7sRGhoKjuPg7e2NyspKeHh4TElJPIZhbM+0/YJsNH19fSAiyGQyABMvV/ds2bvAwEB4eXlhzZo12Lx5M9auXauvimTukngXLlwwWGiPGdvIq6PsnNm+CxcuGNTXsDfszvYpV69eBQAEBwcDMF+5OpFIhLNnz2LJkiXYtWsXAgMDkZiYiP7+/ikpiccwjO1hd7ZPOXXqFADgzTffBGBYri4pKWlSfYeGhuKbb75BW1sb8vPzsWfPHoSGhurf4jHHGACwaNEiVFRUTLqf6aK8vByrVq1i58wO2Pt/H+zO9v+1tLSgoKAAvr6+WLduHQDzlau7e/cuGhsbAfyawHfv3o2IiAg0NjaabQyGYWzbtEu2RITe3l7odDoQEdra2lBWVobXXnsNjo6OqK6u1j+zHU+5uvG4e/cu1q9fj59//hmDg4Ooq6vDjRs3sGjRIrONwTCMbZsWyfabb75BeHg47t27h4GBAbi4uMDR0RGOjo6YO3cu8vPzsXbtWmg0GqNizYWFhdiyZQtyc3MxY8YM+Pj4ICkpCR0dHSguLkZBQQEA4JVXXsG1a9fw+eefIzk5GQDw5z//GVqtFp6enhgeHoZSqYRYLMZf/vIXrF+/Hps2bXruGAzDvBh4RPa5eDuPx0NZWRneeecda4diM0aeabHnj+M38szWTv8MphU7//2umBZ3tgzDMNbGki3DmNmZM2eQkpJiVNrz3XffNWobGRkJqVQKR0dHhIaGjrlUjS3R6XQoKCiAUqk02vf1118jNzf3ha9rbCqWbBnGjD755BMUFRUhNTXVoLTnjBkzUFpaim+//dag/enTp1FRUYEVK1ZAo9EgIiLCSpGPn1arxZ/+9Cds3bp11Lng0dHR4DgOy5cv1y/VzrBky5hZf3//qHc79jbGROzZswdHjx5FeXk5pFKpwb6ioiI4ODhApVLZVbHxZ/33v//Fzp07sWHDBn0tkdFs3rwZ4eHheOutt/DkyRMLRmi7WLJlzOrw4cNobW21+zFM9csvvyAtLQ2ffvopOI4z2q9UKpGUlIQ7d+5g27ZtVojQPMLDw1FZWYnVq1dDKBSO2TYjIwP19fUoLCy0UHS2jSXbaY6IkJ+fj5dffhlCoRBubm6IjY01qMugVqvh5ORkUN1/48aNkEgk4PF4aG9vBwAkJSUhOTkZTU1N4PF4UCgUKCoqAsdx8PLywvr16+Hj4wOO46BUKnHx4kWzjAH8+vaftZY3B369cyUiREdH/2ab7OxszJ07F1988QXOnDkzZn/juS6mlPi0RhlPNzc3vP766ygsLGSzPQC2lPmLZCKrj6anp5OTkxMdOXKEOjs76fLlyxQREUEeHh7U0tKib7d69Wry9vY2+GxeXh4BoLa2Nv22+Ph4ksvlBu1UKhVJJBJqbGykgYEB0mg0tHDhQpJKpfolyyc7xokTJ0gqlVJmZqZJxz+R1XVHExgYSCEhIaPuk8vldP36dSIi+uGHH8jBwYHmzJlDvb29RERUU1NjtLz5eK/LRx99RADou+++o66uLmptbaWlS5eSRCKhwcFBfbtt27aRUCikY8eOUUdHB6WmppKDgwP9+OOPEz7mP/7xjxQeHj5mm5SUFAJAdXV1Ex5nBFtdl7Fb/f39yM/Px9tvv401a9bAxcUFYWFhOHjwINrb23Ho0CGzjcXn8/V3aSEhISguLkZPT4/ZykhGRUWhu7sbaWlpZunPFH19fbh+/Trkcvlz2y5evBhbtmxBc3Mzdu7cOWqbiVyXsUp8WrOMZ1BQEACgoaFhSsexByzZTmMajQa9vb1YsGCBwfaFCxfCycnJ4N98c1uwYAHEYvGEykjamtbWVhDRuFerzc7OxksvvYQDBw7g3LlzRvsne12eLfFp7jKephg5J/fv35/ScewBS7bT2Mi0HGdnZ6N9rq6u+iLqU0UoFKKtrW1Kx7CEgYEBAHjuF0YjOI5DSUkJeDwe1q1bh/7+foP95r4u1izjKRKJAPzvHE1nLNlOY66urgAw6h9vZ2cnfH19p2zsoaGhKR/DUkYSiimT+BcvXoytW7dCq9UiKyvLYJ+5r8vTpUKJyODn/PnzJvVlqpGln0bO0XTGku00Nm/ePDg7OxutdXbx4kUMDg4aFOXh8/n6f0vNoba2FkRkUHnf3GNYipeXF3g8nsnzZ7OyshAcHIy6ujqD7aZcl/GwZhnPkXPi7e1t8bFtDUu20xjHcUhOTkZVVRVKS0vR3d2NhoYGbNiwAT4+PlCpVPq2CoUCDx8+RHV1NYaGhtDW1oYbN24Y9enu7o67d++iubkZPT09+uSp0+nQ0dGBJ0+e4PLly0hKSoKfn59+RePJjlFTU2O1qV9isRiBgYH6JXbGa+RxgqOjo9H28V6X8Y7zvDKeiYmJ8Pb2NvvrwiPnJCwszKz92iVrzoWYDLCpX0YmMjVGp9NRXl4eBQUFkUAgIDc3N4qLi6MrV64YtHvw4AG98cYbxHEcBQQE0Icffkjbt28nAKRQKPRTuC5dukT+/v4kEoloyZIl1NLSQiqVigQCAc2aNYv4fD7JZDKKjY2lpqYms41x8uRJkkqllJ2dbdLxm2vql1qtJoFAQI8ePdJvq6qqIrlcTgDIw8OD5B3n7QAAAhhJREFUNm3aNOpnt2/fbjT1azzX5cCBAyQWiwkABQUFUVNTEx06dIhkMhkBIH9/f7p69SoRET1+/Jh27NhBfn5+xOfzydPTk+Lj40mj0RARUVxcHAGg9PT0MY/z/Pnz9Nprr5GPjw8BIAA0c+ZMUiqV9P333xu1j4qKolmzZpFOpxvfiRyDvU/9Ysn2BWKrv4wqlYrc3d2tHcaozJVstVot8fl8OnLkiBmisrzh4WFaunQpHT582Gx9tre3E8dxtG/fPrP0Z6u/3+PE5tkylvGiV4BSKBTIzMxEZmYment7rR2OSYaHh1FdXY2enh79mnjmkJGRgfnz50OtVputT3vGki3DmElKSgpWrlyJxMREuyo2U1tbi8rKStTU1Ix7rvDz5Ofno76+HidPnoRAIDBLn/aOJVtmSqWmpqKkpARdXV0ICAjAsWPHrB3SlNq1axfUajV2795t7VDGbfny5fjyyy8N6lJMxvHjx/H48WPU1tbCzc3NLH2+CNhS5syUysnJQU5OjrXDsKjIyEhERkZaOwyriYmJQUxMjLXDsDnszpZhGMYCWLJlGIaxAJZsGYZhLIAlW4ZhGAtgyZZhGMYCeET2uV4Fj8ezdggMw1hYQkICKioqrB3GRFTY7dSvqV4/iWEY2zN79mxrhzBhdntnyzAMY0cq2DNbhmEYC2DJlmEYxgJYsmUYhrEAPgC7/GqPYRjGjlz4PxCD1gLXUXoCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqb8veQyBbFd",
        "outputId": "24168aa1-932f-415e-9810-b6d04b1b679b"
      },
      "source": [
        "y=train_a['label'].values\n",
        "print(len(y))\n",
        "print(y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1700\n",
            "[1 0 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0TUT2MnBei9",
        "outputId": "3d40d50b-bdfe-42fe-c63b-cfe26a3ba649"
      },
      "source": [
        "history = model.fit(\n",
        "    x=X, y=y,\n",
        "    batch_size=100, \n",
        "    epochs=5, \n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "14/14 [==============================] - 6s 300ms/step - loss: 0.6930 - accuracy: 0.5040 - val_loss: 0.6919 - val_accuracy: 0.5618\n",
            "Epoch 2/5\n",
            "14/14 [==============================] - 4s 283ms/step - loss: 0.6887 - accuracy: 0.6354 - val_loss: 0.6875 - val_accuracy: 0.5265\n",
            "Epoch 3/5\n",
            "14/14 [==============================] - 4s 276ms/step - loss: 0.6620 - accuracy: 0.5978 - val_loss: 0.6642 - val_accuracy: 0.6265\n",
            "Epoch 4/5\n",
            "14/14 [==============================] - 4s 273ms/step - loss: 0.6310 - accuracy: 0.7938 - val_loss: 0.6272 - val_accuracy: 0.6059\n",
            "Epoch 5/5\n",
            "14/14 [==============================] - 4s 268ms/step - loss: 0.4507 - accuracy: 0.8597 - val_loss: 0.5904 - val_accuracy: 0.7559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuUD1p0OBh8s"
      },
      "source": [
        "# getting the test data\n",
        "\n",
        "y_=list(test_a['text'].values)\n",
        "enc_2 = tokenizer.texts_to_sequences(y_)\n",
        "enc_2 = sequence.pad_sequences(enc_2, maxlen=max_review_len)\n",
        "\n",
        "yt=test_a['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lm-MxkOBqSj",
        "outputId": "6d67b7e1-8e11-4974-993e-877655d5a4de"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "class_names = [\"Negative\", \"Positive\"]\n",
        "predicted_classes = model.predict_classes(enc_2)\n",
        "print(classification_report(yt, predicted_classes, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.75      0.69      0.72       164\n",
            "    Positive       0.66      0.73      0.69       136\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.71      0.71      0.71       300\n",
            "weighted avg       0.71      0.71      0.71       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmVHI88jJETB"
      },
      "source": [
        "Observation:\n",
        "\n",
        "The model performs better than the the multinomial naive bayes and randomforest classifiers built in class. However it surprisingly fails to beat SVM model trained in class in terms of accuracy, precision and recall. It goes to say that the LSTM model is affected by the small size of the training dataset. While the SVM model performs well with the given size. \n",
        "One suggestion to improve this model is to have greater size of training data. Secondly, the truncation of review sizes to 450 could also be a factor as important context can be lost in the process. Therefore by testing the model to work with the maximum size of the review lengths we could expect some improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-yQx_cqcbRm"
      },
      "source": [
        "Question 6) (30 points) Use the train.txt file from the PubMed 20K RCT dataset fine-tune a\n",
        "BERT transformer (class 9 code). This task is a bit different as the one seen in class, here the\n",
        "source dataset has FIVE different classes: background, objective, method, result, and\n",
        "conclusion. Once the BERT model is fine-tuned, classify the: test.txt set. Please present the\n",
        "per-class classification report (accuracy, precision, recall, f1-score metrics). Also, present the\n",
        "global metrics - all classes (accuracy, precision, recall, f1-score metrics). Did you model beat the\n",
        "baseline results (https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve\n",
        "it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUHjgLm-dHHP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG_B2P7rYsL9",
        "outputId": "f8ad10e1-2059-4539-8ed4-c649821f1f3c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WuXmjRVevy-",
        "outputId": "cbba558b-083c-4e99-a7e0-532b6691cd9d"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec1ZSOM0e53f",
        "outputId": "eb71471d-100f-42c1-d705-6835f262a6e8"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBbi-CFriGNQ"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Her6SaCMe7Y3"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/PubMed_20K_RCT/train.csv\", delimiter='\\t',header=None, names=['classes','text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "VVOZbOAIiJ7r",
        "outputId": "f5ad8ae0-366c-46f1-8fe5-70e769c1a5df"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>To investigate the efficacy of 6 weeks of dail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>A total of 125 patients with primary knee OA w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Outcome measures included pain reduction and i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Pain was assessed using the visual analog pain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Secondary outcome measures included the Wester...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180035</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>For the absolute change in percent atheroma vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180036</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>For PAV , a significantly greater percentage o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180037</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Both strategies had acceptable side effect pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180038</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>Compared with standard statin monotherapy , th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180039</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>( Plaque Regression With Cholesterol Absorptio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180040 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            classes                                               text\n",
              "0         OBJECTIVE  To investigate the efficacy of 6 weeks of dail...\n",
              "1           METHODS  A total of 125 patients with primary knee OA w...\n",
              "2           METHODS  Outcome measures included pain reduction and i...\n",
              "3           METHODS  Pain was assessed using the visual analog pain...\n",
              "4           METHODS  Secondary outcome measures included the Wester...\n",
              "...             ...                                                ...\n",
              "180035      RESULTS  For the absolute change in percent atheroma vo...\n",
              "180036      RESULTS  For PAV , a significantly greater percentage o...\n",
              "180037      RESULTS  Both strategies had acceptable side effect pro...\n",
              "180038  CONCLUSIONS  Compared with standard statin monotherapy , th...\n",
              "180039  CONCLUSIONS  ( Plaque Regression With Cholesterol Absorptio...\n",
              "\n",
              "[180040 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u10Hm5VPi02m",
        "outputId": "5bc975bb-5e55-4cd1-fd55-e9743a0ae358"
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 180,040\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2TKoSm9i6YQ"
      },
      "source": [
        "label=[]\n",
        "for i in df.classes:\n",
        "  if i==\"BACKGROUND\":\n",
        "    label.append(0)\n",
        "  elif i==\"OBJECTIVE\":\n",
        "    label.append(1)\n",
        "  elif i==\"METHODS\":\n",
        "    label.append(2)\n",
        "  elif i==\"RESULTS\":\n",
        "    label.append(3)\n",
        "  elif i==\"CONCLUSIONS\":\n",
        "    label.append(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_ZD3OO-kxVi"
      },
      "source": [
        "df.insert(2, 'label', label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "eHgCc8nKlM-Z",
        "outputId": "5c2a8163-7d81-4719-f34e-16a622776720"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>To investigate the efficacy of 6 weeks of dail...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>A total of 125 patients with primary knee OA w...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Pain was assessed using the visual analog pain...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Secondary outcome measures included the Wester...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180035</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>For the absolute change in percent atheroma vo...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180036</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>For PAV , a significantly greater percentage o...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180037</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Both strategies had acceptable side effect pro...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180038</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>Compared with standard statin monotherapy , th...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180039</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>( Plaque Regression With Cholesterol Absorptio...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180040 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            classes                                               text  label\n",
              "0         OBJECTIVE  To investigate the efficacy of 6 weeks of dail...      1\n",
              "1           METHODS  A total of 125 patients with primary knee OA w...      2\n",
              "2           METHODS  Outcome measures included pain reduction and i...      2\n",
              "3           METHODS  Pain was assessed using the visual analog pain...      2\n",
              "4           METHODS  Secondary outcome measures included the Wester...      2\n",
              "...             ...                                                ...    ...\n",
              "180035      RESULTS  For the absolute change in percent atheroma vo...      3\n",
              "180036      RESULTS  For PAV , a significantly greater percentage o...      3\n",
              "180037      RESULTS  Both strategies had acceptable side effect pro...      3\n",
              "180038  CONCLUSIONS  Compared with standard statin monotherapy , th...      4\n",
              "180039  CONCLUSIONS  ( Plaque Regression With Cholesterol Absorptio...      4\n",
              "\n",
              "[180040 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqUak8-jlP-_"
      },
      "source": [
        "sentences = df.text.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMOoWETClhtN",
        "outputId": "b613b5cd-aae0-452c-f5ee-0a4a00ca5cd2"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bex_4PanloqJ",
        "outputId": "a3057783-1992-41e9-c743-60dcba886fca"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "Tokenized:  ['to', 'investigate', 'the', 'efficacy', 'of', '6', 'weeks', 'of', 'daily', 'low', '-', 'dose', 'oral', 'pre', '##d', '##nis', '##olo', '##ne', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low', '-', 'grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '12', 'weeks', 'in', 'older', 'adults', 'with', 'moderate', 'to', 'severe', 'knee', 'os', '##te', '##oa', '##rth', '##rit', '##is', '(', 'o', '##a', ')', '.']\n",
            "Token IDs:  [2000, 8556, 1996, 21150, 1997, 1020, 3134, 1997, 3679, 2659, 1011, 13004, 8700, 3653, 2094, 8977, 12898, 2638, 1999, 9229, 3255, 1010, 12969, 1010, 1998, 22575, 2659, 1011, 3694, 21733, 1999, 1996, 2460, 2744, 1998, 3251, 1996, 3466, 2052, 2022, 8760, 2012, 2260, 3134, 1999, 3080, 6001, 2007, 8777, 2000, 5729, 6181, 9808, 2618, 10441, 15265, 14778, 2483, 1006, 1051, 2050, 1007, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RFchNtBm5uj",
        "outputId": "bf44dc3d-b492-43e3-f64c-beeefc3d989a"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "Token IDs: tensor([  101,  2000,  8556,  1996, 21150,  1997,  1020,  3134,  1997,  3679,\n",
            "         2659,  1011, 13004,  8700,  3653,  2094,  8977, 12898,  2638,  1999,\n",
            "         9229,  3255,  1010, 12969,  1010,  1998, 22575,  2659,  1011,  3694,\n",
            "        21733,  1999,  1996,  2460,  2744,  1998,  3251,  1996,  3466,  2052,\n",
            "         2022,  8760,  2012,  2260,  3134,  1999,  3080,  6001,  2007,  8777,\n",
            "         2000,  5729,  6181,  9808,  2618, 10441, 15265, 14778,  2483,  1006,\n",
            "         1051,  2050,  1007,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOfVzXXtnuQb",
        "outputId": "eee87e52-8f39-4a09-d0f9-36179619aa93"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(12345))\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162,036 training samples\n",
            "18,004 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm-20iTToVs3"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp7W_gf1obtu",
        "outputId": "2c8f1c13-da78-4240-a899-056975ad639f"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 5, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INosxz8Cq0jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca08671-ef51-413b-f8b1-461130353ea2"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-POzbkTq5w_"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO1Ek4TMrQ9w"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c-Y6tQXrexU"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zFGrELorjlC"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daIx-kgZrksG",
        "outputId": "363408ef-ff5d-46f7-e613-0a5d13185e3d"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 12345\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:14.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:29.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:44.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:01:00.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:15.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:30.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:45.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:02:00.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:15.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:30.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:45.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:03:00.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:15.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:31.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:46.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:04:01.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:16.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:31.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:46.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:05:01.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:16.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:31.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:46.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:06:01.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:06:16.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:32.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:47.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:07:02.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:07:17.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:32.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:47.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:08:02.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:08:17.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:32.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:47.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:09:02.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:09:17.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:32.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:48.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:10:03.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:10:18.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:33.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:48.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:11:03.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:11:18.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:11:33.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:48.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:12:03.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:12:18.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:12:33.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:48.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:13:03.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:13:18.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:13:34.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:49.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:14:04.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:14:19.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:14:34.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:49.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:15:04.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:15:19.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:15:34.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:49.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:16:04.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:16:20.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:16:35.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:16:50.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:17:05.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:17:20.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:17:35.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:17:50.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:18:05.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:18:20.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:18:35.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:18:51.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:19:06.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:19:21.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:19:36.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:19:51.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:20:06.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:20:21.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:20:36.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:20:51.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:21:06.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:21:21.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:21:36.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:21:51.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:22:07.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:22:22.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:22:37.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:22:52.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:23:07.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:23:22.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:23:37.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:23:52.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:24:07.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:24:22.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:24:37.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:24:52.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:25:07.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:25:22.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:25:37.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:25:53.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:26:08.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:26:23.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:26:38.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:26:53.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:27:08.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:27:23.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:27:38.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:27:53.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:28:08.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:28:23.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:28:38.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:28:53.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:29:08.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:29:24.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:29:39.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:29:54.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:30:09.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:30:24.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:30:39.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:30:54.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:31:09.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:31:24.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:31:39.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:31:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.36\n",
            "  Validation took: 0:01:13\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:15.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:30.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:45.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:01:00.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:15.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:30.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:46.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:02:01.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:16.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:31.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:46.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:03:01.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:16.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:31.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:46.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:04:01.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:16.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:31.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:47.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:05:02.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:17.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:32.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:47.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:06:02.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:06:17.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:32.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:47.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:07:02.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:07:17.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:32.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:47.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:08:03.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:08:18.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:33.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:48.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:09:03.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:09:18.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:33.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:48.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:10:03.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:10:18.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:33.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:48.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:11:03.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:11:19.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:11:34.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:49.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:12:04.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:12:19.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:12:34.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:49.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:13:04.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:13:19.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:13:34.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:49.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:14:04.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:14:20.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:14:35.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:50.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:15:05.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:15:20.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:15:35.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:50.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:16:05.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:16:20.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:16:35.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:16:50.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:17:05.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:17:21.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:17:36.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:17:51.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:18:06.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:18:21.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:18:36.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:18:51.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:19:06.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:19:21.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:19:36.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:19:51.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:20:06.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:20:21.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:20:37.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:20:52.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:21:07.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:21:22.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:21:37.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:21:52.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:22:07.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:22:22.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:22:37.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:22:52.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:23:07.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:23:22.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:23:37.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:23:52.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:24:07.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:24:22.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:24:37.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:24:53.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:25:08.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:25:23.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:25:38.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:25:53.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:26:08.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:26:23.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:26:38.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:26:53.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:27:08.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:27:23.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:27:38.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:27:54.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:28:09.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:28:24.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:28:39.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:28:54.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:29:09.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:29:24.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:29:39.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:29:54.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:30:09.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:30:24.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:30:39.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:30:55.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:31:10.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:31:25.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:31:40.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:31:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.35\n",
            "  Validation took: 0:01:12\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:06:01 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYt44d9dJH2j"
      },
      "source": [
        "testdf = pd.read_csv(\"/content/drive/MyDrive/PubMed_20K_RCT/test.csv\", delimiter='\\t',header=None, names=['classes','text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnmkLjW2JYPN"
      },
      "source": [
        "label=[]\n",
        "for i in testdf.classes:\n",
        "  if i==\"BACKGROUND\":\n",
        "    label.append(0)\n",
        "  elif i==\"OBJECTIVE\":\n",
        "    label.append(1)\n",
        "  elif i==\"METHODS\":\n",
        "    label.append(2)\n",
        "  elif i==\"RESULTS\":\n",
        "    label.append(3)\n",
        "  elif i==\"CONCLUSIONS\":\n",
        "    label.append(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAaho9egJYPR"
      },
      "source": [
        "testdf.insert(2, 'label', label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "0bweLYPVJYPU",
        "outputId": "c7a5d969-b8a9-4b03-a3f3-e8f44cb292f1"
      },
      "source": [
        "testdf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>This study analyzed liver function abnormaliti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>A post hoc analysis was conducted with the use...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Liver function tests ( LFTs ) were measured at...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Survival analyses were used to assess the asso...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>The percentage of patients with abnormal LFTs ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30130</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>There was a statistically significant between-...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30131</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>There were no statistically significant betwee...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30132</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>There was no significant association between s...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30133</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>No adverse effects were reported .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30134</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>Performing a 6-week do-as-tolerated program of...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30135 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           classes                                               text  label\n",
              "0       BACKGROUND  This study analyzed liver function abnormaliti...      0\n",
              "1          RESULTS  A post hoc analysis was conducted with the use...      3\n",
              "2          RESULTS  Liver function tests ( LFTs ) were measured at...      3\n",
              "3          RESULTS  Survival analyses were used to assess the asso...      3\n",
              "4          RESULTS  The percentage of patients with abnormal LFTs ...      3\n",
              "...            ...                                                ...    ...\n",
              "30130      RESULTS  There was a statistically significant between-...      3\n",
              "30131      RESULTS  There were no statistically significant betwee...      3\n",
              "30132      RESULTS  There was no significant association between s...      3\n",
              "30133      RESULTS                 No adverse effects were reported .      3\n",
              "30134  CONCLUSIONS  Performing a 6-week do-as-tolerated program of...      4\n",
              "\n",
              "[30135 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9X3hFzCJYPU",
        "outputId": "171f08f0-e46c-482e-ee24-34e4ca5a147a"
      },
      "source": [
        "sentences = testdf.text.values\n",
        "labels = testdf.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9Zm8lAdJ8NX",
        "outputId": "004ca538-73b6-4201-d9c1-c125f3e0c7a1"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 30,135 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_T6JkHrtNjF",
        "outputId": "772ea7c8-42c9-4ed3-8191-c721ed5d0d76"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "class_names = [\"BACKGROUND\", \"OBJECTIVE\", \"METHODS\", \"RESULTS\", \"CONCLUSIONS\"]\n",
        "\n",
        "tcr = classification_report(flat_true_labels, flat_predictions, target_names=class_names)\n",
        "\n",
        "print('Per class classification report:\\n {}'.format(tcr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Per class classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.68      0.82      0.74      3621\n",
            "   OBJECTIVE       0.77      0.56      0.65      2333\n",
            "     METHODS       0.93      0.95      0.94      9897\n",
            "     RESULTS       0.92      0.91      0.92      9713\n",
            " CONCLUSIONS       0.85      0.81      0.83      4571\n",
            "\n",
            "    accuracy                           0.87     30135\n",
            "   macro avg       0.83      0.81      0.82     30135\n",
            "weighted avg       0.87      0.87      0.87     30135\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9qX3bnYapeo",
        "outputId": "edc402e2-2c84-4bbf-a1e2-e685cabb32c4"
      },
      "source": [
        "# global metrics\n",
        "import sklearn\n",
        "\n",
        "print('*** Global Evaluation of BERT model ***')\n",
        "print('Accuracy:', sklearn.metrics.accuracy_score(flat_true_labels, flat_predictions))\n",
        "print('Precision:', sklearn.metrics.precision_score(flat_true_labels, flat_predictions, average='macro'))\n",
        "print('Recall:', sklearn.metrics.recall_score(flat_true_labels, flat_predictions, average='macro'))\n",
        "print('F1 Score:', sklearn.metrics.f1_score( flat_predictions, flat_true_labels, average='macro'))\n",
        "print('***')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Global Evaluation of BERT model ***\n",
            "Accuracy: 0.8705823792931807\n",
            "Precision: 0.8305331077174681\n",
            "Recall: 0.8098640363131615\n",
            "F1 Score: 0.8154245422581574\n",
            "***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFXVGUMYQHag"
      },
      "source": [
        "Observation:\n",
        "The fine tuned BERT model here does not exactly beat the baselines set by the given paper at https://arxiv.org/pdf/1710.06071.pdf.\n",
        "It does however competes well with some models mentioned in the paper such as LR and forward ANN in the pubmed 20k category. In terms of overall accuracy, precision, recall and f1 scores, the tuned Bert model falls just short of Bi-ANN model's figures quoted in the paper. This could be because of using the pretrained BERT model which is not entirely context based suited for the domain of the dataset. Though it captures a good score with the basic model, it could be improved by training Bert to more domain specific data. In addition the size of the text sequences used in this model along with the overall size of the dataset fed to train and tune the model also play a part in limiting the potential. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqFz9ERCBt7F"
      },
      "source": [
        "Bonus Question: (50 points) Solve question 6 but instead for fine-tuning BERT, use: BioBert\n",
        "(20 points) and BlueBERT (20 points) and compare the results of the three approaches in a\n",
        "nice table. Answer the following questions: Did you model beat the baseline results\n",
        "(https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rLCFEEKB9Ts"
      },
      "source": [
        "Preparing BioBert implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1i7efAJXbnd",
        "outputId": "5ff64e64-a813-4547-89b2-ca400b27a19b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wRsN_amVKHd"
      },
      "source": [
        "!tar -xzf /content/drive/MyDrive/biobert_v11_pubmed.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg0rWsWdWiW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfcffa2-3990-488a-90da-f608174cde68"
      },
      "source": [
        "# %%bash\n",
        "# transformers-cli convert --model_type bert \\\n",
        "# --tf_checkpoint biobert_v1.1_pubmed/model.ckpt-1000000 \\\n",
        "# --config biobert_v1.1_pubmed/bert_config.json \\\n",
        "# --pytorch_dump_output biobert_v1.1_pubmed/pytorch_model.bin\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 42.6MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 40.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=7e4fa7bf214a574bfa584c82690c2bd1a7d77d8225b217f2d4bdce32c6b29f5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4jt0-Asq0cZ",
        "outputId": "616393c8-a588-4bfe-9d0b-229ad339b09f"
      },
      "source": [
        "!transformers-cli convert --model_type bert \\\n",
        "--tf_checkpoint biobert_v1.1_pubmed/model.ckpt-1000000 \\\n",
        "--config biobert_v1.1_pubmed/bert_config.json \\\n",
        "--pytorch_dump_output biobert_v1.1_pubmed/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 10:44:50.268996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Building PyTorch model from configuration: BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.5.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "Converting TensorFlow checkpoint from /content/biobert_v1.1_pubmed/model.ckpt-1000000\n",
            "Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n",
            "Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n",
            "Loading TF weight bert/embeddings/word_embeddings with shape [28996, 768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n",
            "Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n",
            "Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n",
            "Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n",
            "Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n",
            "Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n",
            "Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n",
            "Loading TF weight bert/pooler/dense/bias with shape [768]\n",
            "Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n",
            "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n",
            "Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n",
            "Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n",
            "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n",
            "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n",
            "Save PyTorch model to biobert_v1.1_pubmed/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiGZQ_rEXNUb"
      },
      "source": [
        "!mv biobert_v1.1_pubmed/bert_config.json biobert_v1.1_pubmed/config.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbePHweMXbnd",
        "outputId": "dfd14ea0-ef70-4e2f-9628-7f5c67869408"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHYP9dFsXbne",
        "outputId": "204208ad-de98-4832-ac00-a4044e790509"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quh5AURQXbne"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qEMrbgoXbne"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/PubMed_20K_RCT/train.csv\", delimiter='\\t',header=None, names=['classes','text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "IzgnLpRCXbne",
        "outputId": "5ee3b413-2e6f-471f-fb2c-3e3e0299cc0a"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>To investigate the efficacy of 6 weeks of dail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>A total of 125 patients with primary knee OA w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Outcome measures included pain reduction and i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Pain was assessed using the visual analog pain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Secondary outcome measures included the Wester...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180035</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>For the absolute change in percent atheroma vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180036</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>For PAV , a significantly greater percentage o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180037</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Both strategies had acceptable side effect pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180038</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>Compared with standard statin monotherapy , th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180039</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>( Plaque Regression With Cholesterol Absorptio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180040 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            classes                                               text\n",
              "0         OBJECTIVE  To investigate the efficacy of 6 weeks of dail...\n",
              "1           METHODS  A total of 125 patients with primary knee OA w...\n",
              "2           METHODS  Outcome measures included pain reduction and i...\n",
              "3           METHODS  Pain was assessed using the visual analog pain...\n",
              "4           METHODS  Secondary outcome measures included the Wester...\n",
              "...             ...                                                ...\n",
              "180035      RESULTS  For the absolute change in percent atheroma vo...\n",
              "180036      RESULTS  For PAV , a significantly greater percentage o...\n",
              "180037      RESULTS  Both strategies had acceptable side effect pro...\n",
              "180038  CONCLUSIONS  Compared with standard statin monotherapy , th...\n",
              "180039  CONCLUSIONS  ( Plaque Regression With Cholesterol Absorptio...\n",
              "\n",
              "[180040 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjXi4yqJXbnf",
        "outputId": "32092f59-ea83-4931-a5a2-75abbf135c55"
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 180,040\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZB0h2MKXbnf"
      },
      "source": [
        "label=[]\n",
        "for i in df.classes:\n",
        "  if i==\"BACKGROUND\":\n",
        "    label.append(0)\n",
        "  elif i==\"OBJECTIVE\":\n",
        "    label.append(1)\n",
        "  elif i==\"METHODS\":\n",
        "    label.append(2)\n",
        "  elif i==\"RESULTS\":\n",
        "    label.append(3)\n",
        "  elif i==\"CONCLUSIONS\":\n",
        "    label.append(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6-23g7yXbnf"
      },
      "source": [
        "df.insert(2, 'label', label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "Dbh62Y4qXbnf",
        "outputId": "91fb0427-8c17-4437-bb0d-2e163c14d64e"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>To investigate the efficacy of 6 weeks of dail...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>A total of 125 patients with primary knee OA w...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Pain was assessed using the visual analog pain...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Secondary outcome measures included the Wester...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180035</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>For the absolute change in percent atheroma vo...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180036</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>For PAV , a significantly greater percentage o...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180037</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Both strategies had acceptable side effect pro...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180038</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>Compared with standard statin monotherapy , th...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180039</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>( Plaque Regression With Cholesterol Absorptio...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180040 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            classes                                               text  label\n",
              "0         OBJECTIVE  To investigate the efficacy of 6 weeks of dail...      1\n",
              "1           METHODS  A total of 125 patients with primary knee OA w...      2\n",
              "2           METHODS  Outcome measures included pain reduction and i...      2\n",
              "3           METHODS  Pain was assessed using the visual analog pain...      2\n",
              "4           METHODS  Secondary outcome measures included the Wester...      2\n",
              "...             ...                                                ...    ...\n",
              "180035      RESULTS  For the absolute change in percent atheroma vo...      3\n",
              "180036      RESULTS  For PAV , a significantly greater percentage o...      3\n",
              "180037      RESULTS  Both strategies had acceptable side effect pro...      3\n",
              "180038  CONCLUSIONS  Compared with standard statin monotherapy , th...      4\n",
              "180039  CONCLUSIONS  ( Plaque Regression With Cholesterol Absorptio...      4\n",
              "\n",
              "[180040 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO-5kZWFXbnf"
      },
      "source": [
        "sentences = df.text.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaqRjDYsXbng",
        "outputId": "ff565c83-c10e-4760-921c-949194f35ae7"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('biobert_v1.1_pubmed', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR2L5ZnbXbng",
        "outputId": "0f3644eb-85a3-45d7-b141-2dcca7c32935"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "Tokenized:  ['to', 'investigate', 'the', 'efficacy', 'of', '6', 'weeks', 'of', 'daily', 'low', '-', 'dose', 'oral', 'pre', '##dn', '##is', '##olo', '##ne', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low', '-', 'grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '12', 'weeks', 'in', 'older', 'adults', 'with', 'moderate', 'to', 'severe', 'knee', 'o', '##ste', '##oar', '##th', '##rit', '##is', '(', 'o', '##a', ')', '.']\n",
            "Token IDs:  [1106, 8242, 1103, 23891, 1104, 127, 2277, 1104, 3828, 1822, 118, 13753, 9619, 3073, 22834, 1548, 12805, 1673, 1107, 9248, 2489, 117, 16178, 117, 1105, 27410, 1822, 118, 3654, 24970, 1107, 1103, 1603, 1858, 1105, 2480, 1103, 2629, 1156, 1129, 8505, 1120, 1367, 2277, 1107, 2214, 6323, 1114, 8828, 1106, 5199, 5656, 184, 13894, 19243, 1582, 7729, 1548, 113, 184, 1161, 114, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAEKm6VnXbng",
        "outputId": "21210d29-a46b-470c-f4c6-efcab7ded39b"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "Token IDs: tensor([  101,  1106,  8242,  1103, 23891,  1104,   127,  2277,  1104,  3828,\n",
            "         1822,   118, 13753,  9619,  3073, 22834,  1548, 12805,  1673,  1107,\n",
            "         9248,  2489,   117, 16178,   117,  1105, 27410,  1822,   118,  3654,\n",
            "        24970,  1107,  1103,  1603,  1858,  1105,  2480,  1103,  2629,  1156,\n",
            "         1129,  8505,  1120,  1367,  2277,  1107,  2214,  6323,  1114,  8828,\n",
            "         1106,  5199,  5656,   184, 13894, 19243,  1582,  7729,  1548,   113,\n",
            "          184,  1161,   114,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WLkTTWHXbng",
        "outputId": "8d9f8a12-fce8-4773-c247-3e5eb47fa8d6"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(12345))\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162,036 training samples\n",
            "18,004 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUWxEm-UXbng"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7BAl6ekXbng",
        "outputId": "eb3b6bab-5a5c-4aa0-de2f-33f74d719906"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "# from transformers import BertModel\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top.                  \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"biobert_v1.1_pubmed\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 5, # The number of output labels--2 for binary classification.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at biobert_v1.1_pubmed were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at biobert_v1.1_pubmed and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWORKwuDXbnh",
        "outputId": "4726c9d1-a0d5-4052-d103-6596c27f4b82"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (28996, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgrlhHcaXbnh"
      },
      "source": [
        "# from transformers import AdamW, BertConfig\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elDZRYV3Xbnh"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utp5nKsZXbnh"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EOWBRjLXbnh"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI7WUlu5Xbnh",
        "outputId": "a3e089b3-07a4-4373-d21b-eeb9b73ab31a"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 12345\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:01:23.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:01:51.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:02:19.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:02:47.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:03:14.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:03:42.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:04:10.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:04:37.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:05:05.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:05:33.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:06:00.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:06:28.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:06:56.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:07:23.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:07:51.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:08:19.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:08:46.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:09:14.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:09:42.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:10:09.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:10:37.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:11:05.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:11:32.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:12:00.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:12:28.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:12:55.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:13:23.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:13:51.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:14:18.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:14:46.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:15:14.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:15:41.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:16:09.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:16:37.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:17:04.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:17:32.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:18:00.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:18:27.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:18:55.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:19:23.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:19:50.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:20:18.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:20:46.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:21:13.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:21:41.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:22:09.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:22:36.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:23:04.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:23:32.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:24:00.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:24:27.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:24:55.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:25:23.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:25:50.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:26:18.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:26:46.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:27:13.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:27:41.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:28:09.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:28:36.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:29:04.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:29:32.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:30:00.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:30:27.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:30:55.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:31:23.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:31:50.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:32:18.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:32:46.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:33:13.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:33:41.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:34:09.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:34:36.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:35:04.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:35:32.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:36:00.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:36:27.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:36:55.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:37:23.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:37:50.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:38:18.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:38:46.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:39:14.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:39:41.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:40:09.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:40:37.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:41:04.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:41:32.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:42:00.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:42:27.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:42:55.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:43:23.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:43:50.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:44:18.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:44:46.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:45:13.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:45:41.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:46:09.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:46:36.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:47:04.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:47:32.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:47:59.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:48:27.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:48:55.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:49:22.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:49:50.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:50:18.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:50:46.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:51:13.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:51:41.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:52:09.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:52:36.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:53:04.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:53:32.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:53:59.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:54:27.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:54:55.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:55:22.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:55:50.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:56:18.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:56:45.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:57:13.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:57:41.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:58:08.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:58:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:02:10\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:55.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:01:23.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:01:51.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:02:18.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFqPX7aXXbnh"
      },
      "source": [
        "testdf = pd.read_csv(\"/content/drive/MyDrive/PubMed_20K_RCT/test.csv\", delimiter='\\t',header=None, names=['classes','text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nInH-fQ6Xbni"
      },
      "source": [
        "label=[]\n",
        "for i in testdf.classes:\n",
        "  if i==\"BACKGROUND\":\n",
        "    label.append(0)\n",
        "  elif i==\"OBJECTIVE\":\n",
        "    label.append(1)\n",
        "  elif i==\"METHODS\":\n",
        "    label.append(2)\n",
        "  elif i==\"RESULTS\":\n",
        "    label.append(3)\n",
        "  elif i==\"CONCLUSIONS\":\n",
        "    label.append(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl3NAT8VXbni"
      },
      "source": [
        "testdf.insert(2, 'label', label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZkULEPDXbni"
      },
      "source": [
        "testdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev9tL8jAXbni"
      },
      "source": [
        "sentences = testdf.text.values\n",
        "labels = testdf.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EFRNJMlXbni"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfSyHWaXXbni"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "class_names = [\"BACKGROUND\", \"OBJECTIVE\", \"METHODS\", \"RESULTS\", \"CONCLUSIONS\"]\n",
        "# Calculate the MCC\n",
        "tcr = classification_report(flat_true_labels, flat_predictions, target_names=class_names)\n",
        "\n",
        "print('Per class classification report:\\n {}'.format(tcr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExVeBFJqXbnj"
      },
      "source": [
        "# global metrics\n",
        "import sklearn\n",
        "\n",
        "print('*** Global Evaluation of BERT model ***')\n",
        "print('Accuracy:', sklearn.metrics.accuracy_score(flat_true_labels, flat_predictions))\n",
        "print('Precision:', sklearn.metrics.precision_score(flat_true_labels, flat_predictions, average='macro'))\n",
        "print('Recall:', sklearn.metrics.recall_score(flat_true_labels, flat_predictions, average='macro'))\n",
        "print('F1 Score:', sklearn.metrics.f1_score( flat_predictions, flat_true_labels, average='macro'))\n",
        "print('***')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}